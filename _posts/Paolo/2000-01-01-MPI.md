---
title: 'MPI, Calcolo Parallelo, UNIMIB'
categories: italiano
tags:
  - Paolo
  - MPI
  - Calcolo Parallelo
maths: 1
comments_id: 15
bigimg: null
published: true
date: 2021-08-01T00:00:00.000Z
---

*  **[MPI a.a. 2020-2021]({{ site.baseurl }}/assets/mpi_88_noPause.pdf)**,  diapositive in formato handout.
Ho aggiunto varie animazioni, reso uniforme e modificato alcune parti rispetto all'anno precedente.
In totale ci Sono 162 diapositive.

*  **[MPI a.a. 2019-2020]({{ site.baseurl }}/assets/mpi_74.pdf)**,  diapositive in formato handout.
Ho aggiunto varie animazioni, corretto errori e modificato alcune parti rispetto all'anno precedente.


* **[MPI a.a. 2018-2019]({{ site.baseurl }}/assets/mpi_63_handout-pages-deleted.pdf)**, queste diapositive sono in
 formato handout (scritte con Latex-beamer) 

* i **file** riguardanti gli esercizi proposti durante il corso sono **[qui](https://github.com/4phycs/mpi-ita-2018-19.git)**.


In questa pagina ci sono i link del materiale che ho scritto per la parte di MPI del corso di Sistemi di Calcolo Parallelo presso il DISCo 
 all'Universita' degli Studi di Milano-Bicocca. 


A chi e' rivolto `MPI`?

Grossolanamente parlando chi ha un cluster e vuole fare dei calcoli paralleli.
In partica ci si aspetta che le varie unita' di calcolo abbiano risorse separate
e per questo motivo debbano comunicare informazioni durante un calcolo parallelo.
Non e' un caso che questo standard si chiami infatti Message Passing Interface.

La curva di apprendimento e' un po' piu' ripida, all'inizio, rispetto a 
**[OpenMP]({{ site.baseurl }}{% link _posts/Paolo/2000-01-01-OpenMP.md %})**.


Il punto di partenza che deve essere tenuto bene a mente e' che ogni unita'
di calcolo, in linea di principio, esegue **TUTTO** il codice che abbiamo scritto.
Per questo motivo si devono usare delle condizioni *if/then* abbinate a degli
identificativi della macchina stessa (forniti da MPI tramite apposite API) per suddividere un calcolo
tra le varie unita' di processazione.
