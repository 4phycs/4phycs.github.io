---
title: MPI, Calcolo Parallelo, UNIMIB, a.a. 2018-2019
categories: italiano
tags: [Paolo, MPI, Calcolo Parallelo]
maths: 1
comments_id: 15
bigimg:
---

In questa pagina ci sono i link del materiale per MPI per il corso di Calcolo Parallelo presso il DISCo 
usato durante l'anno accademico 2018/2019 all'Universita' di Milano Bicocca. 

Cliccando **[qui]({{ site.baseurl }}/assets/mpi_63_handout-pages-deleted.pdf)** si possono scaricare
le diapositive, mentre i file 
da usare durante il corso sono **[qui](https://github.com/4phycs/mpi-ita-2018-19.git)**.

A chi e' rivolto `MPI`?

Grossolanamente parlando chi ha un cluster e vuole fare dei calcoli paralleli.
In partica ci si aspetta che le varie unita' di calcolo abbiano risorse separate
e per questo motivo debbano comunicare informazioni durante un calcolo parallelo.
Non e' un caso che questo standard si chiami infatti Message Passing Interface.

La curva di apprendimento e' un po' piu' ripida, all'inizio, rispetto a 
**[OpenMP]({{ site.baseurl }}{% link _posts/Paolo/2020-02-09-OpenMP-18-19.md %})**.


Il punto di partenza che deve essere tenuto bene a mente e' che ogni unita'
di calcolo, in linea di principio, esegue **TUTTO** il codice che abbiamo scritto.
Per questo motivo si devono usare delle condizioni *if/then* abbinate a degli
identificativi della macchina stessa (forniti da MPI tramite apposite API) per suddividere un calcolo
tra le varie unita' di processazione.








