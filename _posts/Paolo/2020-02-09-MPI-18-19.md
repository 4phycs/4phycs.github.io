---
title: MPI, Calcolo Parallelo, UNIMIB, a.a. 2018-2019
categories: italiano
tags: [Paolo, MPI, Calcolo Parallelo]
maths: 1
bigimg:
---

Cliccando [qui](https://github.com/4phycs/mpi-ita-2018-19.git) si possono scaricare 
le diapositive per MPI per il corso di Calcolo Parallelo presso il DISCo 
durante l'anno accademico 2018/2019 all'Universita' di Milano Bicocca. 

A chi e' rivolto `MPI`?

Grossolanamente parlando chi ha un cluster e vuole fare dei calcoli paralleli.
In partica ci si aspetta che le varie unita' di calcolo abbiano risorse separate
e per questo motivo debbano comunicare informazioni durante un calcolo parallelo.
Non e' un caso che questo standard si chiami infatti Message Passing Interface.

La curva di apprendimento e' un po' piu' ripida, all'inizio, rispetto a OpenMP.

Il punto di partenza che deve essere tenuto bene a mente e' che ogni unita'
di calcolo, in linea di principio, esegue **TUTTO** il codice che abbiamo scritto.
Per questo motivo si devono usare delle condizioni *if/then* abbinate a degli
identificativi della macchina stessa (forniti da MPI tramite apposite API) per suddividere un calcolo
tra le varie unita' di processazione.








