<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <link href="https://fonts.googleapis.com/css?family=Maven+Pro:400,500&amp;subset=latin-ext,vietnamese" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Dancing+Script:400,700&amp;subset=vietnamese" rel="stylesheet">
  <meta name="google-site-verification" content="8zqeFQNuNAWS7ye6oN69hdEeYC_RsDyAlhht79xtAQo" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:image" content="/assets/res/banner.png" />

  

  <title>
    
      Pytorch 4 Feed Forward Neural Network | 4Phycs
    
  </title>

  

  <!-- page's cover -->
  
    <meta property="og:image" content="http://localhost:4000/images/defaultCoverPost.png" />
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1234">
    <meta property="og:image:height" content="592">
  

  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
  

  <link rel="shortcut icon" type="image/x-icon" href="/assets/res/favicon.png">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/css/materialize.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="/assets/css/main.css">

  <link rel="stylesheet" href="/assets/css/thi_scss.css">

  
    
      <link rel="stylesheet" href="/assets/css/post.css">
    
  

  

  <link rel="stylesheet" href="/assets/css/syntax.css">
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml">
  <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml">
  
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Pytorch 4 Feed Forward Neural Network" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="tocIn this post" />
<meta property="og:description" content="tocIn this post" />
<link rel="canonical" href="http://localhost:4000/Pytorch-4" />
<meta property="og:url" content="http://localhost:4000/Pytorch-4" />
<meta property="og:site_name" content="4Phycs" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-15T00:00:00+02:00" />
<meta name="google-site-verification" content="" />
<script type="application/ld+json">
{"headline":"Pytorch 4 Feed Forward Neural Network","dateModified":"2021-10-15T00:00:00+02:00","datePublished":"2021-10-15T00:00:00+02:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/Pytorch-4"},"description":"tocIn this post","@type":"BlogPosting","url":"http://localhost:4000/Pytorch-4","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body>
	<header>
  
    <nav class="top-nav light-blue darken-4">
  <div class="nav-wrapper">
    <div class="container">
      <a class="page-title font-title" href="/">4Phycs</a>
      <ul id="nav-mobile" class="right hide-on-med-and-down">
        <li><a href="/tags">Tags</a></li>
        <li><a href="/categories">Ita-Eng</a></li>
        <li><a href="/me">Me</a></li>
        <li><a href="/about">About</a></li>
        <li><a href="/contact">Contact</a></li>
      </ul>
    </div>
  </div>
</nav>

<div class="container">
  <a href="#" data-activates="slide-out" class="button-collapse top-nav full hide-on-large-only">
    <i class="material-icons">menu</i>
  </a>
</div>
<div id="slide-out" class="side-nav fixed">
  <div>
    <div class="userView thi-userView">
      <div class="background"></div>
        <a href="/">
          <img style="display:inherit;" class="circle z-depth-2" src="/assets/res/user.png">
        </a>
      <span style="font-size: larger;" class="white-text name">Paolo Avogadro</span>
      <span class="white-text email"><a style="color: #bdbdbd;" href="http://"></a></span>
    </div>
  </div>
  <div style="padding: 10px;">
    <form action="/search" method="get">
      <input class="search-sidebar" type="search" name="q"  placeholder="search something?" autofocus>
      <input type="submit" value="Search" style="display: none;">
    </form>
  </div>
  <div id="toc-bar">
    <div class="toc-bar-title">
      In this post
    </div>
    <ol id="toc-sidebar">
  <li><a href="#feed-forward-neural-network">Feed Forward Neural Network</a>
    <ol>
      <li><a href="#il-modello">il Modello</a></li>
      <li><a href="#criterion-e-optimizer">Criterion e Optimizer</a></li>
      <li><a href="#training-loop">Training loop</a></li>
      <li><a href="#test-loop">Test Loop</a></li>
      <li><a href="#prove-sul-modello">Prove sul modello</a></li>
      <li><a href="#prova-senza-funzioni-di-attivazione-e-un-modello-lineare">Prova senza funzioni di attivazione: e’ un modello lineare!</a></li>
    </ol>
  </li>
</ol>

  </div>
</div>
  
</header>
<main>
  <div class="container">
    <div id="post-info">
      <h3>Pytorch 4 Feed Forward Neural Network</h3>
      <span>
        Posted on
        <span style="display: initial;" class="cat-class">15/10/2021</span>,
        in
        
          
          
            <a class="cat-class cat-commas" href="/categories#italiano">Italiano</a>.
          
        
        <span class="reading-time" title="Estimated read time">
  
  
  <font size="2"> Reading time: 31 mins </font>
  
</span>

      </span>
    </div>

    <div class="divider"></div>
    <div class="row thi-post">
      <div class="col s12">
        <div id="toc">
  <div class="toc-title">
    <i class="material-icons mat-icon">toc</i><span>In this post</span>
  </div>
  <div id="full">
<ul id="markdown-toc">
  <li><a href="#feed-forward-neural-network" id="markdown-toc-feed-forward-neural-network">Feed Forward Neural Network</a>    <ul>
      <li><a href="#il-modello" id="markdown-toc-il-modello">il Modello</a></li>
      <li><a href="#criterion-e-optimizer" id="markdown-toc-criterion-e-optimizer">Criterion e Optimizer</a></li>
      <li><a href="#training-loop" id="markdown-toc-training-loop">Training loop</a></li>
      <li><a href="#test-loop" id="markdown-toc-test-loop">Test Loop</a></li>
      <li><a href="#prove-sul-modello" id="markdown-toc-prove-sul-modello">Prove sul modello</a></li>
      <li><a href="#prova-senza-funzioni-di-attivazione-e-un-modello-lineare" id="markdown-toc-prova-senza-funzioni-di-attivazione-e-un-modello-lineare">Prova senza funzioni di attivazione: e’ un modello lineare!</a></li>
    </ul>
  </li>
</ul>

  </div>
</div>

<p>Indice Globale degli argomenti tra i vari post:</p>
<ul>
  <li><strong><a href="/Pytorch-1">Indice degli argomenti</a></strong>.</li>
  <li><strong><a href="/Pytorch-1">Introduzione e fonti</a></strong>.</li>
  <li><strong><a href="/Pytorch-1">Lingo - Gergo utilizzato</a></strong>.</li>
  <li><strong><a href="/Pytorch-1">Tensori in Pytorch</a></strong>.</li>
  <li><strong><a href="/Pytorch-2">Grafo Computazionale e Calcolo dei Gradienti con Autograd</a></strong>.</li>
  <li><strong><a href="/Pytorch-2">Backpropagation introduzione</a></strong>.</li>
  <li><strong><a href="/Pytorch-3">Loss e optimizer</a></strong>.</li>
  <li><strong><a href="/Pytorch-3">Dataset e Dataloader</a></strong>.</li>
  <li><strong><a href="/Pytorch-3">Modelli di Pytorch</a></strong>.</li>
  <li><strong><a href="/Pytorch-3">Dataset Transforms</a></strong>.</li>
  <li><strong><a href="/Pytorch-3">Softmax</a></strong>.</li>
  <li><strong><a href="/Pytorch-3">Activation Function</a></strong>.</li>
  <li><strong><a href="/Pytorch-4">Feed Forward Neural Network</a></strong>.</li>
  <li><strong><a href="/Pytorch-5">Convolutional Neural Network</a></strong>.</li>
  <li><strong><a href="/Pytorch-5">Transfer Learning</a></strong>.</li>
  <li><strong><a href="/Pytorch-5">Tensorboard</a></strong>.</li>
  <li><strong><a href="/Pytorch-6">I/O Saving and Loading Models</a></strong>.</li>
  <li><strong><a href="/Pytorch-7">Recurrent Neural Networks</a></strong>.</li>
  <li><strong><a href="/Pytorch-7">RNN, GRU e LSTM</a></strong>.</li>
  <li><strong><a href="/Pytorch-8">Pytorch Lightning</a></strong>.</li>
  <li><strong><a href="/Pytorch-8">LR Scheduler</a></strong>.</li>
  <li><strong><a href="/Pytorch-9">Autoencoder</a></strong>.</li>
</ul>

<h1 id="feed-forward-neural-network">Feed Forward Neural Network</h1>
<p>Questo e’ il primo esempio di rete neurale funzionante. Nota che qui NON vengono fatti i passaggi preliminari per conoscere la struttura del datset, per vedere se le classi sono bilanciate, o per fare delle trasformazioni. L’ipotesi di partenza e’ che il dataset sia ok.</p>

<p><code class="language-plaintext highlighter-rouge">Scopo</code>:<br /></p>
<ul>
  <li>costruire una fully connected neural network con 1 hidden layer (Feed Forward: una volta fatto il passo il lavoro e’ finito).</li>
  <li>per il riconoscimento di immagini del dataset MNIST  (sono i numeri da 0 a 9 scritti a mano da varie persone, in immagini 28 x28 pixel con un solo canale di colore)</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">Metodo</code>:<br /></p>

<ol>
  <li>Dataset e Dataloader:
    <ul>
      <li>Si importa un dataset, per esempio: <code class="language-plaintext highlighter-rouge">torchvision.datasets.MNIST(...)</code></li>
      <li>Si creano 2 dataloader, uno per il train e uno per il test, per esempio: <code class="language-plaintext highlighter-rouge">torch.utils.data.DataLoader(...)</code></li>
    </ul>
  </li>
  <li>Costruzione e istanziazione del modello:
    <ul>
      <li>si importa la classe <code class="language-plaintext highlighter-rouge">nn.Model</code>, a cui si devono poter passare come parametri le dimensioni dei tensori iniziali, hidden e output…</li>
      <li>in nn.Model, all’interno del metodo <code class="language-plaintext highlighter-rouge">__init__</code> si costruiscono i metodi e gli attributi che serviranno al grafo computazionale (per esempio <code class="language-plaintext highlighter-rouge">self.l1= nn.Linear</code>, <code class="language-plaintext highlighter-rouge">self.n_output= n_output</code>…)</li>
      <li>in nn.Model si definiscono anche le ReLU, SoftMax, ecc  <code class="language-plaintext highlighter-rouge">self.relu= nn.ReLU()</code></li>
      <li>eventualmente gli oggetti vengono mandati sul device: <code class="language-plaintext highlighter-rouge">.to(device)</code></li>
      <li>in nn.Model si costruisce il metodo <code class="language-plaintext highlighter-rouge">forward()</code> (il nome deve essere proprio forward) in cui si mettono i vari passaggi costruire il <code class="language-plaintext highlighter-rouge">grafo computazionale</code></li>
      <li>Finita la costruzione del modello se ne fa un’istanza passando come argomenti i valori corretti delle dimensioni dei tensori</li>
      <li>si usa il metodo per mandare il modello sulla GPU: <code class="language-plaintext highlighter-rouge">modello = NeuralNet(input_size,...).to(device)</code>  in modo che sia sulla <code class="language-plaintext highlighter-rouge">GPU</code></li>
    </ul>
  </li>
  <li>Scelta della funzione di loss (<code class="language-plaintext highlighter-rouge">criterion</code>) e del metodo di ottimizzazione (<code class="language-plaintext highlighter-rouge">optimizer</code>)
    <ul>
      <li>si sceglie una funzione di loss (che per esempio possiamo chiamare <code class="language-plaintext highlighter-rouge">criterion</code>) (occhio che la CrossEntropy include gia’ softmax)</li>
      <li>si applica <code class="language-plaintext highlighter-rouge">optimizer.zero_grad()</code> per evitare che l’ottimizzatore entri nel grafo computazionale</li>
      <li>ci si ricorda di</li>
      <li><code class="language-plaintext highlighter-rouge">loss.backwards()</code> costruisce i gradienti rispetto ai pesi (che hanno autograd =True) tramite la chain rule. Il gradiente della loss serve poi per l’ottimizzazione</li>
      <li>si sceglie una funzione di ottimizzazione <code class="language-plaintext highlighter-rouge">optimizer</code>:  SGD, Adam, … : per esempio: <code class="language-plaintext highlighter-rouge">optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)</code> Nota che bisogna passare i parametri del modello che vengono ottenuti tramite <code class="language-plaintext highlighter-rouge">model.parameters()</code>, perche’ l’ottimizzatore sappia cosa deve modificare.</li>
      <li><code class="language-plaintext highlighter-rouge">optimizer.step()</code> fa un passo nella direzione dell’ottimizzazione in funzione del learning rate.</li>
    </ul>
  </li>
  <li>Loop sulle epoche e sui batch.
    <ul>
      <li>si fa un loop sulle epoche (sceglo io quante).</li>
      <li>si fa un loop per tutti i batch di ogni epoca.</li>
      <li>con <code class="language-plaintext highlighter-rouge">enumerate</code> si spacchettano le immagini e le label dal dataloader.</li>
      <li>si usa <code class="language-plaintext highlighter-rouge">view</code> o <code class="language-plaintext highlighter-rouge">reshape</code> per trasformare gli oggetti in 1D (il risultato e’ lo stesso)</li>
      <li><strong>NON chiaro</strong>, che differnza c’e’ tra passare un’immagine e un batch di immagini al modello? come viene gestito?</li>
      <li><strong>NON</strong> si chiama <code class="language-plaintext highlighter-rouge">forward</code>, ma si passano gli oggetti da classificare al <code class="language-plaintext highlighter-rouge">modello</code> (perche’ il modello nn.Model ha gia’ implementato un metodo <code class="language-plaintext highlighter-rouge">__call__</code> e questo in pratica fa si che quando si chiami il modello come se fosse una funzione, allora si fa entrare in azione il metodo <code class="language-plaintext highlighter-rouge">forward</code>)</li>
      <li>si crea una <code class="language-plaintext highlighter-rouge">loss= criterion(output, labels)</code>  (posso comodamente cambiare la loss cambiando il criterio)</li>
      <li><code class="language-plaintext highlighter-rouge">optimizer.zero_grad()</code> ci si assicura che la backpropagation e l’ottimizzazione non modifichino i gradienti. Si evita quindi che entrino nel grafo computazionale.</li>
      <li>si costruisce la chain rule con:  <code class="language-plaintext highlighter-rouge">loss.backward()</code></li>
      <li>si ottimizzano i pesi usando un metodo del criterio di ottimizzazione: <code class="language-plaintext highlighter-rouge">criterion.step()</code></li>
    </ul>
  </li>
  <li>Si fa la validazione del modello tramite il test set
    <ul>
      <li>in questo caso si vuole evitare che i gradienti vengano fatti: <code class="language-plaintext highlighter-rouge">with torch.no_grad()</code></li>
      <li>si fanno i loop su tutti i batch (non ha senso sulle epoche) del test dataloader</li>
      <li>si usano delle metriche, per esempio l’<code class="language-plaintext highlighter-rouge">accuracy</code>.</li>
    </ul>
  </li>
</ol>

<p>Note:</p>
<ul>
  <li>Per supporto <code class="language-plaintext highlighter-rouge">GPU</code> si costruisce un oggetto device come alla riga 8</li>
  <li>piu’ tardi si fara’ un push to device, ottenuto sia per il modello che per i tensori tramite il metodo <code class="language-plaintext highlighter-rouge">.to(device)</code> (con l’oggetto device opportunamente definito prima, riga 8.</li>
  <li>Occhio che <strong>non esiste</strong> “transform.ToTensor” ma “transforms”.ToTensor con una <strong>s</strong> dopo transform!!!! python mi dava errore: non esiste transform, ma l’errore era una semplice dimenticanza.</li>
  <li>nota che la prima volta che carico il dataset ci mette un po’, la seconda volta MOLTO meno (lo mette da qualche parte in memoria forse)</li>
</ul>

<p>All’inizio ci serve l’oggetto <code class="language-plaintext highlighter-rouge">Module</code> preso da <code class="language-plaintext highlighter-rouge">nn</code>. Questo oggetto e’ una specie di contenitore che connette le varie parti di una rete neurale.</p>

<p>Un layer fully connected da nn.Module ha bisogno di 3 parametri:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">input size</code> (numero di punti dell’immagine)</li>
  <li><code class="language-plaintext highlighter-rouge">hidden size</code> (numero di nodi nascosti)</li>
  <li><code class="language-plaintext highlighter-rouge">output size</code> (in questo caso sono le classi in uscita che voglio trovare).</li>
</ul>

<p>Ricordiamoci di chiamare il metodo <code class="language-plaintext highlighter-rouge">super</code>. Questo mi consente di poter usare i metodi della superclass (la classe che ho ereditato) senza dover riscriverli da zero. Una buona spiegazione: https://realpython.com/python-super/</p>

<p>Il metodo forward ha 2 argomenti: <code class="language-plaintext highlighter-rouge">self</code> e <code class="language-plaintext highlighter-rouge">x</code></p>
<ul>
  <li>self serve perche’ siamo dentro la classe e vogliamo accedere a tutti gli della istanza</li>
  <li>x e’ invece l’immagine (il batch di immagini) che vogliamo catalogare</li>
</ul>

<p>posso prendere invece che self.relu   nn.ReLU ? (provare)</p>

<ul>
  <li>Non applico la softmax alla fine perche’ la cross entropy 
ha gia’ la softmax incorporata</li>
</ul>

<p>Forward pass: ho un problema mi dice che non sono allineati gli oggetti
su cpu e gpu, in particolare dice che :</p>
<ul>
  <li>out e’ su CPU</li>
  <li>il tensore passato come argomento uno al modello e’ su CPU</li>
  <li>ma lui se li aspetta sulla GPU</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">RISOLTO</code>: dovevo usare il metodo to.(device) quando istanziavo il modello! (riga 17 del modello)
Attento che lui nel video non lo faceva (probabilmente perche’ ha piu’ volte detto che il suo laptop non ha supporto GPU, quindi ovunque lui mandi qualcosa su device, resta su cpu)!</p>

<p>Nel seguito, prima spezzo in varie celle i passaggi, e poi per ultimo costruisco una cella con tutti i passaggi congiunti in modo da avere un luogo dove fare qualche esperimento.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1"># device config
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span><span class="p">)</span>   <span class="c1"># device, dove mandare i vari oggetti 
</span>
<span class="c1"># Hyper parametri 
</span><span class="n">input_size</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>    <span class="c1">#  =784 sono le dimensioni delle immagini
</span><span class="n">hidden_size</span>  <span class="o">=</span> <span class="mi">1000</span>   <span class="c1">#  scelto da me, e' la dimensione della hidden layer
</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>      <span class="c1">#  devo classificare immagini di numeri da 0 a 9, quindi la dimensione dell'output =10
</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">2</span>        <span class="c1">#  faccio 2 giri completi sul dataset di train
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>      <span class="c1">#  questo no so come sia stato scelto, comunque posso modificare
</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1">#  piccolo (potrei poi usare delle funzioni per cambiare questo parametro durante l'evoluzione)
</span>
<span class="c1">#carico i dataset MNIST
#  root e' dove viene messo il dataset quando viene caricato 
#  gli diciamo poi che e' un dataset usato per il _training_
#  Occhio che poi quando facciamo train=False per costruire il dataset di test, lui splitta automaticamente
#  mi domando in quale percentuale. 
#  Trasformiamo le immagini facendo diventare le immagini in tensori
#  lo scarico se non e' gia' nella dir data
</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span> <span class="s">'./data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span> <span class="bp">True</span><span class="p">,</span> 
                                           <span class="n">transform</span> <span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                          <span class="n">download</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span> <span class="s">'./data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span> 
                                           <span class="n">transform</span> <span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                          <span class="n">download</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span> <span class="c1"># ho gia' scaricato tutto con il train_datast
</span>

<span class="c1"># costruisco i dataloader:
#DataLoader necessita di almeno 2 parametri:
#  il nome del dataset
#  il la dimensione del batch
#  poi si fa shuffle = True/False
</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span> <span class="p">(</span><span class="n">dataset</span><span class="o">=</span>  <span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">## guardiamo un batch dei dati:
</span>
<span class="n">examples</span> <span class="o">=</span>  <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="nb">next</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1">### nota che la dimensione dei sample e' la seguente
# 100  = numero di immagini nel batch (se non metti batch_size, di default vale 1)
#   1  = numero di canali solitamente i colori
#  28  =  numero di ingressi sull'asse delle x
#  28  = numero di ingressi sull'asse delle y
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([100, 1, 28, 28]) torch.Size([100])
</code></pre></div></div>

<p>qui disegno i sample, ricorda che subplot, indica la struttra, righe e colonne e poi l’indice dice quale di questi e’.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>     <span class="c1"># i primi parametri indicano 2 righe e 3 colonne, e poi il numero dell'immagine corrente.
</span>    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span> <span class="s">'gray'</span><span class="p">)</span>  <span class="c1"># occhio che c'e' solo samples[i][0], le label sono state messe in labels.
</span>
</code></pre></div></div>

<p><img src="/images/posts/pytorch/output_64_0.png" alt="png" /></p>

<h2 id="il-modello">il Modello</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># qui costruisco il modello: e' una classe
</span>
<span class="k">class</span> <span class="nc">NeuralNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>                                    <span class="c1"># lo chiamo NeuralNet e lo importo da nn.Module
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>  <span class="c1"># il costruttore
</span>        <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>                      <span class="c1"># super per ereditare da nn.Module
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>           <span class="c1"># L MAIUSCOLA per Linear
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>                                  <span class="c1"># funzione di attivazione ReLU 
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>          <span class="c1"># secondo(ultimo) strato fully connected
</span>       
    <span class="k">def</span> <span class="nf">forward</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>    <span class="c1"># l'argomento self indica che viene lanciato su se stessi, la x e' il batch di immagini
</span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>      <span class="c1"># sfrutto il metodo self.l1 a cui ho gia' dato dei parametri prima
</span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># ReLU non aveva bisogno di parametri: posso prendere nn.ReLU ?
</span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>            <span class="c1"># DEVE restituire qualcosa: l'output
</span>    

<span class="c1"># qui creo una istanza del modello:
</span><span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNet</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="criterion-e-optimizer">Criterion e Optimizer</h2>
<ul>
  <li>Qui sotto costruisco la funzione di <strong>LOSS</strong></li>
  <li>Poi costruisco l’<strong>optimizer</strong>, ovvero il metodo che mi “aggiusta” i pesi della rete neurale secondo determinati schemi. Attento, devo passare degli argomeni all’optimizer.
In particolare c’e’ un metodo del modello che si chiama <code class="language-plaintext highlighter-rouge">model.parameters()</code></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">criterion</span>  <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>                                    <span class="c1"># non ha bisogno di parametri
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">)</span>  <span class="c1"># qui devo passare i parametri del modello!
</span></code></pre></div></div>

<h2 id="training-loop">Training loop</h2>
<p>Qui sotto faccio il training che e’ composto da un loop esterno <code class="language-plaintext highlighter-rouge">epoch</code> e uno interno sui <code class="language-plaintext highlighter-rouge">batch</code> della singola epoch.</p>

<p><code class="language-plaintext highlighter-rouge">Osservazioni</code>:</p>

<ul>
  <li>Il loop sui batches e’ fatto in modo interessante, con <code class="language-plaintext highlighter-rouge">enumerate(dataloader)</code>. In questo modo ho un indice che mi dice in quale batch sono, inoltre ho creato una tupla contenente sia l’immagine che la corrispondente label (tra tonde)</li>
  <li>devo mandare sia le immagini che le label sul device <code class="language-plaintext highlighter-rouge">.to(device)</code></li>
  <li>uso il modello, non uso il metodo del modello (se faccio model.forward() cosa succede? niente funziona allo stesso modo!)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_total_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>                  <span class="c1"># Loop sulle epochs
</span>   <span class="c1"># for steps in range(n_total_steps):           # loops sui batches 
</span>   <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span><span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span> <span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>   <span class="c1"># loop sui batch     
</span>        <span class="c1"># 100, 1, 28, 28  (batch, canali, x, y) forma del tensore images
</span>        <span class="c1"># 100, 28x28=784  forma voluta dall'hidden layer
</span>        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>     <span class="c1">#usando reshape con il -1
</span>        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># forward pass
</span>        <span class="c1"># print (images.is_cuda)        
</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span> <span class="p">(</span><span class="n">images</span><span class="p">)</span>        <span class="c1">#  non chiama il metodo forward: perche'?
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                 
        <span class="c1"># backward pass
</span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>   <span class="c1"># non voglio che vengano inseriti nel backward pass
</span>        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>          <span class="c1">#  &lt;========  fa tutto lui, calcola chain rule
</span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>         <span class="c1"># aggiorna i pesi
</span>        
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}'</span><span class="p">)</span>        
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>epoch 1 / 2, step 100/600, loss= 0.3839
epoch 1 / 2, step 200/600, loss= 0.2682
epoch 1 / 2, step 300/600, loss= 0.1468
epoch 1 / 2, step 400/600, loss= 0.1664
epoch 1 / 2, step 500/600, loss= 0.0730
epoch 1 / 2, step 600/600, loss= 0.1700
epoch 2 / 2, step 100/600, loss= 0.0749
epoch 2 / 2, step 200/600, loss= 0.2193
epoch 2 / 2, step 300/600, loss= 0.1413
epoch 2 / 2, step 400/600, loss= 0.0539
epoch 2 / 2, step 500/600, loss= 0.0470
epoch 2 / 2, step 600/600, loss= 0.0669
</code></pre></div></div>

<h2 id="test-loop">Test Loop</h2>
<p>qui calcolo l’accuracy con i dati di test.</p>

<ul>
  <li>La funzione <code class="language-plaintext highlighter-rouge">torch.max</code> restituisce: valori e l’indice. Noi vogliamo l’indice che e’ la classe.</li>
  <li>per calcolare il numero totale di immagini processate, conto il numero di righe in labels.</li>
  <li>per ogni predizione corretta aggiungo 1 “sum()” e estraggo dal tensore con item() (non chiarissimo il sum).</li>
  <li>nota la scrittura con l’  ==, quindi facciamo una specie di if “online”</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>    
    <span class="n">n_correct</span> <span class="o">=</span> <span class="mi">0</span>         <span class="c1"># numero di predizioni azzeccate
</span>    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">0</span>         <span class="c1"># ? 
</span>    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>   <span class="c1"># qui il modello e' gia' trainato!
</span>        
        <span class="n">_</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># prendo la classe che ha il valore massimo
</span>        <span class="n">n_samples</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="c1"># numero di samples nel batch corrente (nell'ultimo sono diversi spesso)
</span>        <span class="n">n_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
    <span class="n">acc</span> <span class="o">=</span> <span class="mf">100.0</span>  <span class="o">*</span> <span class="n">n_correct</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="c1"># accuratezza in percentuale
</span>    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'accuracy ={acc}'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>accuracy =97.07
</code></pre></div></div>

<h2 id="prove-sul-modello">Prove sul modello</h2>
<p>In questa cella faccio le mie varianti in modo da poter capire meglio i vari passaggi.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1"># device config
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span><span class="p">)</span>
<span class="c1">#device = torch.device('cpu')
</span>
<span class="c1"># Hyper parametri 
</span><span class="n">input_size</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>    <span class="c1">#  =784 sono le dimensioni delle immagini
</span><span class="n">hidden_size</span>  <span class="o">=</span> <span class="mi">2000</span>   <span class="c1">#  scelto da me
</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>      <span class="c1">#  devo classificare immagini di numeri
</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1</span>        <span class="c1">#  quanti giri completi vengono fatti
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>        <span class="c1">#  questo no so come sia stato scelto
</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1">#  piccolo
</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span> <span class="s">'./data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span> <span class="bp">True</span><span class="p">,</span> 
                                           <span class="n">transform</span> <span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                          <span class="n">download</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span> <span class="s">'./data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span> 
                                           <span class="n">transform</span> <span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                          <span class="n">download</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span> <span class="c1"># ho gia' scaricato tutto con il train_datast
</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span> <span class="p">(</span><span class="n">dataset</span><span class="o">=</span>  <span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">### nota che la dimensione dei sample e' la seguente
# 100  = numero di immagini nel batch (se non metti batch_size, di default vale 1)
#   1  = numero di canali solitamente i colori
#  28  =  numero di ingressi sull'asse delle x
#  28  = numero di ingressi sull'asse delle y
</span>
<span class="k">def</span> <span class="nf">myActiv</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>    <span class="c1"># e' difficile costruire delle funzioni di attivazioni CUSTOM (vedi sopra)
</span>    <span class="c1">#return 1. +x/10. + 0.5*(x/10.)**2+1./6.*(x/10.)**3
</span>    <span class="k">return</span>  <span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span>
        

<span class="c1">############  MODELLO ####################
# qui costruisco il modello: e' una classe
</span>
<span class="k">class</span> <span class="nc">NeuralNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>  <span class="c1"># L MAIUSCOLA
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">my</span> <span class="o">=</span> <span class="n">myActiv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
       
    <span class="k">def</span> <span class="nf">forward</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>      <span class="c1"># sfrutto il metodo self.l1 a cui ho gia' dato dei parametri prima
</span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># ReLU non aveva bisogno di parametri: posso prendere nn.ReLU ?
</span>        <span class="c1">#out = self.sigmoid(out)
</span>        <span class="c1">#out = self.softplus(out)
</span>        <span class="c1">#out = self.my(out)
</span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>            <span class="c1"># DEVE restituire qualcosa
</span>

<span class="c1">############### ISTANZIO MODELLO ########
</span><span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNet</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1">############### CRITERION E OPTIMIZER ###
</span><span class="n">criterion</span>  <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>   <span class="c1"># non ha bisogno di parametri
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">)</span>       <span class="c1"># qui devo passare i parametri del modello!
</span>
<span class="c1">############### TRAINING LOOP ############
</span><span class="n">n_total_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>


<span class="n">tot</span> <span class="o">=</span><span class="mi">0</span> <span class="c1"># PA
</span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>                  <span class="c1"># Loop sulle epoch  
</span>   <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span><span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span> <span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>   <span class="c1"># loop sui batch, uso enumerate cosi' so in che batch sono     
</span>        <span class="c1"># 100, 1, 28, 28  (batch, canali, x, y) forma del tensore images
</span>        <span class="c1"># 100, 28x28=784  forma voluta dall'hidden layer
</span>        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>     <span class="c1">#usando reshape con il -1
</span>        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              
        <span class="c1">#outputs = model (images)        #  non chiama il metodo forward: perche' nn.Model ha il __call__!
</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>        <span class="c1">#  non chiama il metodo forward: perche' nn.Model ha il __call__!
</span>        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="n">tot</span> <span class="o">=</span> <span class="n">tot</span><span class="o">+</span><span class="mi">1</span> <span class="c1"># PA per fare delle modifiche sul Learning Rate
</span>        <span class="k">if</span> <span class="p">(</span><span class="n">tot</span><span class="o">%</span><span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span> <span class="o">*</span><span class="mf">0.8</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'Learning rate {learning_rate}'</span><span class="p">)</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">)</span>
        
        
        <span class="c1"># backward pass
</span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>   <span class="c1"># non voglio che vengano inseriti nel backward pass
</span>        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>          <span class="c1">#  &lt;========  fa tutto lui, calcola chain rule
</span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>         <span class="c1"># aggiorna i pesi
</span>        
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'Epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}'</span><span class="p">)</span>        

            
<span class="c1">############ TEST LOOP #################
</span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>    
    <span class="n">n_correct</span> <span class="o">=</span> <span class="mi">0</span>         <span class="c1"># numero di predizioni azzeccate
</span>    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">0</span>         <span class="c1"># ? 
</span>    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>   <span class="c1"># qui il modello e' gia' trainato!
</span>        
        <span class="n">_</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># prendo la classe che ha il valore massimo
</span>        <span class="n">n_samples</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="c1"># numero di samples nel batch corrente (nell'ultimo sono diversi spesso)
</span>        <span class="n">n_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
    <span class="n">acc</span> <span class="o">=</span> <span class="mf">100.0</span>  <span class="o">*</span> <span class="n">n_correct</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="c1"># accuratezza in percentuale
</span>    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'accuracy ={acc}'</span><span class="p">)</span>            
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1 / 1, step 100/600, loss= 0.2884
Learning rate 0.0008
Epoch 1 / 1, step 200/600, loss= 0.1714
Epoch 1 / 1, step 300/600, loss= 0.1254
Learning rate 0.00064
Epoch 1 / 1, step 400/600, loss= 0.1586
Epoch 1 / 1, step 500/600, loss= 0.1043
Learning rate 0.0005120000000000001
Epoch 1 / 1, step 600/600, loss= 0.0829
accuracy =97.06
</code></pre></div></div>

<h2 id="prova-senza-funzioni-di-attivazione-e-un-modello-lineare">Prova senza funzioni di attivazione: e’ un modello lineare!</h2>
<p>Questi sono i risultati ottenuti quando elimino la activation function e lascio solo il
modello lineare sottostante, dove c’e’ il primo passo la fully connected tra le immagini e lo strato hidden
e dallo strato hidden all’output. I risultati sono in funzione di vari parametri variati.
Con questo dataset i risultati non sono male, si hanno delle  buone accuracy a condizione che 
il numero di neuroni sia paragonabile (anche 4 e’ sufficiente!) al numero di possibili output.</p>

<p>Nota pero’ che comunque ho la softmax finale per la cross entropy come loss.</p>

<ul>
  <li>senza attivazione: accuracy = 91.28    hidden_size  =2000 epoch =1</li>
  <li>senza attivazione: accuracy = 90.69    hidden_size  =10   epoch =1</li>
  <li>senza attivazione: accuracy = 92.54    hidden_size  =10   epoch =4</li>
  <li>senza attivazione: accuracy = 38.22    hidden_size  =1    epoch =4</li>
  <li>senza attivazione: accuracy = 41.95    hidden_size  =1    epoch =14</li>
  <li>senza attivazione: accuracy = 67.53    hidden_size  =2    epoch =4</li>
  <li>senza attivazione: accuracy = 86.04    hidden_size  =4    epoch =4</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1"># device config
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span><span class="p">)</span>
<span class="c1">#device = torch.device('cpu')
</span>
<span class="c1"># Hyper parametri 
</span><span class="n">input_size</span> <span class="o">=</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span>    <span class="c1">#  =784 sono le dimensioni delle immagini
</span><span class="n">hidden_size</span>  <span class="o">=</span> <span class="mi">4</span>      <span class="c1">#  scelto da me
</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>      <span class="c1">#  devo classificare immagini di numeri
</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">4</span>        <span class="c1">#  quanti giri completi vengono fatti
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>        <span class="c1">#  questo no so come sia stato scelto
</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1">#  piccolo
</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span> <span class="s">'./data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span> <span class="bp">True</span><span class="p">,</span> 
                                           <span class="n">transform</span> <span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                          <span class="n">download</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span> <span class="s">'./data/'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span> 
                                           <span class="n">transform</span> <span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                          <span class="n">download</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span> <span class="c1"># ho gia' scaricato tutto con il train_datast
</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span> <span class="p">(</span><span class="n">dataset</span><span class="o">=</span>  <span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">### nota che la dimensione dei sample e' la seguente
# 100  = numero di immagini nel batch (se non metti batch_size, di default vale 1)
#   1  = numero di canali solitamente i colori
#  28  =  numero di ingressi sull'asse delle x
#  28  = numero di ingressi sull'asse delle y
</span>
<span class="k">def</span> <span class="nf">myActiv</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>    <span class="c1"># e' difficile costruire delle funzioni di attivazioni CUSTOM (vedi sopra)
</span>    <span class="c1">#return 1. +x/10. + 0.5*(x/10.)**2+1./6.*(x/10.)**3
</span>    <span class="k">return</span>  <span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span>
        

<span class="c1">############  MODELLO ####################
# qui costruisco il modello: e' una classe
</span>
<span class="k">class</span> <span class="nc">NeuralNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>  <span class="c1"># L MAIUSCOLA
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
       
    <span class="k">def</span> <span class="nf">forward</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>      <span class="c1"># sfrutto il metodo self.l1 a cui ho gia' dato dei parametri prima
</span>        <span class="c1">#out = self.relu(out)  # ReLU non aveva bisogno di parametri: posso prendere nn.ReLU ?
</span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>            <span class="c1"># DEVE restituire qualcosa
</span>

<span class="c1">############### ISTANZIO MODELLO ########
</span><span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNet</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1">############### CRITERION E OPTIMIZER ###
</span><span class="n">criterion</span>  <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>   <span class="c1"># non ha bisogno di parametri
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">)</span>       <span class="c1"># qui devo passare i parametri del modello!
</span>
<span class="c1">############### TRAINING LOOP ############
</span><span class="n">n_total_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>                  <span class="c1"># Loop sulle epoch  
</span>   <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span><span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span> <span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>   <span class="c1"># loop sui batch, uso enumerate cosi' so in che batch sono     
</span>        <span class="c1"># 100, 1, 28, 28  (batch, canali, x, y) forma del tensore images
</span>        <span class="c1"># 100, 28x28=784  forma voluta dall'hidden layer
</span>        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>     <span class="c1">#usando reshape con il -1
</span>        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
              
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span> <span class="p">(</span><span class="n">images</span><span class="p">)</span>        <span class="c1">#  non chiama il metodo forward: perche'?
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                 
        <span class="c1"># backward pass
</span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>   <span class="c1"># non voglio che vengano inseriti nel backward pass
</span>        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>          <span class="c1">#  &lt;========  fa tutto lui, calcola chain rule
</span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>         <span class="c1"># aggiorna i pesi
</span>        
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}'</span><span class="p">)</span>        

            
<span class="c1">############ TEST LOOP #################
</span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>    
    <span class="n">n_correct</span> <span class="o">=</span> <span class="mi">0</span>         <span class="c1"># numero di predizioni azzeccate
</span>    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">0</span>         <span class="c1"># ? 
</span>    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>   <span class="c1"># qui il modello e' gia' trainato!
</span>        
        <span class="n">_</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># prendo la classe che ha il valore massimo
</span>        <span class="n">n_samples</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>          <span class="c1"># numero di samples nel batch corrente (nell'ultimo sono diversi spesso)
</span>        <span class="n">n_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
    <span class="n">acc</span> <span class="o">=</span> <span class="mf">100.0</span>  <span class="o">*</span> <span class="n">n_correct</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="c1"># accuratezza in percentuale
</span>    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'accuracy ={acc}'</span><span class="p">)</span>            
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>epoch 1 / 4, step 100/600, loss= 1.4573
epoch 1 / 4, step 200/600, loss= 1.0294
epoch 1 / 4, step 300/600, loss= 0.8547
epoch 1 / 4, step 400/600, loss= 0.6365
epoch 1 / 4, step 500/600, loss= 0.4938
epoch 1 / 4, step 600/600, loss= 0.6704
epoch 2 / 4, step 100/600, loss= 0.5902
epoch 2 / 4, step 200/600, loss= 0.4542
epoch 2 / 4, step 300/600, loss= 0.5579
epoch 2 / 4, step 400/600, loss= 0.7067
epoch 2 / 4, step 500/600, loss= 0.4833
epoch 2 / 4, step 600/600, loss= 0.6566
epoch 3 / 4, step 100/600, loss= 0.6494
epoch 3 / 4, step 200/600, loss= 0.4046
epoch 3 / 4, step 300/600, loss= 0.7297
epoch 3 / 4, step 400/600, loss= 0.3742
epoch 3 / 4, step 500/600, loss= 0.4305
epoch 3 / 4, step 600/600, loss= 0.4805
epoch 4 / 4, step 100/600, loss= 0.6506
epoch 4 / 4, step 200/600, loss= 0.3813
epoch 4 / 4, step 300/600, loss= 0.3637
epoch 4 / 4, step 400/600, loss= 0.6228
epoch 4 / 4, step 500/600, loss= 0.5557
epoch 4 / 4, step 600/600, loss= 0.5079
accuracy =86.55
</code></pre></div></div>


      </div>
    </div>

    <div class="tag-list">
      
      
      
      <a class="tag-chip" href="/tags#python_cap"><div class="chip z-depth-1">Python</div></a>
      
      
      
      <a class="tag-chip" href="/tags#deeplearning_cap"><div class="chip z-depth-1">DeepLearning</div></a>
      
      
      
      <a class="tag-chip" href="/tags#neural-nets_cap"><div class="chip z-depth-1">Neural Nets</div></a>
      
      
      
      <a class="tag-chip" href="/tags#cuda_cap"><div class="chip z-depth-1">Cuda</div></a>
      
    </div>
    
          <style type="text/css">
.related-posts{
  border: 3px dotted #2e87e7;
  border-radius: 5px;
  margin: 20px 0;
  padding: 10px 10px 0 10px;
}
.related-posts span{
  font-size: 130%;
  font-weight: 500;
  color: #2e87e7;
}
.related-posts ul{
  margin-top: 5px!important;
}
.thi-icon{
  float: left;
  line-height: inherit;
  margin-right: 5px;
  margin-left: 2px;
  color: #2e87e7;
}
</style>

<div class="related-posts">
  <i class="material-icons thi-icon">grade</i><span>You might also like ...</span>
  
  <ul>
    
    
      
      
        
          <li>
            <a href="/Pytorch-7">
              Pytorch 7 Recurrent Neural Network
            </a>
            <small>17 Oct 2021</small>
          </li>
          
          
    
      
      
        
          <li>
            <a href="/Pytorch-1">
              Pytorch 1 Inizio, Tensori
            </a>
            <small>17 Oct 2021</small>
          </li>
          
          
    
      
      
        
          <li>
            <a href="/Pytorch-9">
              Pytorch 9 Autoencoder
            </a>
            <small>15 Oct 2021</small>
          </li>
          
          
    
      
      
        
          <li>
            <a href="/Pytorch-8">
              Pytorch 8 Lightning
            </a>
            <small>15 Oct 2021</small>
          </li>
          
          
    
      
        

    
    
  </ul>
</div>

    
    		
			<script src="  https://unpkg.com/showdown/dist/showdown.min.js"></script>
<script>
const GH_API_URL = 'https://api.github.com/repos/4phycs/4phycs.github.io/issues/21/comments';

let request = new XMLHttpRequest();
request.open( 'GET', GH_API_URL, true );
request.onload = function() {
	if ( this.status >= 200 && this.status < 400 ) {
		let response = JSON.parse( this.response );

		for ( var i = 0; i < response.length; i++ ) {
			document.getElementById( 'gh-comments-list' ).appendChild( createCommentEl( response[ i ] ) );
		}

		if ( 0 === response.length ) {
			document.getElementById( 'no-comments-found' ).style.display = 'block';
		}
	} else {
		console.error( this );
	}
};

function createCommentEl( response ) {
	let user = document.createElement( 'a' );
	user.setAttribute( 'href', response.user.url.replace( 'api.github.com/users', 'github.com' ) );
	user.classList.add( 'user' );

	let userAvatar = document.createElement( 'img' );
	userAvatar.classList.add( 'avatar' );
	userAvatar.setAttribute( 'src', response.user.avatar_url );

	user.appendChild( userAvatar );

	let commentLink = document.createElement( 'a' );
	commentLink.setAttribute( 'href', response.html_url );
	commentLink.classList.add( 'comment-url' );
	commentLink.innerHTML = '#' + response.id + ' - ' + response.created_at;

	let commentContents = document.createElement( 'div' );
	commentContents.classList.add( 'comment-content' );
	commentContents.innerHTML = response.body;
	// Progressive enhancement.
	if ( window.showdown ) {
		let converter = new showdown.Converter();
		commentContents.innerHTML = converter.makeHtml( response.body );
	}

	let comment = document.createElement( 'li' );
	comment.setAttribute( 'data-created', response.created_at );
	comment.setAttribute( 'data-author-avatar', response.user.avatar_url );
	comment.setAttribute( 'data-user-url', response.user.url );

	comment.appendChild( user );
	comment.appendChild( commentContents );
	comment.appendChild( commentLink );

	return comment;
}
request.send();
</script>

<hr>

<div class="github-comments">
	<h2>Comments</h2>
	<ul id="gh-comments-list"></ul>
	<div class="buttonArea">
	  <a target="_blank" href="https://github.com/4phycs/4phycs.github.io/issues/21"class="button">Add comment (via Github)</a>
	</div>
</div>


		
 
  </div>
</main>

	<script src="/assets/js/jquery-1.11.0.min.js"></script>
<script type="text/javascript">
  jQuery(document).ready(function($){
    // browser window scroll (in pixels) after which the "back to top" link is shown
    var offset = 300,
      //browser window scroll (in pixels) after which the "back to top" link opacity is reduced
      offset_opacity = 1200,
      //duration of the top scrolling animation (in ms)
      scroll_top_duration = 700,
      //grab the "back to top" link
      $back_to_top = $('.cd-top');

    //hide or show the "back to top" link
    $(window).scroll(function(){
      ( $(this).scrollTop() > offset ) ? $back_to_top.addClass('cd-is-visible') : $back_to_top.removeClass('cd-is-visible cd-fade-out');
      // if( $(this).scrollTop() > offset_opacity ) { 
      //  $back_to_top.addClass('cd-fade-out');
      // }
    });

    //smooth scroll to top
    $back_to_top.on('click', function(event){
      event.preventDefault();
      $('body,html').animate({
        scrollTop: 0 ,
        }, scroll_top_duration
      );
    });

  });
</script>
<style type="text/css">
.cd-top {
  display: inline-block;
  height: 50px;
  width: 50px;
  position: fixed;
  bottom: 2%;
  right: 2%;
  border-radius: 40px;
  box-shadow: 0 0 10px rgba(0, 0, 0, 0.05);
  /* image replacement properties */
  overflow: hidden;
  text-indent: 100%;
  white-space: nowrap;
  background: #bbb url(/images/cd-top-arrow.svg) no-repeat center 50%;
  visibility: hidden;
  opacity: 0;
  -webkit-transition: opacity .3s 0s, visibility 0s .3s;
  -moz-transition: opacity .3s 0s, visibility 0s .3s;
  transition: opacity .3s 0s, visibility 0s .3s;
}
.cd-top.cd-is-visible, .cd-top.cd-fade-out, .no-touch .cd-top:hover {
  -webkit-transition: opacity .3s 0s, visibility 0s 0s;
  -moz-transition: opacity .3s 0s, visibility 0s 0s;
  transition: opacity .3s 0s, visibility 0s 0s;
}
.cd-top.cd-is-visible {
  /* the button becomes visible */
  visibility: visible;
  opacity: 1;
}
.cd-top.cd-fade-out {
  /* if the user keeps scrolling down, the button is out of focus and becomes less visible */
  opacity: .5;
}
.no-touch .cd-top:hover {
  background-color: #e86256;
  opacity: 1;
}
</style>

<a href="#0" class="cd-top">Top</a>
	<footer class="page-footer light-blue accent-4">  
  <div class="footer-copyright">
    <div class="container text-white">
     <a href="">4Phycs</a> &#xA9; 2021 Inherited from <a href="https://shawnteoh.github.io/matjek/">MatJeck</a>.
    </div>
  </div>
</footer>

<script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/js/materialize.min.js"></script>


  
    <script src="/assets/js/post.js"></script>
  





<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})
  (window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>

<script src="/assets/js/main.js"></script>

        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158698892-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-158698892-1');
</script>

</body>
</html>
