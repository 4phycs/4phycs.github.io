<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <link href="https://fonts.googleapis.com/css?family=Maven+Pro:400,500&amp;subset=latin-ext,vietnamese" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Dancing+Script:400,700&amp;subset=vietnamese" rel="stylesheet">
  <meta name="google-site-verification" content="8zqeFQNuNAWS7ye6oN69hdEeYC_RsDyAlhht79xtAQo" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:image" content="/assets/res/banner.png" />

  

  <title>
    
      Search on this page | 4Phycs
    
  </title>

  

  <!-- page's cover -->
  
    <meta property="og:image" content="http://localhost:4000/images/defaultCoverPost.png" />
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1234">
    <meta property="og:image:height" content="592">
  

  

  <link rel="shortcut icon" type="image/x-icon" href="/assets/res/favicon.png">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/css/materialize.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="/assets/css/main.css">

  <link rel="stylesheet" href="/assets/css/thi_scss.css">

  
    
      <link rel="stylesheet" href="/assets/css/page.css">
    
  

  
    
      <link rel="stylesheet" href="/assets/css/page.css">
    
  
    
      <link rel="stylesheet" href="/assets/css/search.css">
    
  

  <link rel="stylesheet" href="/assets/css/syntax.css">
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml">
  <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml">
  
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Search on this page" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="my ideas and notes, and useful stuff." />
<meta property="og:description" content="my ideas and notes, and useful stuff." />
<link rel="canonical" href="http://localhost:4000/search" />
<meta property="og:url" content="http://localhost:4000/search" />
<meta property="og:site_name" content="4Phycs" />
<meta name="google-site-verification" content="" />
<script type="application/ld+json">
{"headline":"Search on this page","description":"my ideas and notes, and useful stuff.","@type":"WebPage","url":"http://localhost:4000/search","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body>
	<header>
	
		<nav class="top-nav light-blue darken-4">
  <div class="nav-wrapper">
    <div class="container">
      <a class="page-title font-title" href="/">4Phycs</a>
      <ul id="nav-mobile" class="right hide-on-med-and-down">
        <li><a href="/tags">Tags</a></li>
        <li><a href="/categories">Ita-Eng</a></li>
        <li><a href="/me">Me</a></li>
        <li><a href="/about">About</a></li>
        <li><a href="/contact">Contact</a></li>
      </ul>
    </div>
  </div>
</nav>

<div class="container">
  <a href="#" data-activates="slide-out" class="button-collapse top-nav full hide-on-large-only">
    <i class="material-icons">menu</i>
  </a>
</div>
<ul id="slide-out" class="side-nav fixed">
  <li>
    <div class="userView thi-userView">
      <div class="background"></div>
        <a href="/">
          <img style="display:inherit;" class="circle z-depth-2" src="/assets/res/user.png">
        </a>
      <span style="font-size: larger;" class="white-text name">Paolo Avogadro</span>
      <span class="white-text email"><a style="color: #bdbdbd;" href="http://"></a></span>
    </div>
  </li>
  <li style="padding: 10px;">
    <form action="/search" method="get">
      <input class="search-sidebar" type="search" name="q"  placeholder="Search something?" autofocus>
      <input type="submit" value="Search" style="display: none;">
    </form>
  </li>
  <div id="nav-bar">
    <li><a class="waves-effect" href="/"><i class="material-icons">home</i>Home</a></li>
    <li><a class="waves-effect" href="/categories"><i class="material-icons">sort</i>Ita-Eng</a></li>
    <li><a class="waves-effect" href="/tags"><i class="material-icons">loyalty</i>Tags</a></li>
    <li><div class="divider"></div></li>
    <li><a class="waves-effect" href="/me"><i class="material-icons">person</i>Me</a></li>
    <li><a class="waves-effect" href="/about"><i class="material-icons">info</i>About</a></li>
    <li><a class="waves-effect" href="/contact"><i class="material-icons">perm_contact_calendar</i>Contact</a></li>
  </div>
</ul>

	
</header>
<main>
	<div class="container">
	  <div id="page-info">
		  <h2>Search on this page</h2>
		</div>
		<div class="row">
			<form action="/search" method="get">
	<input type="search" name="q"  placeholder="Type what you wanna search..." autofocus>
	<input type="submit" value="Search" style="display: none;">
</form>

<p style="opacity: 0.6; color: darkmagenta; font-size: 1.2rem;margin-bottom: 20px;" ><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for keyword "<strong id="search-query"></strong>"</span></p>
<ul id="search-results"></ul>

<script>
	window.data = {
		
			
				
					
					
					"pytorch-1": {
						"id": "pytorch-1",
						"title": "Pytorch 1 Inizio, Tensori",
						"categories": "italiano",
						"url": " /Pytorch-1",
						"content": "tocIn this post\n  \n  \n\n  PyTorch e Deep Learning    \n      Indice globale degli argomenti nei post:\n      Introduzione a queste note\n      Disclaimer\n      Indice delle lezioni di Python-Engineer\n      Altre fonti utili\n      Lingo -  Utilia\n      Domande\n      Pipeline\n      Overfitting\n    \n  \n  Tensor Basics    \n      Costruire tensori (Random, 0, e 1 e custom)\n      Attributi/metodi dei tensori\n      requires_grad=True,  operazioni tra tensori e slicing\n      IMPORTANTE: Cambiare la forma di un tensore view()!\n      Reshape\n      Numpy,  Tensori e GPU\n      Funzioni Custom sui tensori:\n      Tensori avanzato\n    \n  \n\n\n  \n\n\nPyTorch e Deep Learning\n\nIndice globale degli argomenti nei post:\n\n 1.1.                                    Indice degli argomenti.\n 1.1.                                      Introduzione e fonti.\n 1.1.                                  Lingo - Gergo utilizzato.\n 1.2.                                        Tensori in Pytorch.\n 2.1.                                      Chainrule e Autograd.\n 2.2.                                           Backpropagation.\n 3.1.                                          Loss e optimizer.\n 3.2.                                        Modelli di Pytorch.\n 3.3.                                      Dataset e Dataloader.\n 3.4.                                       Dataset Transforms.\n 3.5.                              Softmax e Cross-Entropy Loss.\n 3.6.                                       Activation Function.\n 4.1.                                Feed Forward Neural Network.\n 5.1.                               Convolutional Neural Network.\n 5.2.                                          Transfer Learning.\n 5.3.                                                Tensorboard.\n 6.1.                              I/O Saving and Loading Models.\n 7.1.                                  Recurrent Neural Networks.\n 7.2.                                            RNN, GRU e LSTM.\n 8.1.                                          Pytorch Lightning.\n 8.2.                                               LR Scheduler.\n 9.1.                                                Autoencoder.\n\nIntroduzione a queste note\n\nQueste sono i miei appunti su PyTorch e reti neurali in genere. La maggior parte del materiale e’ una traduzione delle  lezioni di \nPython Engineer (Patrick Loeber) con l’aggiunta di mie osservazioni\ne spiegazioni.\n\nLe lezioni di Python Engineer contengono dei riassunti di teoria, ma per capire a fondo il motivo di quello che viene fatto e’ bene avere \nuna solida base di come funzionano le reti neurali. Per una buona introduzione teorica che permetta di capire meglio la logica dietro \nle scelte di programmazione e di modellazione delle reti neurali consiglio questo corso introduttivo del MIT \n(© Alexander Amini and Ava Soleimany). Questo corso (MIT 6.S191) ha anche un sito di supporto: http://introtodeeplearning.com a differenza \ndi Python Engineer viene pero’ usato TensorFlow. Io preferisco l’approccio di Pytorch, che quindi uso in queste note (in futuro magari aggiugnero’ anche TensorFlow).\n\nIn alcuni casi ho preso direttamente i codici di Patrick Loeber (forniti nei link alle sue lezioni), ma nella maggior parte dei casi li ho riscritti (sempre seguendo il video), quindi potrebbero esserci delle piccole differenze. Questo e’ anche dovuto al fatto che questi codici sono pensati per girare all’interno di un notebook, mentre Python Engineer usa Vstudio Code.  Per esempio, quando Patrick vuole mostrare alcuni grafici tramite Matplotlib deve lanciare dei comandi che non servono qui. \nPiu’ di una volta mi e’ capitato avere dei problemi con i codici. Spesso il motivo era una mia errata comprensione dei  video che dava luogo a degli errori non facilmente notabili,  nonostante questo segno questi errori (tra i commenti) perche’ sono utili esempi di cosa si puo’ sbagliare.\n\nIl valore aggiunto di questi miei appunti riguarda principalmente 4 cose:\n\n\n  \n    Il lavoro di traduzione che mi obbliga a pensare mentre scrivo il codice. Alle volte, mantengo i termini inglesi perche’ mi consentono di ricordare le keyword e la sintassi.\n  \n  \n    Ove lo ritengo utile aggiungo dei test e delle prove per capire meglio quello che sta succedendo.\n  \n  \n    Ho aggiunto alcune mie considerazioni personali,  per ricordare e capire meglio.\n  \n  \n    Ho messo un contesto di riassunto e una cornice iniziale di teoria e notazioni che leghi insieme gli appunti.\n  \n\n\nQueste note sono pensate per potere essere navigate tramite un indice interattivo su un Jupyter Notebook. \nNel Jupyter Notebook dove sono state scritte ho ottenuto l’indice tramite: jupyter-navbar. \nHo semplicemente scaricato lo zip da https://github.com/shoval/jupyter-navbar e (dopo avere decompresso) \nho fatto girare da Babun con python2.7 il file setup.py (questo perche’ lo sto facendo girare in Windows 10). \nIn questo modo, a sinistra appare il panel con l’indice.\n\nDisclaimer\nEventuali errori di queste note sono da attribuire solo a me. \nSono appunti personali di cui non assicuro il funzionamento (o la pericolosita’).\nCi sono vari problemi di traduzine dal Jupyter notebook in markdown. \nDovrei citare gli articoli originali di ricerca, ma per ora mi limito ai siti da cui ho \npreso le informazioni.\n\nIndice delle lezioni di Python-Engineer\nI codici possono essere scaricati qui. Qui indico le lezioni di Python Engineer, la loro durata e i capitoli corrispondenti in questo notebook.\n\n\n  Istallazione     5:45\n  Tensor Basics 18:28\n  Gradient Calculation con Autograd 15:54\n  Backpropagation - teorie ed esempi 13:13   (molto ben fatto)\n  Gradient Descent con Autograd e Backpropagation 17:31\n  Training Pipeline: Model, Loss, e Optimizer  14:16\n  Regressione Lineare   12:11\n  Regressione Logistica 18:22\n  Dataset e DataLoader - Batch Training 15:27   (importante da rivedere)\n  Dataset Transforms  10:43\n  Softmax e Cross Entropy 18:17\n  Activation Functions 10:00\n  Feed-Forward Neural Network 21:34\n  Convolutional Neural Network 22:07\n  Transfer Learning 14:55\n  How to use TensorBoard 25:41\n  Saving and loading Models 18:24\n  Create and Deploy A Deep Learning App - PyTorch Model Deployment with Flask  41:52\n  RNN Tutorial- Name Classification Using a Recurrent 38:57\n  RNN &amp; LSTM &amp; GRU Recurrent Neural Nets 15:52\n  Lightning Tutorial Lightweight PyTorch Wrapper for ML 28:02\n  LR Scheduler - Adjust the learning Rate for Better Results 13:29\n\n\nAltre fonti utili\nUn articolo interssante (suggerito proprio da Python Engineer) sulle RNN e’ quello di Andrej Karpathy (ora a Tesla).\n\nAltri appunt utili possono essere trovati qui\n\nAltro corso molto interessante (da cui Python Engineer ha preso spunto, per esempio per l’autoencoder).\n\nimport torch\nimport numpy as np\n\n\nLingo -  Utilia\nQui metto un po’ di keyword che possono risultare utili:\n\n\n  super()  metodo che viene usato quando si costruisce una classe ereditandola da un’altra e consente di usare i metodi della classe genitore.\n  tensor   e’ una matrice con in aggiunta dei metodi che sono propri di PyTorch, e’ il tipo fondamentale di PyTorch (il capitolo Tensor Basics e’ fatto proprio per dare una introduzione)\n  _ Un metodo il cui nome termina con un underscore vuole dire che lavora inplace\n  Dataset  e’ una classe di torch.utils.data dove viene messo il dataset che serve alla rete neurale\n  DataLoader e’ una classe di torch.utils.data, serve per dividere il dataset in batch da dare in pasto alla rete\n  epoch  un passo forward e un backward di TUTTI i campioni del training\n  batch_size numero di campioni di training in un forward/backward pass\n  numero di iterazioni numero di passi, dove in ogni passo(forward/backward) si usa un batch di campioni ( di dimensione “batch_size”)\n  criterion e’ il criterio (la funzione) che usiamo per generare la Loss (per esempio, cross_entropy).Nota che la loss e’ il singolo valore ottenuto (in genere), mentre il criterio e’ il tipo di funzione che, ottenuti come argomenti i valori predetti e quelli corretti fornisce il valore. In queste note uso in modo “liberale” i termini loss e criterion, normalmente questo non dovrebbe creare problemi.\n  learning rate in generale si ottimizzano i pesi della rete usando una tecnica tipo discesa del gradiente. La loss e’ una funzione da $R^n \\rightarrow R$ (dove n e’ il numero di pesi usati). Se calcolo il gradiente allora conosco la massima pendenza e mi posso muovere lungo quella direzione per cercare il minimo (ma nel verso opposto). Di quanto mi muovo? la grandezza di questo passo verso il possibile minimo e’ data dal learning rate. Il prolema di come variare il learning rate e’ fondamentale per poter ottenere delle buone convergenze.\n  Grafo computazionale, immagina di mettere tutte le operazioni fatte per ottenere i risultati della rete neurale. In pratica stai costruendo una funzione $R^n \\rightarrow R^m$. Questa funzione puo’ essere vista come una serire di passi, ognuno indipendente dall’altro. Per esempio se hai una rete neurale con vari hidden layer, ogni passaggo ad un layer e’ diverso, ci sono poi delle funzioni non lineari applicate ecc. La tua funzione Loss e’ quindi una funzione di funzione:F(x) = f(g(h(x)))  (ho messo solo 3 funzioni per esempio ma sono in genere di piu’). Quando vorrai calcolare il gradiente rispetto ai parametri dovrai usare una chain rule e spesso questo viene visualizzato come un grafo con vari passi.\n\n\nDomande\n\n\n  viene piu’ volte consigliato di non fare fare la somma quando si fa backpropagation perche’ viene fatta in automatico.\nCi sono vari modi per evitare questo (devo indicare quali sono i video).\n\n\nPipeline\nLo scopo e’ costruire un codice tramite Pytorch che impari a fare qualcosa. Qui sotto indico la pipeline (la serie di passi) che serve per ottenere questo risultato. Attenzione: con il wrapper Pytorch-Lightning, alcuni di questi passi possono essere saltati e diventa quindi piu’ semplice ottenre un modello funzionante.\n\n\n  si importano i dati in dataset (sia per il training che per il test)\n  i dataset vengono trasformati per migliorarne le caratteristiche tramite delle funzioni transformations (per esempio si possono normalizzare le informazioni)\n  si costruisce i dataloader per dare al modello dei batch (sia per train che per test)\n  si eredita un nn.Model (ricordati di mettere il super) dove vengono inseriti i vari strati della rete nella funzione __init__.\n  nel modello si inserisce anche un metodo forward (ATTENTO il nome deve porprio essere forward, si sta facendo un overload di un metodo gia’ esistente in nn.Model!) dove vengono proprio implementati i passi uno dopo l’altro. Questo e’ il cosiddetto grafo computazionale\n  nota che il modello ereditato e’ “callable” ovvero posso usarlo come una funzione a cui do in pasto qualcosa… in pratica i batch di dati.\n  si istanzia il modello passando solo pochi parametri come: dimensione input, dimensione hidden e dimensione output!\n  Quando si chiama l’istanza del nostro modello personalizzato inserendo un batch, viene chiamata la funzone forward a cui e’ passato il batch.\n  si fa un ciclo esterno sulle Epoche (ogni epoca e’ divisa in batch)\n  si fa un ciclo interno su tutti i batch (infornate) di ogni epoca.\n  si istanzia una funzione chiamata criterion (spesso chiamiamo l’istanza proprio criterion) che viene usata per ottenre la loss. Il criterio e’ la forma generale della loss (per esempio cross-entropy), mentre la Loss e’ l’istanza particolare associata al criterio.\n  la loss e’ una funzione sia delle predizioni $\\hat y$ che dei valori noti $y$. Si usano delle notazioni che rimandano con precisione alle funzioni e gli stimatori, per esempio l’input e’ dato dalla $x$, l’output e’ dato dalla $\\hat{y}$ (questa scrittura assomiglia a quella di uno stimatore di un’osservabile di una distribuzione)\nIl risultato di applicare il criterion a questi dati produce un numero (la loss) che quantifica la qualita’ della predizione. Nota che a questo punto ho una fun\n  empirical loss e’ la media delle varie loss ottenute da un batch, in pratica quindi la discesa del gradiente viene fatta sull’empirical loss\n  optimizer.zero_grad() serve per evitare che tutte le azioni (per esempio l’optimizer) vengno considerate parte del grafo computazionale\n  loss.backward()    fa la backpropagation in modo da ottenere i gradienti rispetto ai pesi (stiamo cercando un minimo rispetto della loss dove le variabili sono i pesi)\n  optimizer.step()   e’ il modo in cui ci si muove (con un passo di grandezza learning_rate) sul landscape dato dalla loss per cercare il minimo, per esempio usando la tecnica chiamata SGD (stochastic gradient descent).\n\n\nUna osservazione sui batch (supportata dalla prima lecture del MIT intorno al min 47).\nCosa significa dare in pasto un batch alla mia (feed forward) rete neurale?\nImmagina la rete neurale smplicemente come una funzione di:\n\n  ${\\bf x_i}$ : sono gli input, per esempio i pixel di una foto. Nel seguito supporro’ che sia una sola variabile\n  ${\\bf w}$ i pesi,  anche qui per semplicita’ si ha un  solo peso.\n\n\nCon i valori in uscita (output) e i valori veri (noti nel training set) otteniamo una funzione di Loss.\nQuesta funzione e’ $\\displaystyle L = f(x,w)$\n\nA questo punto pensa al modello piu’ semplice del mondo in cui ho un solo peso $w$.  in questo caso $L = x \\cdot w^2$ (nota che i pesi possono entrare in modo non lineare). Se passo 2 vettori di input diversi (per esempio 2 immagini) allora ho 2 funzioni di loss diverse:\n\n  $L(x_1,w) = x_1 \\cdot w^2 +x_1\\cdot w$  (una quadratica in funzione di y, dove $x_1$ e’ un prametro)\n  $L(x_2,w) = x_2 \\cdot  w^2 +x_2\\cdot w$\n\n\nNoi ora cambiamo prospettiva, dato che vogliamo minimizzare la loss in funzione dei pesi, considero ora:\n\n  $x_i$ sono i parametri\n  w  sono le variabili\n\n\nLa average loss: $L=L_1 +L_2$ e’ ora una funzione di $y$.\nPer trovare il minimo, uno dei modi piu’ interessanti e’ muoversi nella direzione di massima pendenza (gradient) verso valori piu’ bassi (basta ricordare le utilissime note di Valentina di analisi 2 sulle approssimazioni lineari di funzioni da $R^n \\rightarrow R$. In questo caso calcolo la derivata parziale della loss rispetto al peso: $\\frac{\\partial}{\\partial w}$. Se i pesi sono tanti, allora calcolo il gradiente e ottengo quindi una direzione verso cui muovermi.\n\nIn questo esempio banale le loss sono due parabole centrate in zero e non e’ interessante, il minimo si ottiene mettendo $w=0$. Se prendiamo un caso appena piu’ complicato, dove la loss e’ la somma di due parabole non centrate in zero otteniamo una curva con vari minimi.  Nota che il profilo della funzinoe Loss empirica non e’ identico a quello della loss del singolo imput e noi siamo intressati ad un minimo globale per tutto il batch.\n\nOverfitting\n\nCome evitare l’overfitting durange la fase di training? I casi reali si riferiscono a delle funzioni che sono multidimensionali con una dimensionalita’ enorme (migliaia o centinaia di migliaia di parametri). Questo implica che la superficie su cui facciamo la minimizzazione, data dalla Loss avra’ molti minimi locali. Noi siamo interessati ad un minimo globale che non abbia una forte dipendenza dagli input iniziali, ma vada bene per un vasto range di casi.\n\nPer evitare l’overfitting per esempio ci sono delle regolarizzazioni:\n\n  Regularization 1: metodo dropout, si spengono random dei neuroni (guarda 5.3)\nhttps://www.youtube.com/watch?v=5tvmMX8r_OM&amp;t=1008s&amp;ab_channel=AlexanderAmini\nIn ogni iterazione si fanno dei dropout differenti (scelti in modo random) in modo da ottenere diversi percorsi “neuronali”. Avendo spento alcuni dei neuroni diventa anche piu’ facile fare il training in quanto il numero di parametri per la backpropagation diminiuisce.\n-Regularization 2: Early Stopping, fermare il fit dei parametri prima che raggiunga il minimio. Se si guardano le curve che indicano l’errore del training e della validation, al crescere delle iterazioni tendono a scendere. La curva del training pero’ continua a scendere anche quando la validazione ha smesso di scendere. A quel punto sto overfittando.\n\n\nTensor Basics\nGli oggetti chiave di PyTorch sono i tensor.\n\n\n  un tensor non e’ un tensore della matematica (funzionale lineare, con proprieta’ di trasformazione)!\n  un tensor e’ una matrice di dimensione variabile (1D, 2D, 3D, …)\n  un tensor ha associati dei metodi particolari che servono durante il training di un neural network\n  le convenzioni sono simili a quelle di Numpy (per esempio riguardo lo slicing)\n  E’ spesso utile cambiare la forma del tensore (per esempio con il metodo .view())\n  E’ spesso utile cambiare il tipo degli oggetti contenuti nel tensore dtype=torch.float16. Nota che Torch ha i suoi tipi.\n\n\ncomandi utili:\n\nx = torch.empty(1)       # scalar   NON inizializzato\nx = torch.empty(3)       # vector, 1D\nx = torch.empty(2,3)     # matrice 2D con 2 righe e 3 colonne\nx = torch.empty(2,2,3)   # matrice 3D \nx = torch.empty(2,2,2,3) # matrice 4D \n\n\nCostruire tensori (Random, 0, e 1 e custom)\n\n  torch.empty(5,3) per avere un tensore NON inizializzato\n  torch.rand(5,3) per costruire un tensore pieno di numeri Random U (0,1)\n  torch.zeros(5,3)  per avere un tensore pieno di 0\n  torch.ones(5,3) per avere un tensore pieno di 1\n  torch.tensor([1,2,3]) per creare un tensore, a partire da una lista\n  x.size() ci dice la forma del tensore (numero di righe, colonne, ecc)\n  dtype=torch.float16 per esempio  float32 default\n\n\nx = torch.rand(5, 3)                       # numeri RANDOM intervallo [0,1]\nx = torch.zeros(5, 3)                      # zeri\nx = torch.ones(5, 3)                       # gli ingressi sono tutti uno\nx = torch.zeros(5, 3, dtype=torch.float16) # specifico il tipo\nx = torch.tensor([5.5, 3])  # con questa scrittura si inizializza il tensore inserendo i valori in una lista. Questo\n                            # determina automaticamente anche il numero di righe e colonne\n\n\nAttributi/metodi dei tensori\n\n  x.size()           numero di righe e colonne\n  x.dtype            tipo degli oggetti contenuti\n  x[1]                    fai uno slicing ottieni un TENSORE\n  x[1].item()        estrai un valore: otteni un FLOAT (o quello che e’ il tipo degli oggetti nel tensore)\n  x.mean()           e’ un metodo che calcola la media di TUTTI gli ingressi (non importa se il tensore e’ 2D, ottieni uno scalare)\n\n\nprint(x.size() )         # dimmi il numero di righe e colonne  \nprint(x.dtype )          # dimmi il tipo degli oggetti contenuti \nprint(x[1])              # questo e' un TENSORE\nprint(x[1].item())       # questo e' un FLOAT\ntype(x[1].item())        # infatti...\n\n\ntorch.Size([2])\ntorch.float32\ntensor(3.)\n3.0\n\n\n\n\n\nfloat\n\n\ng= torch.tensor([[1.,2,3,4], [2., 4,6,8]])\nprint(g.mean(), g.size())\n\n\ntensor(3.7500) torch.Size([2, 4])\n\n\nrequires_grad=True,  operazioni tra tensori e slicing\n\n\n  requires_grad=True se si inserisce questo argomento nella creazione di un tensore, allora, durante il processo di ottimizzazione PyTorch calcolera’ il gradiente (derivata parziale rispetto a questo tensore). Nota che questa opzione e’ accesa di default\n\n\nLe operazioni di base tra tensori sono ottenute con dei metodi indicati con 3 lettere, minuscole:  \n\n  torch.sub(x,y)     oppure       - (fa la sottrazione tra x e y e la restituisce)\n  torch.add()         oppure       +\n  torch.div()         oppure       /\n  torch.mul()         oppure       *\n  requires_grad=True se voglio che PyTorch calcoli il gradiente (derivata parziale) rispetto a questo tensore rispetto al grafo computazionale.\n  tutti i casi in cui il metodo finisce con un underscore _ lavorano INPLACE\n\n\nx = torch.tensor([5.5, 3], requires_grad=True)\n\ny = torch.rand(2, 2)   # costruiamo 2 tensori random 2D\nx = torch.rand(2, 2)   # costruiamo 2 tensori random 2D\n\n# ADDIZIONI \nz = x + y\nz = torch.add(x,y)\ny.add_(x)                   # INPLACE   &lt;=====================\n\n\n# SOTTRAZIONI\nz = x - y\nz = torch.sub(x, y)\n\n# MOLTIPLICAZIONI\nz = x * y\nz = torch.mul(x,y)\n\n# DIVISIONI\nz = x / y\nz = torch.div(x,y)\n\n# Slicing restituisce dei sotto-tensori (ma sempre di tipo tensor)\nx = torch.rand(5,3)\nprint(x)\nprint(x[:, 0])  # tutte le righe, colonna 0\nprint(x[1, :])  # riga 1, tutte le colonne \nprint(x[1,1])   # elemento  1, 1\n\n# Se voglio ottenere il valore di un ingresso devo usare il metodo .item() (vale per 1 solo valore)\nprint(x[1,1].item())\n\n\ntensor([[0.7356, 0.5790, 0.3409],\n        [0.1011, 0.1175, 0.8874],\n        [0.5814, 0.6688, 0.1503],\n        [0.7797, 0.6233, 0.0940],\n        [0.5445, 0.1418, 0.8160]])\ntensor([0.7356, 0.1011, 0.5814, 0.7797, 0.5445])\ntensor([0.1011, 0.1175, 0.8874])\ntensor(0.1175)\n0.11745560169219971\n\n\nIMPORTANTE: Cambiare la forma di un tensore view()!\ncon il metodo view si cambia la forma di un tensore. Questo e’ particolarmente utile quando si fanno per esempio le reti convoluzionali. In una fully connected layer io vedo l’ingresso come un verttore 1D. Se faccio la convoluzione devo ridare una forma 2D.\n\n\n  con view(3,4) cambio la forma. Semplicemente si mette il numero di righe (3 nell’esempio) e colonne(4 nell’esempio) voluto!\n  NON lavora inplace\n  il valore -1 e’ un jolly: torch automaticamente determina il numero di righe (per esempio) se io scrivo solo il numero di colonne. Per esempio x.view(-1,8) allora torch mettera’ come numero di colonne, il numero di ingressi diviso per 8.\n\n\nx = torch.randn(4, 4)                 # costruisco un tensore2D: 4x4 \ny = x.view(16)                        # lo trasformo in 1D: 16x1\nz = x.view(-1, 8)                     # Voglio ora un tensore2D, con 8 colonne a partire da quello di prima \n                                      # il -1 indica che in questa dimensione sceglie torch AUTOMATICAMENTE!\nw = x.view(2,2,-1,2)    \nprint(x.size(), y.size(), z.size(), w.size())\n\n\ntorch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) torch.Size([2, 2, 2, 2])\n\n\nReshape\nquesto e’ un altro metodo che serve per modificare la forma di un tensore. \nReshape puo’ resituire sia una copy che una view\n\nNumpy,  Tensori e GPU\nvediamo come passare da un ndarray (Numpy) ad un tensore e viceversa.\n\n\n  .numpy() e’ un metodo di torch per trasformare un tensor $\\rightarrow$ ndarray (di numpy). ATTENZIONE usando questo metodo cosi’: b = torch.numpy(a)\nsi ottiene b, che e’ un ndarray, ma i suoi valori sono presi da a. NON e’ un oggetto completamente nuovo. Se modifico “a”, anche “b” cambia!\n  .from_numpy() e’ un metodo di torch per trasformare un ndarray $\\rightarrow$ tensor\n  attenzione se il tensore e’ sulla GPU e lo trasformo in NUMPY anche il trasformato resta sulla GPU\n  esiste un oggetto che dice dove deve essere il tensore: device=torch.device(“cuda”), nota che il nome scelto in questo caso serve a ricordarci che l’argomento perche’ e’ identico\n  .to() per muovere un tensore da un posto all’altro basta il metodo: x=x.to(device)\n  numpy non e’ in grado di gestire tensori sulla GPU\n  torch.cuda.is_available() per sapere se CUDA e’ disponibile, e’ BOOL\n\n\n# Numpy\n# Convertiamo un TENSORE in un ndarray di Numpy\na = torch.ones(5)    # a e' un TENSORE (Torch)\nb = a.numpy()        # b e' un ndarray (Numpy)  (occhio che  .numpy e' un metodo dei TENSORI)\n\na.add_(1)            # cambiamo a\nprint('a=',a)            \nprint('b=',b)        # anche b e' cambiato &lt;================ ATTENTO\n\n\n\n# numpy to torch with .from_numpy(x)\na = np.ones(5)\nb = torch.from_numpy(a)\nprint(a)\nprint(b)\n\n# again be careful when modifying\na += 1\nprint(a)\nprint(b)\n\n# by default all tensors are created on the CPU,\n# but you can also move them to the GPU (only if it's available )\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")          # a CUDA device object\n    print(\"Cuda e' disponibile!!\\n\")\n    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n    z = x + y\n    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n    # move to CPU again\n    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n    # z = z.numpy()\n\n\na= tensor([2., 2., 2., 2., 2.])\nb= [2. 2. 2. 2. 2.]\n[1. 1. 1. 1. 1.]\ntensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64)\nCuda e' disponibile!!\n\n\nFunzioni Custom sui tensori:\nguarda la risposta di  msd15213 al link:\nlink\n\nmolto meglio questo\n\nTensori avanzato\n\n  un tensore puo’ essere contiguous"
					}
					
				
			
		
			
				
					,
					
					"seaborn": {
						"id": "seaborn",
						"title": "Seaborn - appunti",
						"categories": "italiano",
						"url": " /Seaborn",
						"content": "Seaborn:\nQuesti appunti contengono esempi, commenti e grafici basati sul bel video di Derek Banas di\n Simplilearn.\n\nQualunque errore e’ dovuto a me e non da imputare a Derek Banas.\nHo aggiunto anche pensieri e esempi che mi servivano.\n\nIn alcuni casi i comandi indicati da Banas mi davano problemi, \nprobabilmente per le versioni di Python/Matplotlib/Seaborn. \nHo cercato di farli girare con dei piccoli cambiamenti. La mia versione e’ basata su una Anaconda aggiornata \nal Novembre 2020, all’interno di un Jupyter notebook.\n\nAlle volte faccio dei paragoni con Gnuplot, dato che e’ il mio sistema di visualizzazione di base…\n\nE’ capitato che facessi degli errori banali, ho lasciato le note sulle soluzioni perche’ possono essere utili.\n\nIntroduzione:\n\nSeaborn e’ una libreria che lavora su Matplotlib e Pandas.\nVisto che un DataFrame di Pandas ha molte colonne, spesso sara’ necessario fare dei grafici\nmultipli che contengano informazioni di tutte le coppie di colonne. In questo senso \nsi puo’ vedere Seaborn come una serie di script che forniscono delle combinazioni\ndi comandi che rendono veloce e semplice le visualizzazioni multiple (per progetti di data science).\n\nAlternativamente a Matplotlib esiste un’altra libreria chiamata bokeh (che esplorero’ in seguito)\n\nTrucco utilissimo (che non conoscevo/ricordavo) di Jupyter notebook\n\n  cliccki su una cella\n  clicchi su una funzione\n  premi shift-tab: ti fa vedere tutti gli argomenti che possono essere passati a quella funzione\n\n\nQuando mi riferisco alle funzioni di Seaborn, non parlo di metodi associati ai DataFrame. La sola differenza e’ che non si applicano tramite la dot “notation” dei metodi. Il DataFrame (o sue parti) e’ passato come argomenti delle funzioni stesse. Inoltre ci possono essere altri argomenti utili, come per esempio:\n\n  hue       (assegna colori diversi a valori diversi, p.es. maschi e femmine)\n  palette   (sono combinazioni di colori, in cui viene definita una topologia di colori, per esemppio il successivo a questo rosso e’ quest’altro rosso…)\n  styling   (per cambiare la dimensione delle label..)\n  set_style (cambia lo sfondo)    non funge (forse perche’ faccio girare la cella dopo averne fatta girare un’altra che ha lasciato qualcosa in memoria)\n  font_scale (grandezza delle label)\n  spine     (gli assi, laterali e verticali) ATTENTO: va messo sotto il comando sns.joinplot\n  figsize   (indica l’aspect ratio del rettangolo, base e poi altezza). ATTENTO, in jupyter puoi chiedere che matplotlib sia inline, questo fa si’ che le figure siano dei png sul notebook, e si puo’ definire un dpi. Questo ultimo comando “fissa” la dimensione visibile della figura!\n  spine sono gli assi!\n  legend   (la legenda)\n  jitter   (per fare uno spredout dei punti in alcuni tipi di plot)\n  side by side ( per mettere 2 figure di seaborn una da parte all’altra cerca: subplots)\n  palettes  (cerca la lista: maplotlib colormaps https://matplotlib.org/3.3.3/tutorials/colors/colormaps.html )\n  pivot tables (per fare le matrici, definisci le righe e le colonne. Questo seleziona dei valori. Tipicamente per questi valori esistono varie righe del DataFrame, da cui posso estrarre un grafico per ognuna delle righe e colonne della pivot table.) In prarica una pivot table fa un prodotto cartesiano tra tutti gli elementi delle righe e delle colonne.\n  Subplot figure una di lato all’altra,o meglio all’interno di una “griglia” dove ci possono essere tanti grafici.\n\n\nAttento devi mettere il seguente con seaborn, che non c’e’ nel video di Banas:\n\n  ax=axes[0] # per il primo\n  ax=axes[1] # per il secondo oggetto.\n\n\nSe non li metti il sistema non fa vedere la prima figura ma disegna un plot vuoto e fa vedere da parte l’ultimo plot\ndisegnato. Ho trovato l’esempio con i pokemon (sebbene la pagina sia poco leggibile): https://dev.to/thalesbruno/subplotting-with-matplotlib-and-seaborn-5ei8\n\nTRUCCO\nci sono vari magic command di Matplotlib oltre al solito inline:\n\n%matplotlib inline - Figures are shown as static png images (optionally svg if configured)\n\n%matplotlib notebook or %matplotlib nbagg - Interactive Figures inside the notebook\n\n%matplotlib widgets - - Interactive Figures inside the notebook (requires jupyter-matplotlib to be installed)\n\n%matplotlib tk or\n\nNota tecnica:\n\nHo notato che una TOC poteva risultare utile, per questo ho installato jupyter-navbar.\nHo semplicemente scaricato lo zip da https://github.com/shoval/jupyter-navbar\ne (dopo avere decompresso) ho fatto girare da Babun con python2.7 il file setup.py\n(questo perche’ lo sto facendo girare in Windows 10).\nIn questo modo appare la barra con l’indice.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#sns.set()\n\n%matplotlib inline\n#%matplotlib notebook\n#%matplotlib tk\n#%matplotlib widgets\n\n# questi sotto non so ancora cosa facciano\n%reload_ext autoreload \n%autoreload 2\n\n\n#cs_df = pd.read_csv('ComputerSales.csv')  # dovrei trovarlo\n\n\nDataset di Seaborn\nposso sapere la lista di questi dataset e anche caricarli velocemente con il metodo load_dataset\n\nprint (sns.get_dataset_names())\n\n\n['anagrams', 'anscombe', 'attention', 'brain_networks', 'car_crashes', 'diamonds', 'dots', 'exercise', 'flights', 'fmri', 'gammas', 'geyser', 'iris', 'mpg', 'penguins', 'planets', 'tips', 'titanic']\n\n\ncrash_df = sns.load_dataset('car_crashes')\nprint(crash_df.shape)\nprint(crash_df.head(3))\n\n\n(51, 8)\n   total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n0   18.8     7.332    5.640          18.048       15.040       784.55   \n1   18.1     7.421    4.525          16.290       17.014      1053.48   \n2   18.6     6.510    5.208          15.624       17.856       899.47   \n\n   ins_losses abbrev  \n0      145.08     AL  \n1      133.93     AK  \n2      110.35     AZ  \n\n\nDistribution Plots\n\nDistribution Plot\n\nsns.distplot(miaSerie): questa funzione, in pratica, se applicata ad una Series di Pandas produce automaticamente un istogramma.\n\nOcchio che il comando qui sotto e’ deprecato, e verra rimosso in futuro.\nNon e’ chiaro perche’, ma nelle note del “warning” di python indicano di usare una funzione con lo stesso nome:\n\ndistplot ma che e’ “a figure-level function”,\n\noppure:\n\nhistplot\n\nQuesta funzione in ogni modo fa un istogramma di una colonna (Series) di un dataframe di Pandas.\n\nInoltre per default fa anche un kernel density estimation (KDE), possiamo spegnerlo con kde=False\n\nbins e’ il numero di bin dell’immagine, non la loro larghezza (ovviamente visto che ha una s…)\n\nsns.distplot(crash_df['not_distracted'], kde=False, bins=15)\n\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n\n\n\n\n\n&lt;AxesSubplot:xlabel='not_distracted'&gt;\n\n\n\n\nJoint Plots\nLa funzione: sns.jointplot costruisce uno scatterplot con “aggiunte”.\n\n\n  \n    viene fatto per paragonare 2 distribuzioni diverse (che saranno 2 colonne di un DataFrame).\n  \n  \n    In pratica fa un scatter plot, e sopra e sotto mette anche gli istogrammi relativi alle colonne.\n  \n  \n    inolte si puo’ aggiungere al volo una regressione lineare con il comando kind='reg' nello scatterplot e i kernel sopra gli istogrammi.\n  \n  \n    il comando kind definisce lo stile di visualizzazione.\n  \n  \n    vanno passate delle x e delle y in forma di Series che costituiranno le coordinate dei punti dello scatterplot. Ovviamente il numero di oggetti delle x e delle y deve essere lo stesso, altrimenti per un punto ci sarebbe solo una coordinata ma non la seconda…\n  \n\n\nsns.jointplot(x='speeding', y='alcohol', data=crash_df, kind ='reg' );\n\n\n\n\nsns.jointplot(x='speeding', y='alcohol', data=crash_df );  # ho tolto la curva con il kernel  estimation e la regressione\n\n\n\n\nAttenzione che il grafo nel video non ha solo le isoipse ma anche un sistema di colorazione \n che in qui sotto non appare!\n\nsns.jointplot(x='speeding', y='alcohol', data=crash_df, kind= 'kde' );\n\n\n\n\nsns.jointplot(x='speeding', y='alcohol', data=crash_df, kind= 'hex' );\n\n\n\n\nKDE plot\n\nLa funzione Kdeplot costruisce una sorta di interpolazione dei dati di una series.\n\nnota che nel grafico sotto non appare la legenda, mentre nel video c’e’ di default!\n\nsns.kdeplot(crash_df['alcohol']);\n\n\n\n\nPair Plot\nFa vedere la relazione tra tutte le coppi di colonne contenenti valori numerici dell’intero DataFrame.\n\n\n  \n    Esclude i valori categorici\n  \n  \n    Occhio che e’ lento!\n  \n  \n    Anche in questo caso il comando kind=... definisce come viene visualizzato lo scatterplot. Nell’esempio sotto solo le isoipse.\n  \n\n\nsns.pairplot(crash_df, kind = 'kde');  # nel video fa anche i colori e non solo le linee di livello\n\n\n\n\nPairplot\nHue\nhue assegna un colore diverso a tutti i valori della colonna indicata. Per esmepio in questo caso hue=’sex’,\nquindi i punti associati a Male e Female sono colorati in modo diverso.\n\nIn pratica lui va a prendere i dati, li divide per sesso, poi li disegna automaticamente sullo stesso grafico ma con colori diversi!\n\nNota: si puo’ usare anche con variabili categoriche, non solo le variabili numeriche (anzi penso\nche possa avere dei problemi se le variabili numeriche sono float…)\n\ntips_df = sns.load_dataset('tips')\nprint(tips_df.head(3))\nsns.pairplot(tips_df, hue='sex', palette='Blues');            # occhio che qui c'e' il sesso del pagante non del ricevente...\n\n\n   total_bill   tip     sex smoker  day    time  size\n0       16.99  1.01  Female     No  Sun  Dinner     2\n1       10.34  1.66    Male     No  Sun  Dinner     3\n2       21.01  3.50    Male     No  Sun  Dinner     3\n\n\n\n\nRug plot\nQuesto tipo di grafico fa vedere delle lineette per ogni punto. \nIn pratica fa un unfolding di un istogramma.\n\nsns.rugplot(tips_df['tip']);\n\n\n\n\nStyling\nserve per modificare l’aspetto delle figure\n\nProblema, se cambio i parametri di figsize, mi restituisce un “Figure size 576x864 with 0 Axes”, e i valori contenuti sono coerenti coi parametri che ho dato… ma il grafico non viene modificato! Forse il problema e’ legato all’inline lanciato all’inizio mentre in un eventuale salvataggio a file otterrei dei risultati differenti?\n\n\n  spine e’ il termine tecnico associato agli assi. Se per esempio non voglio che uno degli assi appaia nel grafico posso usare la funzione despine. Attenzione che va messo sotto il comando del disegno joinplot altrimenti non ha effetto!\n  \n    set_context modifica i parametri in modo che la dimensione dei font e del grafico siano proporzionati in base al contesto. Per esempio se faccio un poster ho bisogno di label grandi…\n  \n  set_style sono le combinazioni di colori dello sfondo\n\n\n#sns.set_style ('white')      \nsns.set_style ('darkgrid')\n#sns.set_style ('whitegrid')\n#sns.set_style ('ticks')\n\nplt.figure(figsize=(8,5))    # non funge, devo capire perche'!\n\nsns.set_context('paper', font_scale=1.5)\n#sns.set_context('talk', font_scale=1.5)    # ingrandisce tutto\n#sns.set_context('poster', font_scale=1.5)\n\nsns.jointplot(x='speeding', y='alcohol', data= crash_df, kind='reg');\n\nsns.despine(left=True, right=False, top=True, bottom=False)    # Occhio va messo SOTTO joinplot altrimenti non fa nulla  \n\n\n&lt;Figure size 576x360 with 0 Axes&gt;\n\n\n\n\nCategorical Plotting\n\nBar Plots\nbarplot()\n\n  di default fa vedere la mean\n  La barra nera fa vedre la varianza\n  devo passare cosa ci sia sulle x e sulle y  (e il dataframe da cui sono prese)\n\n\nsns.barplot(x='sex', y='total_bill', data=tips_df);\n\n\n\n\nPossiamo usare funzioni diverse per stimare i valori categorici, per esempio tutti quelli\nin numpy, come la mediana, o la moda (non mi e’ riuscito)!\n\n\n  Attento se fai 2 barplot, li sovrappone e non si capisce nulla\n  Si possono usare delle funzioni custom fatte da noi, suppongo che di base si debba lavorare con un oggetto di tipo Series di Pandas\n\n\n#sns.barplot(x='sex', y='total_bill', data=tips_df , estimator=np.median);   # mediana\n#sns.barplot(x='sex', y='total_bill', data=tips_df , estimator=np.std);       # deviazione standard\n#sns.barplot(x='sex', y='total_bill', data=tips_df , estimator=np.var);      # varianza\nsns.barplot(x='sex', y='total_bill', data=tips_df , estimator=np.cov);      # covarianza\n\n#from scipy.stats import mode  # non sono riuscito a fargli usare la moda\n#sns.barplot(x='sex', y='total_bill', data=tips_df , estimator=mode);\n\n\n\n\nCount Plot\ncountplot\n\ne’ come un barplot ma l’estimatore conta solo il numero di occorrenze, per questo non ha bisogno della y (e’ automaticamente il numero di occorrenze)\n\nsns.countplot(x='sex', data=tips_df)\n\n\n&lt;AxesSubplot:xlabel='sex', ylabel='count'&gt;\n\n\n\n\nBox Plot\n\nboxplot()\n\nfa vedere il grafico a baffi con i quartili dei dati.\n\n\n  la linea nera e’ la mean\n  la scatola si estende di una deviazione standard (siamo sicuri? calcola la deviazione standard destra e sinistra? Di solito (wikipedia) la scatola indica il primo e il terzo quartile, devo controllare).\n  I whiskers (baffi) si estendono fino ???    .In alcune rappresentazioni si estendono fino al massimo e al minimo\n  \n    I punti sono outliers (che non stanno nei baffi). Non e’ spiegato bene nella documentazione di Seaborn. Se usano la convenzione per gli outlier che uso io e’ Q3 + 3 IQ  (dove l’interquartile e’ la differenza tra il terzo e il primo quartile IQ= Q3-Q1).\n  \n  sulle x vengono selezionati vari insiemi di dati\n  sulle y viene fatto il grafico a baffi di quei particolari dati (vedi il grafico che e’ chiaro)\n\n\nL’estensione dei whisker non viene spiegata bene nelle note di Seaborn.\n\nsns.boxplot(x='day', y='total_bill', data=tips_df, hue='sex');\n\nplt.legend(loc=1); # la legenda in alto a sx e' loc =0\n\n\n\n\nViolin Plot\nUna combinazione di boxplot e kde plot, dove usa i kernel. Il nome e’ ovvio…\n\nsns.violinplot(x='day', y='total_bill', data=tips_df, hue='sex');\n\n\n\n\n# E' inutile mettere tutto il violino per una sola categoria, mettiamo mezzo per una e mezzo per l'altra: split\nsns.violinplot(x='day', y='total_bill', data=tips_df, hue='sex',split=True);\n\n\n\n\nStrip plot\nstripplot()\n\nsi usa quando una variabile e’ categorica:\n\n\n  jitter non mi pare che faccia una grande differenza, dovrebbe sparpagliare meglio i punti\n  hue funziona assegna dei colori diversi in base ad una variabile categorica\n  dodge, separa fisicamente i punti con hue differente\n\n\nPrima non disegnava correttamente, perche’ dove avevo scritto fig, ax= plt.subplots(1,2, figsize=(15,5))\navrei invece dovuto scrivere ‘fig, axes=…’\n\n######  HO fatto qualche modifica rispetto al video, in modo da paragonare con e senza jitter #####\n\n#plt.figure(figsize=(8,5))\nfig, axes =plt.subplots(1,2 ,figsize=(15, 5) )        # grafici uno da parte all'altro\nsns.stripplot(x='day', y='total_bill', data=tips_df, ax=axes[0]);\nsns.stripplot(x='day', y='total_bill', data=tips_df, ax=axes[1], jitter=True);\n#fig.show()  # non serve in un jupyter notebook\n\n\n\n\nsns.stripplot(x='day', y='total_bill', data=tips_df, jitter=True);  # jitter muove un po' in giro i punti\n\n\n\n\nsns.stripplot(x='day', y='total_bill', data=tips_df, jitter=True, hue='sex'); \n\n\n\n\nSeparo le hue, ma le lascio allo stesso giorno. Questo viene ottenuto tramite il comando dodge separa fisicamente i due gruppi di punti.\n\nsns.stripplot(x='day', y='total_bill', data=tips_df, jitter=True, hue='sex', dodge=True); \n\n\n\n\nSwarm plot (lo sciame)\nviolinplot()\n\ncombina i plot precedenti.\n\n\n  in pratica definisce la posizione dei punti come se fossero delle foglie, il primo al centro poi un a dx in alto , sx in alto..\n\n\nPrima riguardiamo il violino (poi lo confrontiamo con lo swarmplot)\n\nsns.violinplot(x='day' , y='total_bill', data=tips_df);\n\n\n\n\n# poi vediamo lo sciame.\nsns.swarmplot(x='day' , y='total_bill', data=tips_df);\n\n\n\n\n# metto insieme il violino e lo sciame\nsns.violinplot(x='day' , y='total_bill', data=tips_df);\nsns.swarmplot(x='day' , y='total_bill', data=tips_df, color='white');\n\n\n\n\nPalettes\n\npalette e’ un parametro\n\n\n  una palette e’ un insieme di colori predefiniti.\n  in cui definiamo anche una topologia tra colori: ovvero quale colore e’ vicino a quale colore.\n  punto di partenza una palette standard\n  Le palette si trovano qui: https://matplotlib.org/3.3.3/tutorials/colors/colormaps.html )\n\n\nplt.figure(figsize=(8,5)) # funge! se non lo metto sotto diventa tutto piu' piccolo\nsns.set_style('dark')\nsns.set_context('talk')\nsns.stripplot(x='day', y='total_bill', data=tips_df, hue='sex');\n\n\n\n\ncambio palette\n\nplt.figure(figsize=(8,5))\nsns.stripplot(x='day', y='total_bill', data=tips_df, hue='sex', palette='PuBu'); # PuBu=palette trovata su matplotlib\n\n\n\n\nLegend\nqualche comando per muovere la legenda.\nIn teoria:\n\n\n  loc = 0 sceglie lui la posizione ottimale\n  upper right=1\n  upper left =2\n  lower left =3\n  lower right =4\n\n\nCerca Matplotib legends e ci sono tutte le opzioni https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.legend.html\n\n#plt.figure(figsize=(8,5)) # funge! se non lo metto sotto diventa tutto piu' piccolo\nplt.figure(figsize=(8,7)) # funge! se non lo metto sotto diventa tutto piu' piccolo\nsns.set_style('dark')\nsns.set_context('talk')\nsns.stripplot(x='day', y='total_bill', data=tips_df, hue='sex');\n#plt.legend(loc=0) # best = sceglie lui la posizione\n#plt.legend(loc=1) # in alto a dx\n#plt.legend(loc=2) # in alto a sx         \n#plt.legend(loc=3) # in basso a sx\nplt.legend(loc=4)  # in basso a dx \n\n\n&lt;matplotlib.legend.Legend at 0x12265a93550&gt;\n\n\n\n\nMatrix Plot\n\nIn questo caso vogliamo visualizzare una matrice, ovvero un oggetto con righe e colonne.\nIn ogni ingresso della matrice avro’ dei valori e voglio visualizzarli.\n\n\n\nHeatmaps\nheatmap()\n\nqui sotto prendiamo il crash_df e cerchiamo di costruire delle heatmaps\n\nargomenti utili:\n\n\n  cmap = ‘Blues’  e’ la colormap\n  annot =True   scrivi anche il valore della colorazione nella casella (altrimenti fa solo il colore)\n\n\ncrash_df.head(3);  # riguardiamo questo df\n\n\nQui sotto uso un metodo (di Pandas?) per cui\n\n\n  dato un dataframe con valori numerici e categorici\n  calcola la correlazione tra ogni coppia di colonne numeriche\n\n\ncrash_mx = crash_df.corr() \ncrash_mx.head(3)\n\n\n\n\n\n  \n    \n      \n      total\n      speeding\n      alcohol\n      not_distracted\n      no_previous\n      ins_premium\n      ins_losses\n    \n  \n  \n    \n      total\n      1.000000\n      0.611548\n      0.852613\n      0.827560\n      0.956179\n      -0.199702\n      -0.036011\n    \n    \n      speeding\n      0.611548\n      1.000000\n      0.669719\n      0.588010\n      0.571976\n      -0.077675\n      -0.065928\n    \n    \n      alcohol\n      0.852613\n      0.669719\n      1.000000\n      0.732816\n      0.783520\n      -0.170612\n      -0.112547\n    \n  \n\n\n\nplt.figure(figsize=(8,6))\nsns.set_context('paper', font_scale=1.4)\n#sns.heatmap(crash_mx, annot=True, cmap='Blues')   # fa vedere anche i numeri nelle caselle colorate\nsns.heatmap(crash_mx, annot=False, cmap='magma')   # fa vedere SOLO i colori\n\n\n&lt;AxesSubplot:&gt;\n\n\n\n\nPivot Table\nquesto e’ un altro modo per costruire una matrice.\n\nNEll’esempio sotto quello che fa e’:\n\n  indico l’index ovvero l’attributo che viene usato per l’indice di riga\n  indico le columns, ovvero l’attributo che viene usato per l’indice di colonna\n  A questo punto lui va. Controlla tutti gli i valori  dell’attributo per l’index. Li usa per costruire una tabelle di cui sono tutte le righe.\n  Poi va e controlla i valori dell’attributo per le columns e costruisce le colonne.\n  Poi va e pesca per ognuno degli attributi dell’index e delle columns i valori dati come values e li mette nelle caselle.\n\n\nflights = sns.load_dataset('flights')\nflights.head(3)\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      passengers\n    \n  \n  \n    \n      0\n      1949\n      Jan\n      112\n    \n    \n      1\n      1949\n      Feb\n      118\n    \n    \n      2\n      1949\n      Mar\n      132\n    \n  \n\n\n\nflights.pivot_table(index='month', columns='year', values='passengers')  # NON lavora INPLACE (invece nel video si')\nflights_pt = flights.pivot_table(index='month', columns='year', values='passengers') \n\n\n#sns.heatmap(flights.pivot_table(index='month', columns='year', values='passengers'), annot=False, cmap='Blues') # IDENTICO\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\nsns.heatmap (flights_pt, ax=axes[0],annot=False, cmap='Blues') \nsns.heatmap (flights_pt, ax=axes[1],annot=False, cmap='Blues', linecolor='white', linewidth=1) ; #larghezza linea default 0?\n\n\n\n\nCluster Map\nclustermap()\n\nhierarchically clusterd heatmap  = heatmap ottenuta cone una clusterizzazione gerarchica\n\n\n  la distanza tra tutti i punti e’ calcolata\n  i piu’ vicini sono uniti\n  il lavoro continua con il prossimo vicino\n  quindi paragona le colonne e le righe\n\n\nA differenza della heatmap, dove l’ordine degli attributi e’ mantenuto costante, in questo caso\nviene riordinato seguendo il clustering.\n\niris = sns.load_dataset('iris') # e' un pandas dataframe di default\niris.head(3)\n#sns.clustermap(iris)\n\n\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n      species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n  \n\n\n\nspecies = iris.pop('species')  # pop spara fuori una colonna e la trasforma in una Series\n\n\nHeatmap ottenuta con una clusterizzazione gerarchica\n\nsns.clustermap(iris);  # heatmap ottenuta con una clusterizzazione gerarchica\n\n\n\n\nRicorda che la pivot table ho dovuto rinominarla, per lui fights e’ la pivot table, per me e’ flights_pt\n\n#sns.clustermap(flights , cmap ='Blues', standard_scale =1)  # NON FUNGE normalizza i dati per focalizzarci sul clustering \nsns.clustermap(flights_pt , cmap ='Blues', standard_scale =1);  # normalizza i dati per focalizzarci sul clustering \n\n\n\n\nun commento a quanto qui sopra. Pensale in termine di sequenze numeriche, in cui il colore e’ un numero.\nPuoi avere sequenze verticali e orizzontali.\nPrendiamo ora le sequenze orizzontali.\nLe due piu’ in alto sono molto chiare, ma non sono le piu’ vicine, infatti Nov e Jan sono connesse. Poi si connette Feb.\nNon mi e’ chiaro il dendrogramma come venga poi costruito. Mi pare di capire che alla fine ci possano essere solo delle coppie. Se il primo vicino di una sequenza e’ gia’ in una coppia, questa rimane isolata e va attaccata alla coppia oppure… devo pensare all’algoritmo.\n\nNota che a causa del clustering mi aspetto di vedere striscie. Questo perche’ sequenze simili vanno messe vicine tra loro.\n\nPotrebbero mettere un puntino al centro di ogni cella. Questo punto si puo’ muovere sull’asse delle z o delle y .Il modvimento e’ lo stesso sui due assi e in questo modo si vedono le sequenze sia guardando le righe che le colonne!\n\nPair Grids\nPairGrid()\n\nPrima abbiamo visto i pairplots, dove si facevano degli scatter plot tra tutte le coppie di colonne del DataFrame.\n\nPer prima cosa creiamo una grid vuota.\n\niris = sns.load_dataset('iris')\niris_g = sns.PairGrid(iris, hue='species')  # assegna un colore diverso alle varie specie\niris_g.map(plt.scatter);                     # questo mi pare un comando di matplotlib o PANDAS\n\n\n\n\nOra vogliamo mettere un istogramma lungo la diagonale (della griglia di grafici).\n\niris_g = sns.PairGrid(iris, hue='species')  # assegna un colore diverso alle varie specie\n#iris_g.map(plt.scatter);                    # questo mi pare un comando di matplotlib o PANDAS\niris_g.map_diag(plt.hist);                  # nei grafi diagonali inserisce un istogramma\niris_g.map_offdiag(plt.scatter);            # non mette gli scatterplot diagonali! (occhio che devi commentare l'altro!) \n\n\n\n\nOra vogliamo mettere delle altre cose nella:\n\n  parte superiore (della matrice di grafici)\n  parte inferiore (della matrice di grafici)\n\n\nquindi diamo un comando chen indica cosa mettere sulla diagonale e poi uno per la triangolare superiore e uno per la triangoplar e superiore. Occhio che si deve passare come argomento di\n\nmap_diag  (oppure map_lower o map_upper) il nome della funzione che si userebbe per diegnare un singolo plot di questo tipo.\n\niris_g = sns.PairGrid(iris, hue='species')  # assegna un colore diverso alle varie specie\niris_g.map_diag(plt.hist);                  # nei grafi diagonali inserisce un istogramma\niris_g.map_upper(plt.scatter);              # sopre metti gli scatter plot \niris_g.map_lower(sns.kdeplot);              # sotto metti KDE quindi devi usare la funzione di SEABORN\n\n\n\n\nVariabili per la nostra custom grid\n\n#iris_g = sns.PairGrid(iris, hue='species')  # assegna un colore diverso alle varie specie\niris_g = sns.PairGrid(iris, hue='species', \n                       x_vars=[\"sepal_length\", \"sepal_width\"],\n                      y_vars= [\"petal_length\", \"petal_width\"] )\niris_g.map(plt.scatter);                                         # map e' usata in modo molto potente\niris_g.add_legend();\n\n\n\n\nFacet Grid\nFacetGrid()\n\nE’ una specie di subplots di matplotlib ma con delle cose predefinite.\n\n\n  posso disegnare plot multipli in una griglia (grid)\n  posso definire le colonne e righe\n\n\nSi crea un sistema a forma di griglia (in cui pero’ non abbiamo ancora messo nulla).\nAl primo passo indico le colonne e le righe, per esempio:\n\n\n  nelle colonne metto il tempo (time). Che puo’ assumere 2 valori: Dinner e Lunch\n  nelle righe metto ‘smoker’. Che puo’ assumere 2 valori: yes e no\n\n\nQuindi la griglia che ho creato e’ 2x2.\n\nIn ogni ingresso della griglia  devo mettere un grafico.\nCosa metto?\n\nMap\nIl metodo map() di python e’ utilissimo perche’ posso passare anche delle funzioni!\n\nMappo ogni grafo con il metodo map() e faccio un istogramma \ndella quantita’ ‘total_bill’.\n\nQueste quantita’ saranno limitata al valore di ‘time’ e ‘smoker’\ncorrispondente alla griglia!\n\nQuindi per esempio in alto a sx:\n\n  smoker = yes\n  time = lunch\n\n\nFaccio l’istogramma di tutti i ‘total_bill’ che si riferiscono a smoker e lunch.\n\nRicapitolando con FacetGrid definisco una griglia associata a due colonne,\nche formeranno le righe e le colonne della griglia. Per ogni valore di ciascuna\ndelle due colonne faccio un grafico riferito, ad una terza colonna\n\ntips_fg= sns.FacetGrid(tips_df, col='time', row='smoker')  # qui resta vuota.\n\n\n\n\nsns.set_context('paper', font_scale=1.5)\ntips_fg= sns.FacetGrid(tips_df, col='time', row='smoker')\ntips_fg.map(plt.hist, 'total_bill', bins=8 );                 # mappa la funzione plt.hist, sulla quantita 'total_bill' \n\n\n\n\ntips_fg= sns.FacetGrid(tips_df, col='time', row='smoker')\ntips_fg.map(plt.hist, 'day' )   \n\n\n&lt;seaborn.axisgrid.FacetGrid at 0x122685a3ac0&gt;\n\n\n\n\ntips_fg= sns.FacetGrid(tips_df, col='time', row='smoker')\ntips_fg.map(plt.scatter, 'total_bill', 'tip');\n\n\n\n\nNel caso sotto invece, facciamo una griglia che contiene solo colonne.\nNon ci sono righe, pero’ adesso usiamo il comando hue che ci permette di usare un colore diverso\nin base all’argomento usato. In questo caso uso come hue=’smoker’\n\nAggiungo un prametro, col_order che mi consente di ordinare le colonne. Basta mettere una lista contenente \nil nome delle colonne volute e l’ordine di quella lista sara’ seguito dal plot.\n\ntips_fg= sns.FacetGrid(tips_df, col='time', hue='smoker', height=4, aspect=1.3, col_order=['Dinner','Lunch']\n                      , palette='Set1')\ntips_fg.map(plt.scatter, 'total_bill', 'tip', edgecolor ='w');\n\n\n\n\nGli stili, le linee etc\n\n\n  creo quindi un dizionario, in cui ci sono i parametri, lo chiamo kws\n costruisco una Griglia faccettata (FacedGrid), in cui:\n  le colonne sono i valori di ‘sex’\n  punti che corrispondono a fumatori e non fumatori sono in colori diversi hue=’smoker’\n  altezza = 4  height=4\n  aspect = 1.3  (non ricordo cosa faccia)\n\n\na questo punto mappo la funzione plt.scatter sulla griglia faccettata, tramite map.\nAlla funzione map passo 3 parametri:\n\n  le x che sono ‘total_bill’\n  le y che e’ ‘tip’\n  kws    sintassi strana devo mettere due asterischi *, davanti al dizionario quando lo passo!\n\n\nHo trovato che non gli piace il fatto che definisca le colonne della FacetGrid tramite \nla variabile ‘sex’, forse perche’ e’ categorica? se metto time funge.\nHo trovato l’errore.\n\nIo non penso in modo “case sensitive”, nell’esempio si mette hue_order=['yes', 'No'], io\ninvece avevo preso tutto in minuscolo. Per questo non scriveva nulla: non c’era \ncorrispondenza tra:\n\n  i valori dello hue: Yes,No\n  i valori dello hue_order: yes, no\n\n\nAttento devi controllare che negli argomenti ci sia perfetta corrispondenza tra i nomi!\n\nDomanda cosa fanno i doppi asterischi davanti al dizinoario? \nRisposta fa un-packing dell’oggetto.\n\n\nkws = dict(s=50, linewidth=0.5, edgecolor ='w')  # ho creato un dizionario con 3 ingressi\n\ntips_fg = sns.FacetGrid(tips_df, col ='sex', hue='smoker', height=4, aspect=1.3, \n                        hue_order=['Yes', 'No'], \n                        hue_kws=dict(marker=['^','v']))   # triangolini in su e triangolini in giu'\n\ntips_fg.map(plt.scatter, 'total_bill', 'tip', **kws);     # nota sintattica, qui gli passo **\n\n\n\n\nAltro dataset: attention\n\nHo degli studenti, ne voglio mettere 5 per linea.\nPer fare questo indico solo quale sia la variabile che uso per le colonne\nPoi tramite col_warps=5 indico che devono esserci solo 5 colonne al max, poi\n va a capo lui automaticamente\n\n\n  numero di colonne per linea col_wrap=5\n  se non uso col_wrap=5 lui mette ogni valore di subject in una colonna diversa, ce ne sono 20…\n\n\natt_df = sns.load_dataset('attention')\natt_fg  = sns.FacetGrid(att_df, col='subject')\natt_fg.map(plt.plot, 'solutions', 'score', marker='.')\n\n\n&lt;seaborn.axisgrid.FacetGrid at 0x122692041f0&gt;\n\n\n\n\natt_fg  = sns.FacetGrid(att_df, col='subject', col_wrap=5, height=1.5)\natt_fg.map(plt.plot, 'solutions', 'score', marker='.')\n\n\n&lt;seaborn.axisgrid.FacetGrid at 0x1226863a4f0&gt;\n\n\n\n\natt_df.head(3)\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      subject\n      attention\n      solutions\n      score\n    \n  \n  \n    \n      0\n      0\n      1\n      divided\n      1\n      2.0\n    \n    \n      1\n      1\n      2\n      divided\n      1\n      3.0\n    \n    \n      2\n      2\n      3\n      divided\n      1\n      3.0\n    \n  \n\n\n\nRegression Plots\nUso tip data, faccio uno scatter plot con interpolazione.\n\nlmplot()  (linear regression?)\n\nFaccio due interpolazioni diverse per ognuno delle differenti hue\n\nplt.figure(figsize= (8,6))\nsns.set_context('paper', font_scale=1.4)\nsns.lmplot(x='total_bill', y='tip', hue='sex', data = tips_df, markers=['o', '^'], \n          scatter_kws={'s':100, 'linewidth':0.5, 'edgecolor':'w'});\n# regression plot\n\n\n&lt;Figure size 576x432 with 0 Axes&gt;\n\n\n\n\nQui sotto usa i comandi col e row per costruire una sorta di FacetGrid automatica, \ntramite la funzione lmlpot (che fa la regressione).\n\nAnche in questo caso  viene costruita una griglia.\n\nQuesta griglia seleziona i punti e poi per i punti che hanno le caratteristiche \nche combaciano con quelle della griglia si fa il regression plot\n\nsns.lmplot(x='total_bill', y='tip', col='sex', row='time', data=tips_df);\n\n\n\n\nSalvare le figure\nPer salvare i file si usano semplicemente le funzioni di Matplotlib.\nIn praticolare si deve:\n\n  chiamare una funzione che faccia un’immagine\n  subito dopo chiamare plt.savefig('nomeImmagine.eps')\n  cambiando l’estensione si ottengono file diversi, per esempio png, pdf,...\n\n\nsns.lmplot(x='total_bill', y='tip', col='sex', row='time', data=tips_df);\nplt.savefig('prova.pdf')\n\n\n\n\nSubplots (Matplotlib)\nquesto e’ piu’ correlato con matplotlib, comunque e’ utile anche in questo notebook.\n\n#import pandas as pd\n#import seaborn as sns\n#from matplotlib import pyplot as plt\npokemon = pd.read_csv('pokemon.csv')\n#p_df.head()\n\n# bulbasaur = pokemon[['Name', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']][pokemon.loc[:, 'Name'] == 'Bulbasaur']\npoke_num = pokemon[['Name', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']].set_index('Name')\n\nbulbasaur = poke_num.loc['Bulbasaur']\ncharmander = poke_num.loc['Charmander']\nsquirtle = poke_num.loc['Squirtle']\n\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\nfig.suptitle('Initial Pokemon - 1st Generation')\n\n# Bulbasaur\nsns.barplot(ax=axes[0], x=bulbasaur.index, y=bulbasaur.values)\naxes[0].set_title(bulbasaur.name)\n\n# Charmander\nsns.barplot(ax=axes[1], x=charmander.index, y=charmander.values)\naxes[1].set_title(charmander.name)\n\n# Squirtle\nsns.barplot(ax=axes[2], x=squirtle.index, y=squirtle.values)\naxes[2].set_title(squirtle.name)\n\n\nText(0.5, 1.0, 'Squirtle')\n\n\n\n\ntips_df = sns.load_dataset('tips')\n\n#fig, axes =plt.subplots(1,3, figsize=(15,5), sharey=True)\nfig, axes =plt.subplots(1,3, figsize=(15,5))\nsns.stripplot( ax=axes[0] ,x='day', y='total_bill', data=tips_df, palette='magma')                # FUNGE \nsns.stripplot( ax=axes[1], x='day', y='total_bill', data=tips_df, jitter=True, palette='PuOr')    # FUNGE \nsns.stripplot( ax=axes[2], x='day', y='total_bill', data=tips_df, jitter=True, palette='winter')  # FUNGE\n\n#sns.stripplot( x='day', y='total_bill', data=tips_df)                # NON FUNGE \n#sns.stripplot( x='day', y='total_bill', data=tips_df, jitter=True)   # NON FUNGE \n#sns.stripplot( x='day', y='total_bill', data=tips_df, jitter=True)   # NON FUNGE\n\n\n&lt;AxesSubplot:xlabel='day', ylabel='total_bill'&gt;"
					}
					
				
			
		
			
				
					,
					
					"matplotlib": {
						"id": "matplotlib",
						"title": "Matplotlib - appunti",
						"categories": "italiano",
						"url": " /Matplotlib",
						"content": "Matplotlib\n\nQueste sono le mie (Paolo Avogadro) note, basate su questo \nvideo di Derek Banas. Oltre agli esempi suggeriti aggiungo dei miei test e considerazioni.\nQualunque errore e’ esclusivamente dovuto ad una mia erronea interpretazione dei comandi. Lo scopo di queste note non e’ di\npresentare esempi perfettamente funzionanti, ma serve a me come spunto per ricordare i comandi di Matplotlib, e il modello mentale che io ho sul pacchetto.\n La versione originale di queste note ha la forma di un Jupyter Notebook\ne quindi possono esserci dei riferimenti ai notebook all’interno del testo\n\nCerco di ricostruire gli esempi presentati e fare delle piccole varianti per capire meglio. Queste note suppongono che ci sia una certa conoscenza di base di come fare i grafici al computer, per esempio partendo da Gnuplot.\n\nNotazione:\n\n  cerco di usare l’evidenziatore per i comandi\n  cerco di usare il grassetto per i termini principali\n\n\nMicro-riassunto:\n\nCi sono 2 modi principali per fare un grafico:\n\n  \n    modo veloce: con le funzioni di plotting, per esempio: plt.plot(x_1, y_1) (dove x_1 e x_2 sono due oggetti contenenti lo stesso numero di variabili). Si possono inoltre aggiungere delle funzioni per controllare le label, il titolo ecc.\n  \n  \n    modo esteso:\n    \n      prima si definisce una figure, per esempio: fig_1 = plt.figure(figsize=(5,4), dpi =100); pensa alla figure come un’immagine bianca.\n      poi si costruisce uno (o piu’) axes (assi) con un metodo delle figure: axes_1 = fig_1.add_axes([0.1,0.1,0.9,0.9]) (dove specifichiamo la posizione degli assi all’interno della figura). Gli assi determineranno la posizione del grafico. Per esempio se hai un solo quadrante per il tuo grafico puoi immaginare gli assi come un rettangolo (vuoto all’interno).\n      A questo punto si fa partire un grafico, usando un metodo degli assi, per esempio: axes_1.plot(x_1,y_1);  Nota che questi metodi sono in pratica le stesse funzioni del punto 1 (solo che vengono chiamati come metodi dell’asse).\n    \n  \n\n\nNota\n\n  se non sei in un jupyter notebook dovrai usare un plt.show()\n  se sei su un notebook invece, serve un magic command (e’ una di quelle cose decorate con il percentuale),  ci sono vari di questi comandi, tra cui:\n    \n      %matplotlib inline   (questo fa apparire delle immagini png statiche nel notebook)\n      %matplotlib notebook (si possono fare zoom delle immagini)\n      %matplotlib tk  (tkinter GUI)\n    \n  \n\n\nUna lista di termini utili:\n\n\n  alpha=0.75 definisce la trasparenza\n  lw=2  larghezza delle linee del grafico\n  ls ='-.' line style, se e’ una linea continua, oppure trattino e punto, ecc…\n  marker = 'o' marker sono i punti di gnuplot. Cosa viene messo nei punti? in questo caso dei cerchietti =o)\n  markersize=7 la grandezza dei punti\n  markerfacecolor ='y' il colore dell’interno dei punti\n  markeredgecolor='k' il colore dei contorni dei punti\n  markeredgewidth=2 la larghezza del contorno dei punti\n  projection='3d' argomento per quando si creano degli assi e devono avere un 3D\n  goog_df = pd.read_csv('GOOG.csv', index_col = 0, parse_dates=True) trasforma del testo in datetime!\n  facecolor e’ il colore dello sfondo di un’immagine\n\n\nMetodi di FIGURE:\n\n\n  fig.tight_layout() oppure,  plt.tight_layout() serve per evitare sovrapposizioni per esempio i numeri degli assi trasbordino\n  fig_3.savefig('ultimoPlot.png') salvare a file una figura!\n\n\nMetodi degli Assi\n\n\n  plt.xticks(np.linspace(0,5,5), ('Tom', 'Dick', 'Harry', 'Sally', 'Sue'))  tics (o ticks) sull’asse x. Per non avere ticks: plt.xticks([]) (non ho messo nulla nella lista = non ci sono ticks)\n  axes_3.set_xlim([0,3])  definisce i limiti sull’asse x (set xlim[1:100])\n  axes_4.set_xlabel('temp')               label degli assi\n  axes_3.grid(False, color='r', dashes=(0,2,1,2)) mette una griglia sullo sfondo, occhio che color e’ il colore della griglia non dello sfondo. plt.grid(False) e plt.grid(b=None) tolgono la griglia\n  axes_3.set_facecolor('w') colore dello sfondo (bianco in questo caso)\n  axes_4.set_title('da Pandas: IceCream') titolo\n  axes_1.legend(loc =0 )                      # Loc=0 e’ la migliore location scelta da lui`\n\n\nTipi di disegno (possono essere chiamati come metodi degli assi o funzioni plt):\n\n\n  axes_4.plot(x_2, y_2)  disegno standard in cui ci sono i punti e posso unirli, cambiarli ecc.\n  plt.bar(x_2, y_2, width=1.5); barchart (come istogramma ma sulle x possono essere categorici)\n  plt.stem(x_2, y_2, '-.') impulsi, interessante si puo’ indicare il tipo di linea\n  plt.hist(arr3ok, bins= 7, density=True, stacked =False); istogrammi (raggruppa i valori sull’asse delle x in bins)\n  plt.pie() piechart TORTE (gurada sotto perche’ servono un po’ di dettagli)\n  axes_13.scatter(dr_arr, test_arr,  s=cc_arr_sm, c=color_arr, alpha=0.2 ) scatterplot valori sull’asse delle x, y, dimensione punti, colori dei punti, trasparenza)\n  axes_9.scatter3D(x_3,y_3,z_3, c=z_3, cmap='Blues'); scatterplot 3D\n  axes_9.contour3D(x_4,y_4,z_4, 20, cmap='Blues'); 3D contorno, curve di livello, isoipse\n  axes_9.plot_wireframe(x_4,y_4,z_4, cmap='Blues'); wireframe e’ il grafico 3D standard di gnuplot, collega tutti i punti\n  axes_9.plot_surface(x_4,y_4,z_4, rstride=1, cstride=1,  cmap='Blues', edgecolor='r'); 3D, collega i punti e colora le tegole\n\n\nConsiglio:\nin un Jupyter notebook usa shift-tab su una funzione per vederne la sua descrizione (prima devi cliccare sulla cella e poi avere il cursore sulla funzione stessa).\n\nConsiglio questo articolo contiene trucchi su jupyter notebook e alternative a Matplotlib.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n#%matplotlib notebook\n%reload_ext autoreload\n%autoreload 2             \n\n\nFunctional Plot\nCominciamo con un’immagine semplice in cui\n\n  c’e’ il titolo: plt.title('ciao')\n  ci sono i nomi degli asssi:  plt.xlabel('Days')\n  c’e’ un grafico:  plt.plot(x_1, y_1)\n\n\nQuando faccio un disegno, voglio che tutte le coordinate x siano in un contenitore (lo stesso vale per le coordinate y).\nQuesti “contenitori” devono contenere lo stesso numero di oggetti, altrimenti per un punto avrei solo la coordinata x o solo la y… quindi mi manca il punto!\n\nx_1 = np.linspace(0,5,10)  # genera un Numpy array con 10 float equispaziati tra 0 e 5\ny_1 = x_1 **2              # genera un Numpy array che e' il quadrato del primo \nplt.plot(x_1, y_1);\nplt.title('ciao');\nplt.xlabel('Days');\nplt.ylabel('Days squared');\n#plt.show()                  # se non siamo in jupyter notebook\n\n\n\n\nDomanda: posso passare delle liste ad un plt.plot()?\n\nRisposta: si’ certo! posso anche graficare delle liste che contengano delle stringhe. Se il contenitore di stringhe e’ una lista, allora esiste un ordine per le stringhe e questo ordine verra’ usato nella visualizzazione. Per un set invece non esiste un ordine e si ha un errore TypeError: unhashable type: ‘set’\n\nl1= [1,2,3,4]\nl2= [3,4,5,6]\nl3= ['a','b','e','d']\nd1 = {\"apple\", \"banana\", \"cherry\"}\nplt.plot(l1,l3);\n#plt.plot(l1,d1)   # non funge!\n\n\n\n\nplt.subplot() molti grafici in modo veloce\nQui vediamo come mettere piu’ di un grafico vicino all’altro. Nel dettaglio usando subplot potremo costuire una griglia, in ogni casella della griglia verra’ messo un grafico.\n\nIl comando plt.subplot(1,2,1) fa questo tipo di lavoro.\n\n  il primo argomento e’ il numero di righe della griglia (in questo caso c’e’ solo una riga)\n  il secondo argomento e’ il numero di colonne della griglia .\n  il terzo argomento e’ l’indice del grafico. L’indice ci dice in quale casella della griglia stiamo mettendo il subplot. L’ordine seguito e’ lo stesso che si ha quando si legge: da SINISTRA a DESTRA da SOPRA a SOTTO.\n\n\nVediamo un esempio:\n\n# nota che se anche il terzo argomento e' 2 il grafico appare al primo posto, perche'\n# non ce ne sono 2! E' un po' come se cadesse a sinistra se ci sono dei buchi?\nplt.subplot(1,2,2)        # questo ci dice che abbiamo una riga e 2 colonne\nplt.plot(x_1,y_1, 'r');   # r = red \n\n\n\n\nplt.subplot(1,2,1)        # questo ci dice che abbiamo una riga e 2 colonne\nplt.plot(x_1,y_1, 'r')    # r = red \nplt.subplot(1,2,2)        # se metto 1 mi sovrappone con il primo ma mi dice che c'e' qualcosa di strano\nplt.plot(x_1,y_1, 'b')\n\n\n[&lt;matplotlib.lines.Line2D at 0x2de659e5c40&gt;]\n\n\n\n\nplt.subplot(2,2,1)        # \nplt.plot(x_1,y_1, 'r')    #  \nplt.subplot(2,2,2)        # \nplt.plot(x_1, y_1-y_1**2, 'b')\nplt.subplot(2,2,4)\nplt.plot(x_1, -y_1, 'g');\nplt.tight_layout()              # evita sovrapposizione dei numeri dei grafici!\n\n\n\n\nFigure e axes\n\n  Una figure e’ un oggetto su cui poi si mette il grafico  (lo vedo come la tela bianca su cui fare il disegno)\n  contiene tutti i ‘plot elements’\n  puo’ contenere molti axes (assi), che in pratica sono gli assi che definiscono il disegno vero e proprio, in quanto i punti sono riferiti agli assi.\n  posso definire la sua larghezza e lunghezza in inch (inch=2.54 cm), probabilmente posso cambiare scala: figsize=(5,4)\n  posso anche definire la risoluzione in dpi\n  ATTENTO se definisci il numero di dpi, quando lo visualizzi come un png, questo definisce la dimensione della figura a video! quindi sembra che figsize non funzioni!\n\n\nfig_1 = plt.figure(figsize=(5,4), dpi =100);\n\n\n&lt;Figure size 500x400 with 0 Axes&gt;\n\n\nAxes\n\nL’oggetto axes (come indica il nome) identifica la posizione, la forma, e tutte le caratteristiche degli ASSI di un grafico. Se non facciamo esplicitamente un grafico, ci saranno solo le due fracce perpendicolari (gli assi) con dentro nulla. Possiamo i plot (grafici) sono dei metodi degli assi! La logica e’ quindi che siano un oggetto in funzione di dove sono gli assi (e ha senso, quando uno fa un grafico su un foglio, prima disegna gli assi, e poi puo’ definire la posizione dei punti che compongono il grafico. In questo senso quindi il plot e’ stato definito come un metodo di un axes.\nNota che posso mettere piu’ di un axes su una singola figure. Anche questo e’ intuitivo, posso mettere 2 grafici sullo stesso foglio, poi i punti di un grafico saranno riferiti ad un paio di assi e quelli del secondo ad un altro paio di assi. Gli assi definiscono il sistema di riferimento “inerziale” che determina la posizione dei punti!\n\nGli assi vengono costruiti su una figure tramite questo metodo:\n\naxes_1 = fig_1.add_axes([0.1,0.1,0.9,0.9])\n\nSignifica che axes_1 sara’ un rettangolo il cui:\n\n  punto in basso a sx ha coordinate 0.1, 0.1 (rispetto a fig_1). Ovvero, la figure e’ un rettangolo, anche gli axes sono un rettangolo, il cui punto in basso a sinistra si trova nelle coordinate che sono il 10% delle x e il 10% delle y del punto in basso a sx della figure.\n  \n    punto in alto a dx ha coordinate 0.9,0.9 (rispetto a fig_1)\nIn questo modo ho un grafico che e’ piu’ piccolo del “canvas” definito da fig_1.\n  \n  (nel video) non e’ chiaro come ha fatto l’esponente 2 sulla x. Io devo usare i comandi Latex\n\n\nAttenzione, io avevo messo il comando fig_1 = plt.figure(figsize=(5,4), dpi =100) in una cella diversa \nda dove facevo il axes.plot. Per questo non vedevo nulla!! Bisogna creare la figura nella stessa cella di Jupyter!\n\nQuindi ricapitolando:\n\n  creo un oggetto figura    ( me lo immagino come un foglio bianco di una certa dimensione)\n  creo un oggetto axes che e’ ottenuto da un metodo della figura  ( e’ il grafico vero e proprio, definito dagli assi sopra, sotto e destra e sinistra. Al suo interno posso poi mettere dei disegni tramite il metodo plot)\n  tramite metodi di axes aggiungo delle caratteristiche come le label\n  tra i metodi di un axes c’e’ plot (e altri tipi di grafico che potrei fare direttamente con plt). Chiamando un metodo che disegna da un axes, il grafico viene messo su questo axes.\n  posso aggiungere piu’ di un grafico sullo stesso axes, basta chiamare piu’ volte un metodo che disegna sull’axes.\n  nota che si deve fare un axes.plot per ognuno dei disegni che voglio compaiano nella figura!\n\n\nfig_1 = plt.figure(figsize=(5,4), dpi =100) # istanzio una FIGURA chiamata 'fig_1' \naxes_1 = fig_1.add_axes([0.1,0.1,0.9,0.9])  # istanzio un AXES (axes_1), della figura 'fig_1'\naxes_1.set_xlabel('Days new')               # LABEL degli assi\naxes_1.set_ylabel('Days squared new')       # LABEL degli assi\naxes_1.set_title('Ciao new')                # TITOLO degli assi\naxes_1.plot(x_1, y_1, label = 'x/x$^2$')    #  GRAFICO 1  (all'interno di axes_1)\naxes_1.plot(y_1, x_1, label = 'x^2/x')      #  GRAFICO 2  (all'interno di axes_1)\naxes_1.legend(loc =0 )                      # Loc=0 e' la migliore location scelta da lui\n# 1=alt dx; 2=alto sx; 3=basso sx, 4 basso dx \n# oppure si fornisce una tupla di x e y dall'angolo in basso a sinistra\ntu = (0.3, 0.4) # (tupla) questi valori sono in frazione rispetto alla grandezza totale, vedi sotto \naxes_1.legend(loc=tu );  # posizione della legenda\n\n\n\n\nMolte curve: versione veloce\nse devo fare un grafico veloce, basta che passo le x e y di tutti i grafici in ordine \nal plot, in questo modo verranno visualizzati tutti! Se non metto color='black' di default le due curve avranno colori diversi\n\nplt.plot(x_1, y_1, x_1, y_1/3);                   # disegna le 2 funzioni \n\n\n\n\nAxes innestati\nVoglio ora inserire piu’ di un axes nella stessa figura. In pratica aggiungo un axes all’esempio precedente.\n\nPer fare questo devo creare un altro axes, proprio perche’ in questo caso\ni dati si riferiscono ad assi diverse che devono essere definite.\n\nRicapitolando:\n\n\n  nell’esempio sopra ci sono una curva  blu e una arancione, sono comunque riferite allo stesso axes. Questi axes vanno da 0 a 25 (circa).\n  se voglio inserire una figura nuova, i punti di questa figura saranno riferiti a un nuovo sistema di assi, ho quindi bisogno di inserire questi nuovi assi, creando un nuovo oggetto axes (con un nome diverso)\n  dovro’ quindi indicare dove si collocano questi nuovi assi rspetto alla figure\n  dovro’ anche indicare la loro grandezza, anche in questo caso rispetto alla figure\n\n\nTesto nella figura\n\n  per inserire un testo nel disegno si usa il metodo text di axes.\n  Le coordinate sono riferite all’axes e partono dal basso a sinistra.\n  Nota che nel disegno sotto ho 2 axes, e il messaggio e’ riferito ad axes_2. Questo e’ ovvio perche’ e’ chiamato come un metodo di questo axes\n  Nota inoltre che axes_2.text(0,40,'message') fa uscire dal disegno, in quanto per il disegno l’asse delle y arriva solo fino a circa 25!\n\n\nnell’esempio di qui sotto:\n\n  il primo axis contiene due curve\n  il secondo axis contiene una curva\n\n\nfig_1 = plt.figure(figsize=(5,4), dpi =100)     # FIGURA 1\nassi_1 = fig_1.add_axes([0.1,0.1,0.9,0.9])      # ASSI_1 \nassi_1.set_xlabel('Days new')           \nassi_1.set_ylabel('Days squared new')\nassi_1.set_title('Ciao new')\nassi_1.plot(x_1, y_1, label = 'x/x$^2$')        #  GRAFICO 1 (degli \"ASSI_1\")\nassi_1.plot(y_1, x_1, label = 'x^2/x')          #  GRAFICO 2 (degli \"ASSI_1\")\nassi_1.legend(loc =0 )                          # Loc=0 e' la migliore location scelta da lui\n\n########   costruisco i secondi assi #####################\nassi_2 = fig_1.add_axes([0.45, 0.45,0.4,0.3])   # ASSE 2\nassi_2.set_xlabel('Days new')                      \nassi_2.set_ylabel('Days squared new')\nassi_2.set_title('Ciao dentro')\nassi_2.plot(x_1, y_1, 'r')  #  GRAFICO 2        # GRAFICO 1 (degli \"ASSI_2\")  \n\n\n#assi_2.text(0,40, 'Message')  # testo\nassi_2.text(0,40, 'Message')  # testo\n\n\n\nText(0, 40, 'Message')\n\n\n\n\nsubplots() Una griglia di grafici\n\nOCCHIO:  plt.subplots()$\\neq$plt.subplot() (il primo termina in s)\n\nIl singolo comando subplots in pratica costruisce 2 oggetti:\n\n  una figure\n  una array di assi (ma un array di numpy puo’ contenere degli oggetti strani? non erano solo numeri? no! basta che in tutti gli oggetti siano dello stesso tipo:  omogeneita’ degli array).\n  devo quindi descrivere/inizializzare ognuno dei possibili axes dell’array, altrimenti ho solo gli assi senza nessun disegno dentro.\n\n\nIn pratica e’ una specie di scorciatoia per ordinare facilmente degli axis in una figure in modo che siano esattamente alle posizioni della griglia che viene definita con il comando, per esempio indicando il numero di colonne e di righe. Altrimenti avrei potuto istanziare una figura, e istanziare tanti axes stando attento a metterli nel posto giusto all’interno della figura.\n\nAttenzione se voglio mettere degli axes aggiuntivi (oltre all’array di axes iniziale), posso farlo, occhio pero’ che si riferiranno tutti alla figure per quanto riguarda la posizione e non avranno un particolare ordinamento o forma. Dovro’ essere io a stare attento a metterli nel posto corretto e con la forma corretta!\n\n\n  \n    il comando plt.tight_layout() aiuta a non fare sovrapporre le label.\n  \n  Attento che devi usare il nome della figura corretto fig_2\n  Attento: non usare un nome gia’ usato per un altro axes, come axes_2\n  Attento: la dimensione del subplot e’ riferita al figsize, non all’axes di cui e’ subplot. Per questo trasborda!\n  Attento: se costruisci un nuovo axes viene messo sopra l’axis genitore, e per questo lo (puo’) coprire.\n  Di default un axes non e’ trasparente!\n\n\nfig_2 , axes_2 = plt.subplots(figsize=(8,4), nrows=1, ncols= 3) \nplt.tight_layout()                    # evita la sovrapposizione delle label\naxes_2[1].set_title('Plot 2')\naxes_2[1].set_xlabel('x')\naxes_2[1].set_ylabel('x quadro')\naxes_2[1].plot(x_1, y_1)\n\n# Nuovo AXES che non fa parte dell'array creato con   subplots\n\naxes_3 = fig_2.add_axes([0.45, 0.45,0.4,0.4])\naxes_3.set_xlabel('Days new')\naxes_3.set_ylabel('Days squared new')\naxes_3.set_title('Ciao straripante')\naxes_3.plot(x_1, y_1, 'r')  #  GRAFICO 2\n\naxes = fig_2.add_axes ([0.085,0.15,0.2,0.7])\naxes.plot(x_1,y_1, 'co')\naxes.set_title('Dentro')\n\n\nText(0.5, 1.0, 'Dentro')\n\n\n\n\nf , a = plt.subplots(figsize=(8,4), nrows=1, ncols= 3) \nplt.tight_layout()          \n\n############ Axes Centrale ###############\na[1].set_title('Centrale')\na[1].set_xlabel('x')\na[1].set_ylabel('x quadro')\na[1].plot(x_1, y_1)\n\n############ Axes Ciao Dentro ############\na1 = f.add_axes([0.45, 0.45,0.4,0.4])\na1.set_xlabel('Days now')\na1.set_ylabel('Days squared new')\na1.set_title('Tra centro e sinistra')\na1.plot(x_1, y_1, 'r')  #  GRAFICO 2 della figura centrale\n\n############ Axes Sinistro ###############\na[0].set_title('Sinistra')\na[0].set_xlabel('x')\na[0].set_ylabel('x quadro')\na[0].plot(x_1, -y_1,'g')\n\n############ Axes Piccolo sinistra  ######\na0 = f.add_axes([0.1, 0.25,0.2,0.2])\na0.set_xlabel('Days old')\na0.set_ylabel('Days squared new')\na0.set_title('Piccolo Sinistra')\na0.plot(x_1, y_1, 'r')  #  GRAFICO 2 della figura centrale\n\n\n[&lt;matplotlib.lines.Line2D at 0x2de66e3a190&gt;]\n\n\n\n\nColori e Apparenza\nI colori di default sono:\n\n  r = red\n  c = cyan\n  m = magenta\n  y = yellow\n  k = black\n  w = white\n\n\nInoltre\n\n\n  color=”0.75” crea un 75% gray  (e’ una percentuale di black)\n  si possono usare i colori con hexcodes   color=”#eeefff”\n  \n    si possono usare i colori tipo color=”burlywood” che si trovano a https://en.wikipedia.org/wiki/Web_colors\n  \n  lw come gnuplot, ma devo mettere l’uguale, p.es. lw=2\n  ls ‘-.’  si trovano qui: https://matplotlib.org/3.1.0/gallery/lines_bars_and_markers/linestyles.html\n  marker sono i punti: https://matplotlib.org/3.3.3/api/markers_api.html\n  markersize = grandezza del punto\n  markerfacecolor = colore di riempimento del punto\n  makeredgecolor  = colore del bordo del punto\n\n\nfig_3 = plt.figure(figsize=(6,4))\naxes_3  = fig_3.add_axes([0,0,1,1])\naxes_3.plot(x_1, y_1, color='navy', alpha=0.75, lw=2, ls ='-.', marker = 'o', \n           markersize=7, markerfacecolor ='y', markeredgecolor='k', markeredgewidth=2)\n\n\n[&lt;matplotlib.lines.Line2D at 0x2de66eaa970&gt;]\n\n\n\n\nGrandezza degli assi e background\nI comandi per gestire gli assi  assomigliano a quelli di gnuplot, ma solo un po’ piu’ “verbose”, in cui\nsi deve scrivere di piu’.\n\nPossimo anche mettere una griglia e il background color.\n\n\n  axes_3.set_xlim([0,3])                           limiti asse x\n  axes_3.grid(True, color='0.6', dashes=(5,2,1,2)) caratteristiche della griglia (NON dello sfondo!), dashes mette delle linee tratteggiate attraverso il disegno. Quindi qui sono le righe che partono da un tic e arrivano dall’altra parte del disegno\n  axes_3.set_facecolor('#FAEBD7')                  colore di sfondo\n\n\nfig_3 = plt.figure(figsize=(3,4) )\naxes_3  = fig_3.add_axes([0,0,1,1])\naxes_3.plot(x_1, y_1, color='navy', alpha=0.75, lw=2, ls ='-.', marker = 'o', \n           markersize=7, markerfacecolor ='y', markeredgecolor='k', markeredgewidth=2)\n\naxes_3.set_xlim([0,3])\naxes_3.set_ylim([0,25])\n\n#axes_3.grid(True, color='0.6', dashes=(5,2,1,2))   # mettiamo una griglia non lasciamo vuoto \naxes_3.grid(False, color='r', dashes=(0,2,1,2)) \n\n#axes_3.set_facecolor('#FAEBD7')\naxes_3.set_facecolor('w')\n\n\n\n\n\nSalvare una figura a file\nstrano quando lavoravo con Seaborn sembrave che il save dovesse avvenire nella stessa cella dove si faceva il disegno.\n\n  Basta mettere il nome dell’estensione e lui salva correttamente nel formato corrispondente\n\n\nfig_3.savefig('ultimoPlot.png')\n\n\nPandas\nQui usiamo l’ICE CREAM data table (che diventera’ un DataFrame). Ho copiato il dataframe del video.\n\n\n  \n    Assegno dei nomi alle colonne del csv, mentre leggo il file: ics_df = pd.read_csv('icecream.csv', names=['temps', 'sales'])  . Nota che io ho usato i nomi sales  e temps (temperatures). Lui li aveva con la prima lettera in maiuscolo. Temp e’ in Farenheit, e sales e’ in unita’ di gelato.\n  \n  \n    Se non usassi il parametro names=... lui prenderebbe la prima riga e la trasformerebbe nei nomi delle colonne (e i valori della prima riga non sarebbero accessibili)!\n  \n  \n    Osservazione: il metodo dei DataFrame sort_values(by='temps') lavora inplace, quindi modifica il df!\n  \n\n\nics_df = pd.read_csv('icecream.csv', names=['temps', 'sales'])\nics_df.head()\n\n\n\n\n\n  \n    \n      \n      temps\n      sales\n    \n  \n  \n    \n      0\n      37\n      292\n    \n    \n      1\n      40\n      228\n    \n    \n      2\n      49\n      324\n    \n    \n      3\n      61\n      376\n    \n    \n      4\n      72\n      440\n    \n  \n\n\n\nAttento sort_values() lavora inplace\n\nics_df = ics_df.sort_values(by='temps')  # LAVORA INPLACE\n\n\nA questo punto lui fa delle cose che sembrano non necessarie.  Prende e converte il DataFrame in un array di Numpy.\nPoi prende e scrive le x e le y da questo array di numpy. In effetti ho notato in una sezione sotto che alle volte e’ davvero meglio avere dei numpy array invece che i dataframe, in particolare per evitare dei valori strani sull’asse delle x.\n\n#   con numpy array ###############\n#  np_arr = ics_df.values    # prende solo i valori, rimuove le etichette\n#  x_2 = np_arr[:,0]         # seleziono colonna 0\n#  y_2 = np_arr[:,1]         # seleziono colonna 1  \n###################################\n\n\n# Alternativa:\nx_2 = ics_df.temps # non sono array di np, ma serie di Pandas vanno bene lo stesso\ny_2 = ics_df.sales # ricorda puoi usare l nome di una colonna per selezionare tutta le colonna come se fosse un attributo\n\n#x_2 = np.array(ics_df.temps) # NON serve... ora, ma in alcuni casi si'\n#y_2 = np.array(ics_df.sales) # NON serve... ora, ma in alcuni casi si'\n\n\nok ma fino a qui, dove ha usto il fatto che sia Pandas?\n\nfig_4 = plt.figure(figsize=(6,4))\naxes_4 = fig_4.add_axes([0,0,1,1])  # prendo tutto lo spazio, dall'angolo in basso a sx a quello in alto a dx\naxes_4.set_title('da Pandas: IceCream')\naxes_4.set_xlabel('temp')\naxes_4.set_ylabel('sales')\naxes_4.plot(x_2, y_2, marker='+');  # ho messo sui punti le crocette come in Gnuplot\n\n\n\n\nAnnotare la figura\nSe voglio mettere delle annotazioni nel grafico, come per esempio delle frecce, devo usare un metodo degli axes chiamato annotate. Vediamo nel dettaglio il comando:\naxes_4.annotate('Good Month', xy=(83, 536), xytext=(60,520), arrowprops= dict(facecolor='black', shrink=0.0, width=0.5))\n\n\n  'Good Month' e’ il testo che viene inserito\n  xy=(83,536)  e’ il punto di arrivo della freccia\n  xytext=(60,520) e’ il punto di partenza del testo orizzontale\n\n\nAll’interno di arrowprops si hanno vari parametri (si deve passare un dizionario con tutti gli argomenti)\n\n\n  facecolor= ‘black’\n  shrink=0.5   indica quanto piu’ corta deve essere la freccia, rispetto alla lunghezza massima che va dalla fine del testo al punto di arrivo della freccia.\n  width=0.5 possiamo anche allargare la larghezza\n\n\nfig_4 = plt.figure(figsize=(6,4))\naxes_4 = fig_4.add_axes([0,0,1,1])  # prendo tutto lo spazio, dall'angolo in basso a sx a quello in alto a dx\naxes_4.set_title('da Pandas: IceCream')\naxes_4.set_xlabel('temp')\naxes_4.set_ylabel('sales')\naxes_4.plot(x_2, y_2)\naxes_4.annotate('Good Month', xy=(83, 536), xytext=(60,520),\n                arrowprops= dict(facecolor='black', shrink=0.0, width=0.5))\n\n\nText(60, 520, 'Good Month')\n\n\n\n\nbar() Barchart sotto il grafico\nbar()  e’ un metodo di plt\n\nSe voglio fare aggiungere anche le barchart sotto il grafico, basta disegnare ANCHE loro!\n\nAttento ho fatto 2 plot:\n\n  il primo e’ dato da axes_4.plot(x_2, y_2) ed e’ passato come un metodo degli assi\n  il secondo e’ un grafico veloce ed e’ una funzione di matplotlib: plt.bar(x_2, y_2, width=1.5);\n\n\nfig_4 = plt.figure(figsize=(6,4))\naxes_4 = fig_4.add_axes([0,0,1,1])  # prendo tutto lo spazio, dall'angolo in basso a sx a quello in alto a dx\naxes_4.set_title('da Pandas: IceCream')\naxes_4.set_xlabel('temp')\naxes_4.set_ylabel('sales')\naxes_4.plot(x_2, y_2)\naxes_4.annotate('Good Month', xy=(83, 536), xytext=(60,520),\n                arrowprops= dict(facecolor='black', shrink=0.0, width=0.5))\nplt.bar(x_2, y_2, width=1.5);\n\n\n\n\nImpulsi stem()   e proprieta’ setp()\nIn gnuplot mettevo with impulses quando volevo che il grafico avesse delle linee verticali che partono dall’asse x e raggiungono ogni punto. Il comando descritto qui sopra bar() non e’ l’ideale per ottenere questo risultato in quanto la larghezza dell’impulso puo’ creare problemi, meglio usare la funzione:\n\nplt.stem()\n\nmentre posso decidere di colorare l’asse sotto tramite la funzione set property:\n\nplt.setp()\n\nQuesta funzione puo’ essere usata per vari oggetti!\n\nfig_4 = plt.figure(figsize=(6,4))\naxes_4 = fig_4.add_axes([0,0,1,1])  # prendo tutto lo spazio, dall'angolo in basso a sx a quello in alto a dx\naxes_4.set_title('da Pandas: IceCream')\naxes_4.set_xlabel('temp')\naxes_4.set_ylabel('sales')\naxes_4.plot(x_2, y_2)\naxes_4.annotate('Good Month', xy=(83, 536), xytext=(60,520),\n                arrowprops= dict(facecolor='black', shrink=0.0, width=0.5))\nmarkerline, stemlines, baseline = plt.stem(x_2, y_2, '-.')\nplt.setp(baseline, 'color', 'r', 'linewidth', 2)\n\n\n[None, None]\n\n\n\n\nTeX - regular expressions\npossiamo usare Latex per scriver formule matematiche usando per esempio $\\frac{1}{2}$\n\n\n  IMPORTANTE nota che nel tutorial ha usato: r'$\\alpha \\beta \\gamma$'  non ha semplicemente messo ‘’ perche’ cosi’ prende le regular expression,\ncome il dollaro e lo slash.\n\n\nOvvero la scrittura  r’ciao $\\frac{2}{3}’ crea una stringa che pero’ ha delle regular expression che vengono valutate ed eseguite.\n\n\n  basta poi ricordare i comandi di Latex\n  il metodo .text degli ‘axes’ mette ha all’inizio le coordinate (separate da una virgola), poi una virgola con il testo da inserire.\n\n\nfig_5 = plt.figure(figsize=(5,4), dpi=100)\naxes_5 = fig_5.add_axes([0.1, 0.1, 0.9, 0.9])                       # costruisco un axes\n\naxes_5.text(0,23, r'$\\alpha~ \\beta~ \\gamma ~ \\frac{1}{2} ~\\Sigma$') # prima le coordinate del testo, poi il testo\n\naxes_5.plot(x_1, y_1)\n\n\n[&lt;matplotlib.lines.Line2D at 0x2de66ff15e0&gt;]\n\n\n\n\nIstogrammi plt.hist()\n\nAlcuni argomenti utili per gli istogrammi:\n\n\n  stacked=True\n  \n\n\nSimuliamo probabilita’ di lancio di 2 dadi. Ci sono 11 possibili valori per la somma:\n\n  1+1 =2  I\n  1+2 =3  II\n  1+3 =4  III\n  1+4 =5  IV\n  1+5 =6  V\n  1+6 =7  VI\n  2+6 =8  VII  (nota che tutti gli altri valori di (2+qualcosa) danno dei risultati gia’ ottenuti)\n  3+6 =9  VIII\n  4+6 =10 IX\n  5+6 =11 X\n  6+6 =12 XI\nCome altri parametri:\n  density=True mostra la frequenza di ogni bin (se e’ falso mostra il conteggio)\n  stacked=True cosa fa?\n\n\nAttento: ricorda che il numero di bins puo’ portare a risultati MOLTO fuorvianti. Per esempio se scegliamo bins=7 otteniamo un oggetto bicefalo attorno al centro. Se invece scegliamo bins=11 otteniamo una campana!\n\narr_1 = np.random.randint(1,7,5000) # genera 5000 numeri interi tra 1 e 6\narr_2 = np.random.randint(1,7,5000) # genera 5000 numeri interi tra 1 e 6\narr_3 =arr_1+arr_2\n\n\narr3ok = arr_3\nplt.hist(arr3ok, bins= 7, density=True, stacked =False);\n\n\n\n\nplt.hist(arr_3, bins= 11, density=True, stacked =True);\n\n\n\n\nax[0].hist() Axes e istogrammi\n\nQui sotto provo a combinare axes e istogrammi.\n\n  Ho supposto di poter usare il metodo hist() direttamente su un asse invece che dover usare un plt.hist, ovvero:\naxes.hist(...)\n\n\nFunge!\n\nfig , ax = plt.subplots(figsize=(8,4), nrows=1, ncols= 2) \n#plt.tight_layout()          \nax[0].hist( arr_3, bins= 11, density=True, stacked =True);\nax[1].hist( arr_3, bins= 11, density=False, stacked =False);\n\n\n\n\naltri argomenti che si possono passare:\n\n  Range deve essere una tupla con il range di cui si e’ interessati\n  cumulative =True  costruisce la CDF (cumulative distribution function) dati i valori. Attento non me lo prendeva (diceva qualcosa riguardo l’oggetto kernel). Non ho lanciato tutte le altre celle, ma solo quelle iniziali con gli header e quelle della cella Istogramma\n  histtype= 'step' genera un grafo con le linee (ma vuoto)\n  color = 'orange' colora  di arancione…\n  orientation = 'horizontal'  gira di 90 gradi l’istogramma\nposso combinare anche due istogrammi insieme come con gli altri plot.\n\n\nplt.hist(arr_3, bins= 11, density=True, stacked =True, cumulative=True,\n         histtype='step', color='blue', orientation= 'horizontal');\n\n\n\n\nBar charts\n\nChe differenza c’e’ tra un grafo a barre e un istogramma? de facto nell’istogramma si mettono le frazioni e le “barre” sono attaccate l’una all’altra. In un bar chart invece si hanno i numeri e le barre non sono attaccate l’una all’altra, questo perche’ sull’asse delle x spesso non si hanno dei valori numerici, ma categorici (come nell’esempio riportato sotto, dove l’ordine delle colonne e’ sostanzialmente arbitrario).\n\nPer un grafo a barre, si chiama la funzione seguente:\n\nplt.bar(spc, m_eng,width=larghezza, label='maschi', edgecolor ='k')\n\n\n  il primo argomento contiene la lista/tupla con i nomi che appaiono sull’asse delle x (dato che spesso lo usiamo per variabili categoriche dobbiamo indicare le label), oppure le posizioni delle barre (se ho le posizioni dovro’ poi aggiungere le label sull’asse)\n  Attento se nella prima tupla ci sono dei nomi, allora le loro posizioni sono equispaziate automaticamente. Se io aggiungo un altro bar chart, questo secondo viene messo dopo quelle gia’ esistenti.\n  Attento se invece nella prima tupla ci sono dei float (che quindi definisce la posizione delle barre), allora facendo un secondo plot, quest’ultimo segue le proprie posizioni.\n  Attento pui mettere 2 bar chart, uno con variabili categoriche e uno con float. Le posizioni delle categoriche sono messe automaticamente in integer (che partono quindi da zero). Nell’esempio qui sotto, la barra di nuclear ha posizione sull’asse delle x uguale a 0, hydro e’ in posizione 1, …\n  il secondo argomento contiene l’array che con le altezze della barchart\n  yerr ???  serve per la barra che indica l’errore, ed e’ un array che deve contenere tanti oggetti quante sono le barre\n  width  larghezza della barra (altrimenti da’ errore? )\n  label non la vedo… scritta forse bisogna attivarla. Anche nel video non fungeva\n\n\n## energia francese\nx = ['nuclear', 'hydro', 'coal', 'gas', 'solar', 'wind', 'other']\nper_1 = [71,10,3,7,2,4,3]   # percentuale\nvariance = [8,3,1,3,1,2,1]  # varianza per anno\n\nplt.bar(x, per_1, color='purple',yerr=variance, label='prova')  \n\n\n&lt;BarContainer object of 7 artists&gt;\n\n\n\n\n## energia francese\nx = ['nuclear', 'hydro', 'coal', 'gas', 'solar', 'wind', 'other']\nper_1 = [71,10,3,7,2,4,3]   # percentuale\nvariance = [8,3,1,3,1,2,1]  # varianza per anno\nplt.bar(x, per_1, color='purple',yerr=variance, label='prova')  \ny = [el + '   ' for el in x]\nz = ['test1', 'test2', 'test3']\nz2 = [1, 2, 10]\nper_2 = [34,43,21]\nplt.bar(z2, per_2, color='red', label='prova') \n\n\n&lt;BarContainer object of 3 artists&gt;\n\n\n\n\ny\n\n\n['nuclear   ',\n 'hydro   ',\n 'coal   ',\n 'gas   ',\n 'solar   ',\n 'wind   ',\n 'other   ']\n\n\nBar Chart affiancate\nQui sotto mettiamo due bar chart affiancate una da parte all’altra. In questo modo possiamo confrontare dati diversi.\nE’ fondamentale che la posizione dell’array che definisce l’asse delle x della seconda bar chart sia spostato rispetto all’asse delle x della prima bar chart di una quantita’ tale da non fare sovrapporre (a meno di volerlo). Per esempio di puo’ usare lo stesso array maggiorato della larghezza della barchart!\n\nm_eng = (76,85,86,88,93)  # percentuale maschi ingegneri\nf_eng = (24,15,14,12,7)   # femmine\n\nspc = np.arange(5)\nlarghezza =0.45\nplt.bar(spc    , m_eng,width=larghezza, label='maschi', edgecolor ='k')\nplt.bar(spc+larghezza, f_eng,width=larghezza, label='femmine', edgecolor ='k')\n#plt.xticks(spc + larghezza/2, ('Aero', 'Chem', 'Civil', 'Elect', 'Mec'))\nplt.xticks(spc   , ('Aero', 'Chem', 'Civil', 'Elect', 'Mec')) ;   # altrimenti lo mette a meta' strada del primo istogramma\n\n\n\n\nBar Chart impilate (stacked)\n\nQui mettiamo le barre una sopra l’altra.\n\nDiamo un’occhiata alla list comprehension che viene usata:\n\nind = [x for x, _ in enumerate(t_type)]\n\n\n  enumerate restituisce delle coppie: posizione, oggetto.\n  Non ci serve l’oggetto ma solo la posizione, qunidi non spreco una variabile y, metto _\n  Prendi tutte le posizioni che ci sono nell’oggetto t_type\n  questa volta la label e’ apparsa nella legenda.\n\n\nATTENTO\n\n  il parametro bottom dice cosa c’e’ sotto di questa barchart. In particolare possiamo indicare un array, o anche una somma di array come nell’esempio di cui sotto. Se mettiamo un array che viene disegnato nella barchart, allora stiamo in pratica impilando il nuovo barchart sopra quello dell’altro array\n\n\n#############   DATI ######################\nt_type= ['kind', 'elem', 'sec', 'special']\nprint(type(t_type))\nm_teach = np.array([2,20,44,14])\nf_teach = np.array([98,80,56,86])\nn_teach = np.array([12,14,13,15])\n\nind = [x for x,_ in enumerate(t_type)]  # list comprehension. Vedi sopra per come si legge\n\n\nplt.bar(ind, n_teach, width=larghezza, label='nuovo', bottom=f_teach+m_teach) # posso metterne piu' di uno sotto\nplt.bar(ind, m_teach, width=larghezza, label='maschi', bottom=f_teach) # posso metterne piu' di uno sotto\nplt.bar(ind, f_teach, width=larghezza, label='femmine')\nplt.legend(loc='lower right');   # non ideale....\n#plt.legend(loc=0);                # manco questo... \n\n\n&lt;class 'list'&gt;\n\n\n\n\nTorte - Pie chart,  plt.pie()\n\nVediamo i diagrammi a torta.\nPer questi si usa il comando:\n\nwedges, texts, autotexts = plt.pie(poke_num, explode=explode, labels=types, colors=colors,\n                                  autopct='%1.0f%%', shadow=True,\n                                  startangle=140, textprops =dict(color='w'))\n\nDal punto di vista sintattico la funzione pie() restituisce 3 oggetti:\n\n  le wedges (gli spicchi o cunei del diagramma a torta).\n  i texts\n  gli autotext\n\n\nIn questo caso abbiamo prima costruito la figure, poi gli axes ed infine abbiamo chiamato la funzione pie.\nE’ un po’ diverso dal solito quando si usava un metodo dell’axes.\n\n\n  \n    Nota che in un diagramma a torta, intuitivamente, i valori di larghezza (angolo) associati ad ogni fetta vengono convertiti in percentuali dell’angolo giro. Questo perche’ ci si aspetta che tutti i valori di un array riempiano tutto il cerchio.\n  \n  \n    explode a questa keyword si deve passare un array di float con tanti ingressi quante sono le fette. Il valore di ogni ingresso dice di quanto viene “estratta” la fetta alla posizione corrispondente, vedi l’esempio sotto.\n  \n  \n    nell’esempio sotto ci sono 2 array: types e pole_num, questi devono avere il medesimo numero di ingressi.\n  \n  \n    labels=types e’ un parametro che indica le etichette associate ad ogni fetta\n  \n  \n    autopct indica come vengono arrotondati i numeri associati alle larghezze, gli si deve passare come valore una stringa che indica un formato.\n  \n  \n    shadow=true e’ il parametro che dice se mettiamo l’ombra\n  \n  \n    colori ha usato un trucco notevole, ha fatto scrivere dei valori in formato RGB tramite il generatore di numeri casuali. Tre numeri indicano un colore, e lui indicando il range dei colori tra [0, 0.5] ha fatto si’ che vengono scuri. Ha scelto i colori scuri perche’ la scritta viene in bianco!\n  \n  \n    Occhio, avevo fatto un errore di sintassi ma non semplice da osservare. Nell’array types che contiene dei nomi tra virgolette, in un caso, quando andavo a capo ho dimenticato di mettere una virgola tra un nome e l’altro e lui mi ha preso solo uno dei nomi\n  \n  \n    bbox_to_anchor = (1,0,0.5,1) serve per spostare di 1 e 1/2 a destra della piechart (???)\n  \n\n\nimport random\nfig_6  = plt.figure(figsize=(8,5))\naxes_6 = fig_6.add_axes([0.1,0.1,0.9,0.9])\n\n#Vogliamo un diagramma a torte\ntypes = ['water', 'normal', 'flying', 'grass', 'psychic','bug',\n        'fire', 'poison', 'ground','rock','fighting', 'dark', 'steel',  \n        'electric','dragon','fairy','ghost','ice']\n\npoke_num =[133, 109, 101, 98, 85, 77, 68, 66, 65, 60, 57, 54, 53, 51, 50, 50, 46, 40]\n\ncolors = []\nfor i in range(18):         # per il testo bianco genero i coloi delle fette in modo che siano scuri\n    rgb = (random.uniform(0,.5) , random.uniform(0,.5) , random.uniform(0,.5)  )\n    colors.append(rgb)\n    \nexplode = [0] * 18     # ho creato una lista di 18 zeri (non mi ricordavo questo modo!)\nexplode[0] = 0.2       # esplodi la prima fetta ma solo di 0.2\n\n#print(len(types));\n#print(len(poke_num));\n\nwedges, texts, autotexts = plt.pie(poke_num, explode=explode, labels=types, colors=colors,\n                                  autopct='%1.0f%%', shadow=True,\n                                  startangle=140, textprops =dict(color='w'))\n\nplt.legend(wedges, types, loc='right', bbox_to_anchor = (1,0,0.5,1)); #  sposto dalla piechart\n\n\n\n\nSerie Temporali\n\nQui vediamo come fare un grafico con una serie temporale in cui i vari punti sono etichettati con un timestamp.\nPuo’ essere necessario togliere dei giorni particolari e risulta piu’ comodo sapere la data piuttosto che trovare il punto corrispondente della time series.\n\nIl database usato viene da Yahoo riguardo i dati di google, GOOG.csv. (non e’ esattamente come mostrato nel video ma si trova in fretta). Per trovarlo cerca con google “yahoo google stock”, seleziona le date e fai download (nota che la frequenza e’ giornaliera).\n\nAll’inizio si carica il file con read_csv di Pandas, poi si trasforma la tabella in un array di numpy (sono tutti valori numerici). Lui usa un metodo dei DataFrame di Pandas che io non uso mai: tp_numpy(). Io invece faccio semplicemente np.array().\n\nHo provato a fare un giro piu’ semplice, cercando di plottare i dati direttamwente DAL DataFrame, di cui seleziono le colonne volute (ma avendo prima selezionato le righe, vedi sotto). Sfortunatamente sull’asse delle x vengono dei valori sballati come tics, il grafico e’ pero’ corretto. Questo e’ probabilmente il motivo per cui lui preferisce trasformare tutto in array di Numpy.\n\nScrubbing data: per esempio vogliamo togliere alcune vacanze, ha controllato due date che sono vacanze e vuole escluderlo.\nUsa datetime. La funzione datetime.datetime(2020,5,25) crea una data in un oggetto specifico, che puo’ poi essere trasformato a seconda delle esigenze, p.es g/m/a  o m/g/a ecc.\n\nPoi costruisce un array di date che vanno da una data iniziale ad una finale, tramite un metodo di pandas: pd.bdate_range, si puo’ passare il parametro frequency freq ='C' in questo caso, ma no so cosa sia il valore ‘C’!\n\nholidays e’ il nome di un altro parametro che appunto corrisponde alle vacanze e possiamo passare un array/tupla contentente dei dati in formato datetime che vengono riconosciuti. ATTENTO la mia versione non riconosce questo parametro. Ho riscritto tutto e ora funge.\n\nProblema: non so quando ha preso lui le date da Yahoo, io ho piu’ giorni.\n\nProblema2 se uso tutti questi giorni, i tics che vengono segnati sono troppi e sotto l’asse viene un guazzabuglio di linee. Devo modificare per ottenere le date corrette.\n\nimport datetime\n\n\ngoog_data = pd.read_csv('GOOG.csv')    # IMPORTO il file GOOG.csv che ho salvato nella dir corrente\ngoog_data_np = goog_data.to_numpy()    # trasformo in np.array\n#goog_data_np =np.array(goog_data)     # modo alternativo di trasformare\ngoog_cp = goog_data_np[:,4]\n\nholidays = [datetime.datetime(2020,5,25)  , datetime.datetime(2020,8,19) ] # creo una lista con due date che saranno vacanze\n\ndate_arr = pd.bdate_range(start ='5/20/2020' ,\n                            end ='8/19/2020' , \n                           freq ='C', \n                       holidays = holidays) \n\ndate_arr_np = date_arr.to_numpy()\ngoog_data.head(3)\n\n\n\n\n\n  \n    \n      \n      Date\n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n    \n  \n  \n    \n      0\n      2019-08-21\n      1193.150024\n      1199.000000\n      1187.430054\n      1191.250000\n      1191.250000\n      740700\n    \n    \n      1\n      2019-08-22\n      1194.069946\n      1198.011963\n      1178.579956\n      1189.530029\n      1189.530029\n      947500\n    \n    \n      2\n      2019-08-23\n      1181.989990\n      1194.079956\n      1147.750000\n      1151.290039\n      1151.290039\n      1687000\n    \n  \n\n\n\nSelezionare righe secondo delle date\n\nSeguo questo esempio per selezionare le date:\nhttps://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates\n\nCreo una mask per selezionare le date che voglio e che devono seguire quelle indicate nel bdate_range.\nIn pratica creo una maschera, ovvero un array di bool che poi posso passare a loc!\nIn questo modo solo gli ingressi in cui la maschera e’ vera vengono selezionati.\n\n\n  Problema I: devo paragonare delle date… in formati magari diversi\n  Soluzione I uso pd.to_datetime() che e’ una goduriosa funzione di Pandas che converte una stringa in un oggetto di tipo datetime. Questo oggetto e’ una data ed e’ possibile paragonare due datetime per vedere chi viene prima o dopo! Questa funzione e’ particolarmente VANTAGGIOSA in quanto riconosce tanti tipi diversi di formato in cui possiamo scrivere una data e li converte i un unico oggetto!\n  Alternativa usa parse_dates (vedi il Finance Module)\n\n\nUna volta ottenuto un modo per paragonare le date posso creare una lista con valori booleani in cui seleziono le date (basta un loop), chiamo questo oggetto maschera\n\n\n  Problema II la maschera cosi’ creata non e’ un oggetto iterabile che si possa mettere nel metodo loc di pandas. Devo tasformarlo in un oggetto non iterabile\n  Soluzione II basta costruire una funzione che prende come input qualcosa e quando lo sputa in output gli metto un tuple davanti!\n  DUBBIO ehi ma nel codice non ho usato la tupla, anzi se dove faccio finanza metto la tupla mi da errore, sembra che una Series di pandas vada bene\n\n\nAttenzione pero’ la maschera cosi’ creata e’ un oggetto mutabile e questo non puo’ essere usato come ingresso della funzione loc (di PANDAS) perche’ questa necessita oggetti immutabili da cui puo’ estrarre una hashtable.\n\nlink utili:\n\nloc: https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates\n\nto_datetime: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n\nconvertire lista in tupla: https://www.geeksforgeeks.org/python-convert-a-list-into-a-tuple/\n\n# PROBLEMA  I\n# qui sotto prendo la colonna Date del dataFrame\n# poi converto i valori ivi contenuti in un oggetto di tipo datetime con to_datetime\n# a questo punto li paragono ai valori entro cui voglio che siano le date, sempre\n# sfruttando la funzione di pandas pd.to_datetime\n\nmask = (   ( pd.to_datetime(goog_data['Date']) &gt;= pd.to_datetime('5/20/2020')) \n         &amp; ( pd.to_datetime(goog_data['Date']) &lt;= pd.to_datetime('8/19/2020')) )\n\n\n\n# PROBLEMA II\n# l'oggetto mask non  e' di tipo immutabile e quindi non puo' essere usato come iteratore\n# devo trasformarlo in unoggetto immutabile\n\ndef convert(list): \n    return tuple(list) \n\nmask_t= convert(mask)\n\n#print(type(mask_t) , 'tipo maschera')    # controllo\n#print(len(goog_data.loc[mask]))          # controllo che i due oggetti abbiano lo stesso numero di righe  \n\nnew = goog_data.loc[mask]   # loc NON lavora inplace &lt;===================\nnew_np = new.to_numpy()\ngoog_cp = new_np[:,4]       #  \n\n\n# PROBLEMA III \n# Costruisco un array con le date corrispondenti in modo che io possa poi disegnarle\n\nfig_7 = plt.figure(figsize=(8,5))  # creiamo la figura/canvas come al solito\naxes_7 = fig_7.add_axes([0.1,0.1, 0.9, 0.9])  # il grafico non copre tutta la figura, lasciamo un po' di padding\nplt.plot(date_arr_np, goog_cp);\n\n#plt.plot(new.Date, new.Close) # questo fa vedere sbagliato i tics sotto\n\n\n\n\n\nTabelle\n\nQuesto non e’ cosi’ interessante, la cosa che trovo piu’ utile e’ come girare le date sull’asse delle x.\nCopio il pezzo di notebook scritto da Banas qui sotto:\n\n# Format column data to 2 decimals\ngoog_data['Open'] = pd.Series([round(val, 2) for val in goog_data['Open']], \n                              index = goog_data.index)\ngoog_data['High'] = pd.Series([round(val, 2) for val in goog_data['High']], \n                              index = goog_data.index)\ngoog_data['Low'] = pd.Series([round(val, 2) for val in goog_data['Low']], \n                              index = goog_data.index)\ngoog_data['Close'] = pd.Series([round(val, 2) for val in goog_data['Close']], \n                              index = goog_data.index)\ngoog_data['Adj Close'] = pd.Series([round(val, 2) for val in goog_data['Adj Close']], \n                              index = goog_data.index)\n\n# Get most recent last 5 days of stock data\nstk_data = goog_data[-5:]\nstk_data\n\n# Define headers\ncol_head = ('Date','Open','High','Low','Close','Adj Close','Volume')\n\nstk_data_np = stk_data.to_numpy()\nstk_data_np\n\n# Add padding around cells in table\nplt.figure(linewidth=2, tight_layout={'pad':.5}, figsize=(5,3))\n\n# Get rid of axes and plot box\naxes_8 = plt.gca()\naxes_8.get_xaxis().set_visible(False)\naxes_8.get_yaxis().set_visible(False)\nplt.box(on=None)\n\n# np.full returns an array filled with 0.1\n# cm is a colormap object we are using to use a default blue color\n# matplotlib.org/3.1.0/tutorials/colors/colormaps.html\nccolors = plt.cm.Blues(np.full(len(col_head), 0.2))\n\n# Receives data, loc, list of column headers, column header color as array of colors\n# You can also add rowLabel, rowColours, rowLoc: Text alignment\nthe_table = plt.table(cellText=stk_data_np, loc='center', colLabels=col_head,\n                     colColours=ccolors)\n# Set table font size\nthe_table.set_fontsize(14)\nthe_table.scale(3, 2.5)\n\n\n\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:132: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations. \n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\nScatterPlot\nQui ci sono dei dati relativi al Coronavirus.\nE’ importante che ci sia uniformita’ di grandezza per quanto riguarda gli array che vanno plottati:\n\n  ci sono 26 nazioni\n  ci sono 26 tassi di mortalita’\n  ci sono 26 valori di casi confermati giornalieri\n  ci sono 26 dimensioni dei punti\n\n\nNota che i questo caso non costruisco la figura e poi gli assi. Questo perche’ viene fatto automaticamente dal comando plt.scatter. Ci sono 2 vie per ottenere lo stesso grafico:\n\n  costruisco la fig, e gli assi e uso scatter come metodo sull’asse creato\n  uso plt.scatter e lui automaticamente crea gli assi!\n\n\nArgomenti dello scatterplot:\n\n  prima si mettono i valori dell’asse delle x (e’ un np.array)\n  poi l’array per i valori dell’asse delle y (anche questo un np.array lungo quanto quello sopra)\n  s  per size (dei punti): NON e’ come gnuplot che accettava le abbreviazioni, qui il parametro si chiama SOLO s!\n  c  per color (dei punti)\n  alpha e’ in pratica il livello di trasparenza, in questo caso e’ fondamentale in quanto alcuni punti andranno a sovrapporsi\n\n\n# Numpy array con i nomi delle nazioni\ncnt_arr = np.array(['Australia','Brazil','Canada','Chile','France','Germany','Greece',\n                   'Iceland','India','Iran','Italy','Mexico','New Zealand','Nigeria',\n                   'Norway','Pakistan','Peru','Russia','Saudi Arabia','Singapore',\n                   'South Africa','Spain','Sweden','Turkey','UK','US'])\n# Tasso mortalita per 100k casi Coronavirus\ndr_arr = np.array([1.8,53,24.5,56.5,45.4,11.2,2.2,\n                   2.8,4,24.6,58.6,46.3,.5,.5,\n                   4.9,2.9,83.3,11,10.4,.5,\n                   21.5,61.6,56.9,7.3,62.4,52.9])\n# Numero giornaliero di casi confermati (Tests)\ntest_arr = np.array([110,7197,600,1862,1636,1103,35,\n                   10,295,1658,1226,2490,8,243,\n                   48,1395,1101,4447,1443,280,\n                   2830,1602,447,1205,1546,24988])\n# Dimensione del punto dei casi confermati\ncc_arr = np.array([24236,3456652,125408,390037,256534,229706,7684,\n                   2035,2836925,350279,255278,537031,1654,50488,\n                   10162,290445,549321,935066,302686,56031,\n                   596060,370867,85411,253108,323008,5529824])\n\ncc_arr_sm = cc_arr/1000 # rimpicciolisce a dimensione dei punti (?)\ncolor_arr= np.random.rand(26)\n\n# Se faccio questi sotto vengono aggiunti ad una figura aggiuntiva, non al mio scatterplot\n# questo perche' ho provato ad usare la strada per cui prima faccio la figura, aggiungo gli assi\n# e il disegno viene con un metodo!\n#plt.title('Mortalita per 100k vs. Casi confermati')\n#plt.xlabel('Mortalita per 100k')\n#plt.ylabel('Casi confermati')\n#plt.scatter(dr_arr, test_arr, s=cc_arr_sm, c=color_arr,alpha=0.5 )\n#plt.figure(figsize=(8,5))\n\n\nfig_13 = plt.figure(figsize=(8,5))\naxes_13 = fig_13.add_axes([0.1,0.1,0.9,0.9])\naxes_13.set_xlabel('Mortalita per 100k')\naxes_13.set_ylabel('Casi confermati')\naxes_13.set_title('Mortalita per 100k vs. Casi confermati')\n\naxes_13.scatter(dr_arr,       # valori sull'asse delle x\n                test_arr,     # valori sull'asse delle y\n                s=cc_arr_sm,  # valori che indicano la dimensione dei punti\n                c=color_arr,  # colori di ogni punto\n                alpha=0.2 );  # trasparenza 1 = no trasparenza, 0 = completamente trasparente\n\n\n\n\n3D\n\n\n  from mpl_toolkits import mplot3d  abbiamo bisogno di importare questo modulo\n  projection='3d'  quando si costruisce la figura si aggiunge questo parametro\n  fig_9 = plt.figure(figsize=(8,5), dpi=100) dpi=100 stranamente sembra avere un effetto sulla dimensione della figura, mentre sembra non prendere il parametro figsize! Probabilmente questo e’ dovuto al fatto che con %matplotlib inline mi mette le figure come dei png, cambiando il numero di punti questo cambia la dimensione dell’immagine a schermo. Per esempio dpi=100 e’ circa un terzo della figura con dpi=300\n  scatter3D la funzione per uno scatterplot 3D\n  c= z_3 se uso questo parametro per i colori, allora quelli piu’ in alto (asse z) avranno una sfumatura differente da quelli in basso\n\n\nScatter3D\n\nfrom mpl_toolkits import mplot3d\n\nfig_9 = plt.figure(figsize=(6,5), dpi=100)\naxes_9 = fig_9.add_axes([0.1,0.1,0.9,0.9], projection='3d')   # mette degli assi 3D\n\nz_3 = 40 *np.random.random(100)            # random:  sample dalla [0,1) uniforme\nx_3 = np.sin(z_3) * np.random.randn(100)   # randn\ny_3 = np.cos(z_3) * np.random.randn(100)   # randn: sample dalla N(0,1)\n\n#axes_9.scatter3D(x_3,y_3,z_3, cmap='Blues');\naxes_9.scatter3D(x_3,y_3,z_3, c=z_3, cmap='Blues');\n\n\n\n\n\n\nContour3D\n\nIn questo caso ho bisogno di una funzione z =z(x,y) questo perche’ lui deve poter sapere la altezza in ogni punto.\n\n\n  \n    per costruire una griglia rettangolare devo usare np.meshgrid:  x_4, y_4  = np.meshgrid(x_4, y_4) occhio che se non metto questo comando mi dice che c’e’ un errore!? Il motivo e’ semplice. meshgrid prende in ingresso due array 1 dimensionali e restituisce due array 2 dimensionali. In pratica ha fatto un prodotto cartesizano per ognuno dei punti del primo array creando una coppia con quelli del secondo array (e viceversa per il secondo array). Questo perche’ contour3D si aspetta delle matrici per le x e le y e anche le z, in quanto per ogni x e y c’e’uno z. Per capire meglio fai fare print(x_4) prima e dopo meshgrid e vedi la differenza.\n  \n  Angolo di vista, per cambiare: axes_9.view_init(45, 55). questo sposta l’angolo di vista di 45 gradi e lo ruota di 55\n  il 4to parametro indica il numero di linee. In pratica quante fette parallele al piano xy che vengono visualizzate, se metto 80 sono tante, se metto 20 sono poche\n\n\nfig_9 = plt.figure(figsize=(6,5), dpi=100)\naxes_9 = fig_9.add_axes([0.1,0.1,0.9,0.9], projection='3d')\n\ndef get_z (x,y):\n    return np.sin(np.sqrt(x**2+y**2))\n\nx_4 = np.linspace(-6,6,30)\ny_4 = np.linspace(-6,6,30)\n\n#print(x_4)   \nx_4, y_4  = np.meshgrid(x_4, y_4)\n#print(x_4)\n\n\nz_4 = get_z(x_4, y_4)\n\naxes_9.set_xlabel('x')\naxes_9.set_ylabel('y')\naxes_9.set_zlabel('z')\n\naxes_9.view_init(35, 30)  # angolo di visione, angolo di rotazione\naxes_9.contour3D(x_4,y_4,z_4, 20, cmap='Blues');\n\n\n\n\nWireFrame e surface\nIn questo caso vengono connessi tutti i punti da un segmento.\n-plot_wireframe(x_4,y_4,z_4, cmap='Blues') in questo caso non devo passare il numero di tagli paralleli all’asse xy, quindi non ha il 4to parametro.\n\n\n  edgecolor ='none' non colora i segmenti di collegamento (il wireframe)\n\n\nfig_9 = plt.figure(figsize=(6,5), dpi=100)\naxes_9 = fig_9.add_axes([0.1,0.1,0.9,0.9], projection='3d')\naxes_9.view_init(35, 30)  # angolo di visione, angolo di rotazione\n#axes_9.plot_wireframe(x_4,y_4,z_4, cmap='Blues');\n\naxes_9.plot_surface(x_4,y_4,z_4, rstride=1, cstride=1,  cmap='Blues', edgecolor='r');\n\n\n\n\n\nFinance Module\n\nper installare ho fatto:\n\n  anaconda prompt\n  pip install mpl_finance\n  pip install –upgrade mplfinance   # upgrade\n\n\nquesto modulo fa vedere le candele giapponesi ecc.\n\n\n  posso cambiare il nome dell’index: goog_df.index.name='Date' a questo punto l’index non si chiama piu’ index ma Date! \nmi pare di capire che questo sia necessario perche’ la libreria prenda correttamente il dataframe.\n\n\nCandele giapponesi\n\n  Attento se prendi tante date, non riesci a vedere le candele! devono essere poche per essere visibili.\n\n\ntrendlines\npossiamo mettere automaticamente delle medie mobili con il parametro:\n-type='ohlc', mav=4  # che significa che mette Open High Low Close e  la media mobile basata sui precedenti 4 punti,nota che possiamo tenere come type ‘candle’ (ma si vede meno bene)\n\n\n  altri tipi di medie mobili. mav=(3,5,7) e’ bene usare dispari, quindi fa vedere 3 medie mobili basate sui 3, 5 e 7 gg precedenti\n  il parametro volume=True va vedere i volumi giornalieri\n  mostrare non-tading days: show_nontrading=True\n\n\nparse_dates\n\n  parse_dates=true vuol dire che non prende le date come delle semplici stringhe ma le legge come date, infatti ora sono in formato Timestamp\n\n\nimport mplfinance as mpf\n\ngoog_df = pd.read_csv('GOOG.csv', index_col = 0, parse_dates=True)\n#type(goog_df.index[0])\ngoog_df.index.name='Date'\n\n#goog_df = pd.read_csv('GOOG.csv')\ngoog_df.head(3)\n\n\n\n\n\n  \n    \n      \n      Open\n      High\n      Low\n      Close\n      Adj Close\n      Volume\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2019-08-21\n      1193.150024\n      1199.000000\n      1187.430054\n      1191.250000\n      1191.250000\n      740700\n    \n    \n      2019-08-22\n      1194.069946\n      1198.011963\n      1178.579956\n      1189.530029\n      1189.530029\n      947500\n    \n    \n      2019-08-23\n      1181.989990\n      1194.079956\n      1147.750000\n      1151.290039\n      1151.290039\n      1687000\n    \n  \n\n\n\nmask = (   ( pd.to_datetime(goog_df.index) &gt;= pd.to_datetime('5/20/2020')) \n         &amp; ( pd.to_datetime(goog_df.index) &lt;= pd.to_datetime('8/19/2020')) )\n\nnew = goog_df.loc[mask]   # \n#mpf.plot(new, type='line')     # normali linee\n#mpf.plot(new, type='candle')   # candele giapponesi\n#mpf.plot(new, type='ohlc', mav=4)   # open high low close + moving average\nmpf.plot(new, type='ohlc', mav=(3,5,7), volume=True, show_nontrading=True)   # open high low close + moving average\n\n\n\n\nHeatmap\nho un array 2 dimensionale e voglio mostrarlo con dei colori invece che dei numeri.\n\n\n  symptoms sono i 4 tipi di malattia a cui si riferiscono i dati (dyspnea = short of breath)\n  dates sono i giorni in cui sono state fatte le osservazioni (sono 9 giorni)\n  symp_per sono il numero di pazienti per giorno per malattia e’ un array 4x9\n\n\nNota: pensavo che la heatmap di default mettesse delle righe bianche in mezzo alle caselle risultando molto poco chiara! in realta’ e’ una delle opzioni lasciate dal finance module!!!! (se faccio girare prima la casella sotto le righe bianche in mezzo non ci sono!)\n\n\n  Per la heatmap si deve usare subplots() (non figure)\n  Cosa fa il comando? prende la matrice che ha 0,3 righe, e 0,8 colonne. Per ognuna delle righe e delle colonne scrive un colore associato al numero dell’ingresso dell’array da disegnare.\n\n\nsymptoms = [\"Coronavirus\",\"Influenza\",\"Pneumonia\",\"Dyspnea\"]\ndates = [\"Jun28\",\"Jul05\",\"Jul12\",\"Jul19\",\"Jul26\",\"Aug02\",\"Aug09\",\"Aug16\",\"Aug21\"]\nsymp_per = np.array([[5.2, 5.5, 5.7, 5.6, 5.3, 5.1, 5.0, 4.9, 5.3],\n                    [3.5, 4.0, 4.3, 3.9, 3.5, 3.2, 2.7, 2.2, 2.0],\n                    [1.8, 2.2, 2.3, 2.2, 2.1, 1.9, 1.7, 1.4, 1.3],\n                    [1.0, 1.1, 1.1, 1.0, 0.9, 0.8, 0.8, 0.8, 0.7]])\n\n\nfig_10 , axes_10 = plt.subplots()\nim= axes_10.imshow(symp_per, cmap='Wistia')\n\n\n\n\ntics\n\nnon chiaro perche’ all’inizio metta un np.arange, dato che abbiamo gia’ un array con dates e symptoms:\n\n  ok: axes_10.set_xtics(np.arange(len(dates)) qui definisce la distanza (posizione) che devono avere i tics sulla mappa.\n  axes_10.set_xticlabels(dates) questo definisce cosa ci deve essere nei ticks\n  occhio che ticks ha la k\n  occhio i ticks vanno assegnati DOPO avere definito la figura e l’axes\n  giro i ticks di 45 gradi! plt.setp(axes_10.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor') (non chiaro l’anchor cosa faccia)\n\n\nfig_10 , axes_10 = plt.subplots()\nim= axes_10.imshow(symp_per, cmap='Wistia')\n\naxes_10.set_xticks(np.arange(len(dates)))       # posizione tics sull'asse x\naxes_10.set_yticks(np.arange(len(symptoms)))    # posizione tics sull'asse y\n                  \naxes_10.set_xticklabels(dates)                 # cosa viene mostrato ad ogni tic dell'asse x \naxes_10.set_yticklabels(symptoms)                 # cosa viene mostrato ad ogni tic dell'asse x \n                  \nplt.setp(axes_10.get_xticklabels(), rotation=45, ha='right');                  \n\n\n\n\n\nNumeri nelle caselle\nmetto qui anche i numeri dentro le caselle. Nota che usa un costrutto che non ho mai usato prima, chiama un metodo dell’axes dentro una funzione di matplotlib.\n\n-plt.setp(axes_10.get_xticklabels(), rotation=45, ha='right'); \n\n  chiama\n\n\nfig_10 , axes_10 = plt.subplots()\nim= axes_10.imshow(symp_per, cmap='Wistia')\n\naxes_10.set_xticks(np.arange(len(dates)))       # posizione tics sull'asse x\naxes_10.set_yticks(np.arange(len(symptoms)))    # posizione tics sull'asse y\n                  \naxes_10.set_xticklabels(dates)                 # cosa viene mostrato ad ogni tic dell'asse x \naxes_10.set_yticklabels(symptoms)                 # cosa viene mostrato ad ogni tic dell'asse x \n                  \nplt.setp(axes_10.get_xticklabels(), rotation=45, ha='right'); \n\nfor i in range(len(symptoms)):\n    for j in range(len(dates)):\n        text = axes_10.text(j,i, symp_per[i,j], ha='center', va='center', color='k', fontweight='bold')\n\n\n\n\n\n\nRiempire le aree tra curve\n\nci sono ottimi esempi al sito di matplotlib:\n\nhttps://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/fill_between_demo.html\n\nil metodo degli assi fill_between() permette di riempire quello che c’e’ tra una curva e l’altra.\n\nx = np.arange(0.0, 2, 0.01)           # le x\ny1 = np.sin(2 * np.pi * x)            # y1 = la funzione seno\ny2 = 1.2 * np.sin(4 * np.pi * x)      # y2 = funzione seno piu' larga e con maggiore frequenza\n\n\nfig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True)  \n\nax1.fill_between(x, 0, y1)          # riempie tra 0 e y1\nax1.set_ylabel('TRA y1 e 0')\n\nax2.fill_between(x, y1, 1)          # riempie tra y1 e 1 (quello che c'e' sopra y1) \nax2.set_ylabel('TRA y1 e 1')  \n\nax3.fill_between(x, y1, y2)         # quello che c'e' TRA y1 e sotto y2\nax3.set_ylabel('TRA y1 e y2')\nax3.set_xlabel('x')\n\n\nText(0.5, 0, 'x')\n\n\n\n\nsi possono mettere ulteriori condizioni per dare dei colori diversi tra le curve.\nIn particolare si aggiungono dei parametri logici.\n\nfig, (ax, ax1) = plt.subplots(2, 1, sharex=True)       # costruisce subplots\nax.plot(x, y1, x, y2, color='black')                   # disegna le 2 funzioni \nax.fill_between(x, y1, y2, where=y2 &gt;= y1, facecolor='green', interpolate=True)\nax.fill_between(x, y1, y2, where=y2 &lt;= y1, facecolor='red', interpolate=True)\nax.set_title('fill between where')\n\n# Test support for masked arrays.\ny2 = np.ma.masked_greater(y2, 1.0)\nax1.plot(x, y1, x, y2, color='black')\nax1.fill_between(x, y1, y2, where=y2 &gt;= y1,\n                 facecolor='green', interpolate=True)\nax1.fill_between(x, y1, y2, where=y2 &lt;= y1,\n                 facecolor='red', interpolate=True)\nax1.set_title('Now regions with y2&gt;1 are masked')\n\n\nText(0.5, 1.0, 'Now regions with y2&gt;1 are masked')\n\n\n\n\nTicks\nAl comando ticks possono essere passati degli argomenti per specificare:\n\n  rotation = 45 ruota di 45 gradi\n  se il primo ingresso e’ un np.array allora quelli sono i ticks (le posizioni)\n  se il secondo ingresso e’ una tupla, allora alle varie posizioni dei ticks vengono messi i valori della tupla\n  fontsize=24 viene passato\n\n\ncome al solito puoi passare piu’ di un parametro basta che sia separato dalla virgola!\n\nplt.plot(x_1,y_1)\n#plt.xticks(np.linspace(0,5,100))\n#plt.xticks(np.arange(15))\n#plt.xticks(np.arange(5), ('Tom', 'Dick', 'Harry', 'Sally', 'Sue'))\n#plt.grid(False, color='r', dashes=(0,2,1,2)) \nplt.grid(False) \n#plt.grid(b=None)\ndegrees = 45\nplt.xticks(rotation=degrees)           # Rotazione dei ticks \nmioArray= np.array([1,2,3,4,8])\n#plt.xticks(np.linspace(0,5,5), ('Tom', 'Dick', 'Harry', 'Sally', 'Sue'))\nplt.grid(True)                         # presenza della grid \nplt.xticks(fontsize=24)                # GRANDEZZA FONT\nplt.xticks(mioArray, ('Gino', 'Pino', 'Mino', 'Tino', 'Asdrubale'));\n\n\n\n\nAnimazioni\nTesto di riferimento:  https://riptutorial.com/Download/matplotlib-it.pdf\n\nLo ho scaricato ed e’ nella dir.\n\n\n  Bisogna importare anche la parte del package che fa animazioni.\n  Bisogna usare il metodo set_data() che assegna i valori delle x e y di un grafico\n\n\n%matplotlib notebook\nimport matplotlib.animation as animation\n\n\nTWOPI = 2*np.pi\nfig, ax = plt.subplots()                    # costruiamo una figura e un array di assi\nt = np.arange(0.0, TWOPI, 0.001)            # t =array di posizioni \ns = np.sin(t)                               # y = sin(t) \nl = plt.plot(t, s)                          # grafico  \nax = plt.axis([0,TWOPI,-1,1])               # assi\n\nredDot, = plt.plot([0], [np.sin(0)], 'ro')  # l'oggetto \"redDot\" disegna il punto rosso, all'inizio e' in zero\n\ndef animate(i):                             # questa funzione modifica i parametri del punto rosso\n redDot.set_data(i, np.sin(i))              # quindi il resto del grafico resta invariato!  \n return redDot,\n\n# create animation using the animate() function\nmyAnimation = animation.FuncAnimation(fig, animate, frames=np.arange(0.0, TWOPI, 0.01), \\\n interval=1, blit=True, repeat=True)\n\n\n&lt;IPython.core.display.Javascript object&gt;\n\n\n\n\nMio test di animazione\nvorrei fare estendere la funzione seno, in modo che ad ogni frame sia moltiplicata per una diversa ampiezza.\nAttenzione: ho provato a farlo girare molte volte e non andava. Ho resettato il kernel e ora sembra fungere.\nMi viene il dubbio che il problema fosse connesso a qualche cella che avevo lasciato attiva.\n\n\n  Curiosamente se metto i limiti degli assi il grafico non appare! Errore Ax e’ un array di assi!\n  interval=1  rallenta l’esecuzione del programma\n  frames sono tutti i vari prarametri che andranno a definire i frame\n\n\npossiamo ingrandire o diminuire la dimensione dei limiti:\nhttps://stackoverflow.com/questions/53423868/matplotlib-animation-how-to-dynamically-extend-x-limits\n\nTWOPI = 2*np.pi\n#fig, ax = plt.subplots()                    # costruiamo una figura e un array di assi\n\nfig = plt.figure()\nax = fig.add_subplot(111, autoscale_on=False, xlim=(0, 6.29), ylim=(-2, 2))\n\n\n#ax = plt.axis([0,TWOPI,-1,1])              # ATTENTO assi QUESTO BLOCCA set_xlim\n#ax.set_xlim([0,TWOPI])                     # ERRORE ax non e' un asse ma una tupla di assi!  \n#ax.set_ylim([-1,1])                        # ERRORE    \n\nt = np.arange(0.0, TWOPI, 0.001)            # t =array di posizioni \ns = np.sin(t)  \n# y = sin(t) \nplt.grid(False)\n\nnew = plt.plot(t, t)                        # bisettrice\nsecond = plt.plot(t,s/2)\ncurva, = plt.plot(t, s)                     # grafico  \n#ax = plt.axes(xlim=(0, 10), ylim=(-1, 1))\n\n\ndef animate(A):                             # questa funzione modifica i parametri del punto rosso\n curva.set_ydata(A *np.sin(t))              # quindi il resto del grafico resta invariato!  \n #print(A*np.sin(t))\n return curva,\n\nframes1 = np.arange(0.0,1.0,0.001)\nframes2 = np.arange(1.0,0.0,-0.001)\nframes = np.concatenate((frames1, frames2), axis=None)\n\n# create animation using the animate() function\n#myAnimation = animation.FuncAnimation(fig, animate, frames = np.arange(0.0, 1.0, 0.001), \\\n# interval=10, blit=True, repeat=True)\n\nmyAnimation = animation.FuncAnimation(fig, animate, frames = frames, \\\n interval=1, blit=True, repeat=True)\n\n\n&lt;IPython.core.display.Javascript object&gt;\n\n\n\n\nSlider interattivo\npossiamo modificare la figura tramite uno slider interattivo!\nIn questo caso non uso la funzione animate, perche’ la modifica viene fatta in base a cosa tocco sullo slider.\n\nfrom matplotlib.widgets import Slider\nTWOPI = 2*np.pi\nfig, ax = plt.subplots()\n\nA0 = .5                                       # valore iniziale ampiezza \nt = np.arange(0.0, TWOPI, 0.001)              # x del grafico \ns = A0*np.sin(t)                              # y del grafico  (iniziale)\n\nl, = plt.plot(t, s, lw=2)                     # grafico (da capire la virgola)\n\nax = plt.axis([0,TWOPI,-1,1])                 # assi (che non verranno toccate) ??? \naxamp = plt.axes([0.25, .03, 0.50, 0.02])     # non chiaro axIs e axEs\n\n# Slider\nsamp = Slider(axamp, 'Amp', 0, 1, valinit=A0) # SLIDER interattivo, si chiama  \"samp\"\n\ndef update(val):\n # amp is the current value of the slider\n amp = samp.val                               # valore corrente dello slider\n # update curve\n l.set_ydata(amp*np.sin(t))                   # fai update delle y della curva  \n # redraw canvas while idle\n fig.canvas.draw_idle()                       \n\nsamp.on_changed(update)                       # ridisegna la figura se muoviamo lo slider\n\n#plt.show()\n\n\n\n&lt;IPython.core.display.Javascript object&gt;\n\n\n\n\n0\n\n\nFoto\nVediamo come mostrare una immagine. Si passa un array 2D e questo viene convertito automaticamente, assegnando ai valori un colore. Per esempio:\n\nimmagine = np.array([ [1,0,0,0,1,0,0,0,1],\n                      [0,0,0,0,1,0,0,0,0],\n                      [0,0,0,0,1,0,0,0,0],\n                      [0,0,0,0,1,0,0,0,0],\n                      [0,0,0,0,1,0,0,0,0],\n                      [1,0,0,0,1,0,0,0,1]])\n\nplt.imshow(immagine)\n\n\n&lt;matplotlib.image.AxesImage at 0x2de6a38e640&gt;\n\n\n\n\nUnpacking\nquesto non e’ strettamente connesso con matplotlib….\n\nnumbers = [1, 2, 3, 4, 5, 6]\nfirst, *rest = numbers       # multiple assignment\nprint(rest)\nprint(first)\n\nd = dict(a=5,b=2,c=4)\n\n\n\n[2, 3, 4, 5, 6]\n1\n\n\nenumerate()\n\nfor o,_ in enumerate(d):\n    print(o)                # stampa l'ordine degli oggetti\n\n\n0\n1\n2\n\n\nfor _, o in enumerate(d):\n    print(o)                # stampa le chiavi del dizionario\n\n\na\nb\nc\n\n\nfor _, o in enumerate(d):\n    print(d[o])              # stampa i valori del dizionario\n\n\n5\n2\n4\n\n\nfor o in enumerate(d):\n    print(o)              # stampa le NUOVE coppie chiave-chiave vecchia costruite da enumerate()\n\n\n(0, 'a')\n(1, 'b')\n(2, 'c')"
					}
					
				
			
		
			
				
					,
					
					"pytorch-7": {
						"id": "pytorch-7",
						"title": "Pytorch 7 Recurrent Neural Network",
						"categories": "italiano",
						"url": " /Pytorch-7",
						"content": "tocIn this post\n  \n  \n\n  Recurrent Neural Network\n  RNN, GRU e LSTM    \n      Il Codice\n    \n  \n\n\n  \n\n\nIndice Globale degli argomenti tra i vari post:\n\n 1.1.                                    Indice degli argomenti.\n 1.1.                                      Introduzione e fonti.\n 1.1.                                  Lingo - Gergo utilizzato.\n 1.2.                                        Tensori in Pytorch.\n 2.1.                                      Chainrule e Autograd.\n 2.2.                                           Backpropagation.\n 3.1.                                          Loss e optimizer.\n 3.2.                                        Modelli di Pytorch.\n 3.3.                                      Dataset e Dataloader.\n 3.4.                                       Dataset Transforms.\n 3.5.                              Softmax e Cross-Entropy Loss.\n 3.6.                                       Activation Function.\n 4.1.                                Feed Forward Neural Network.\n 5.1.                               Convolutional Neural Network.\n 5.2.                                          Transfer Learning.\n 5.3.                                                Tensorboard.\n 6.1.                              I/O Saving and Loading Models.\n 7.1.                                  Recurrent Neural Networks.\n 7.2.                                            RNN, GRU e LSTM.\n 8.1.                                          Pytorch Lightning.\n 8.2.                                               LR Scheduler.\n 9.1.                                                Autoencoder.\n\nRecurrent Neural Network\n\nVideo,\n note e diapositive di Python Engineer.\n\nLezione  del MIT sulle RNN\n© Alexander Amini and Ava Soleimany  \nMIT 6.S191: Introduction to Deep Learning \nIntroToDeepLearning.com \n\nAttenzione alla notazione: il hidden-tensor non e’ un hidden layer del modello! E’ un tensore che viene usato per la predizione ma non e’ l’input!\n\nNota descrivo con qualche immagine in piu’ le RNN, LSTM e RCU nel prossimo capitolo.\n\nScopo: costruire una rete neurale ricorrente RNN, che prenda una dopo l’altra le singole lettere di un nome (ogni lettera sara’ un input) e alla fine dell’ultima lettera dica a quale lingua appartiene il nome\n\n\n  usiamo batch di dimensione 1  qui (1 lettera)\n\n\nLOGICA\n\n  un nome e’ una sequenza di lettere.\n  ogni lettera vine trasformata in un tensore-lettera che diventa parte dell’input della rete neurale.\n  Perche’ ho scritto solo parte dell’input? Perche’ l’input e’ una concatenazione di un tensore-lettera e un tensore-hidden!\n  la rete neurale restituisce in output a quale lingua appartiene la lettera … ma dato che in input c’e’ anche il tensore-hidden modificato dallo strato lineare (hidden tensor), c’e’ memoria delle lettere precedenti, quindi ha senso dire la lingua di appartenenza di una sola lettera: c’e’ comunque la memoria derivante dalle altre lettere ottenuta tramite il tensore hidden!\n  come secondo output la rete neurale emette anche un nuovo tensore-hidden (che verra’ usato al passo successivo, concatenandolo al  tensore-lettera successivo)\n  alla fine della parola mi deve dire di che lingua stiamo parlando.\n\n\nLe parole sono spezzate in modo da diventare sequenze di tensori, secondo la logica one-hot encoderd. Supponiamo di avere un alfabeto di 6 lettere: a, e, i, o, u, l.\n    La parola aiuola diventa la seguente sequenza di tensori 1D contennti 6 ingressi:\n\na= \n\n, i= \n\n, u= \n \n, o= \n \n, l= \n \n, a= \n\n\nQuanto appena fatto e’ un tipo di embedding, ovvero una trasformazione da un dominio (quello delle lettere in questo caso) ad un \nformato matematico (di grandezza fissa) che puo’ essere processato dalle reti neurali. Chiaramente esistono molti tipi di embedding\ndifferenti e possono avere un impatto importante sui risultati.\n\nIl tensore hidden invece ha una dimensione che fissiamo noi (nell’esempio 128), al passo 0 viene inizializzato con tutti 0, \nma ai passi successivi si popola perche’ lo strato lineare che costruisce le versioni successive del tensore hidden prende in ingresso sia il tensore combinato che il tensore della lettera. Per esempio se la lettera passata e’ la $a$ e il tensore-hidden e’:\nhidden = \n \n\n\nAllora il tensore-combinato = \n =\n \n(in questo esempio  il tensore combinato ha dimensione 6 + 128 (perche’ in questo esempio l’alfabeto per  l’one-hot encoring contiene solo aeioul, mentre la dimensione del tensore combinato nel video di Python Engineer e’ 57 +128, perche’ l’alfabeto da lui usato contiene tutte le maiuscole, le minuscole e alcuni segni di punteggiatura.\n\n\n\nOsservazione\nIl tensore che viene dato in pasto alla fully connected layer e’ la versione concatenata di:\n\n  one-shot encoded  (che ha dim 57 nel nostro caso, le maiuscole, minuscole e qualche segno di punteggiatura\n  hidden tensor (che ha dimensione 128, perche’ lo abbiamo scelto noi).\n\n\nQuesto tensore concatenato viene dato in pasto anche ad un’altra fully connected layer in modo da mantenere la\nmemoria di quanto e’ successo.\n\nNel video del MIT si dice che per fare il training di una RNN si usano la cosiddetta: BPTT (Backpropagation through time)\nocchio che nel nostro caso non mi pare che si faccia.  Nel dettaglio la backpropagation si fa sulla loss soltanto, e quindi l’hidden tensor e’ considerato come un input non come un peso. Per questo non mi e’ chiaro come venga aggiornato il tensore dei pesi che ho chiamato W2 nell’immagine.\n\nPROBLEMI\n\n\n  \n    ho provato a mandare tutto sul device CUDA ma rallenta! sospetto che sia perche’ copio sul device di volta in volta.\nIl tempo che impiega (su 5000 passi) e’ 23 s col device e 13 sulla cpu! Vediamo se riesco ad evitare di copiare le cose in GPU ogni passaggio per velocizzare il calcolo. Mettendo line_tensor e hidden prima ho guadagnao, ora sono 20 s (comunque piu’ lento che con la CPU)\n  \n  \n    Che strano: rifacendolo andare qualche giorno successivo ci mette 307 secondi! (sulla CPU) e se provo a farlo andare sulla GPU dice che ci sono problemiperche’ alcune cose sono su CPU e altre su GPU.  Seguendo le indicazioni ho messo line_tensor.to(device) e ora sembra fungere linea 188.\n  \n  \n    ho inserito tutto fino a quando fa “whole sequence/name” ma ottengo un errore non ben chiaro:\n“IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)”. Errore trovato: avevo scritto \ninout_tensor invece che input_tensor\n  \n  \n    Il tensore in uscita ha dimensione 128 invece che 18 (il numero di lingue) e non capisco perche’! Chiaro avevo scritto: \nself.i2o = nn.Linear(input_size + hidden_size , hidden_size) che quindi mi dava come dimensione di uscita del layer lineare hidden_size invece che output_size!\n  \n\n\nNote:\nNella lezione si fa uso di funzioni di aiuto “helper functions” (io all’inizio capivo alpha-functions…). Python Engineer le mette in un modulo, mentre io le ho riscritte all’inizio del codice qui sotto\n\n# dati https://download.pytorch.org/tutorial/data.zip\n\nimport io\nimport os\nimport unicodedata\nimport string\nimport glob       # ?\n\nimport torch\nimport random\n\n\n#  Helper Functions\n\n# Alfabeto minuscolo e maiuscolo\nALL_LETTERS = string.ascii_letters + \".,;''\"   # insieme delle lettere e della punteggiatura usata\nN_LETTERS  = len(ALL_LETTERS)\n\n# converti un UNICODE in ASCII grazie a https://www.stackoverflow.com/a/518232/2809427\n# in pratica trasforma le lettere accentate in lettere NON accentate\ndef unicode_to_ascii(s):\n    return ''.join( c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != \"Mn\" and c in ALL_LETTERS)\n\n# costuisce un dizionario \"category_lines\" e una lista di nomi per le varie lingue\ndef load_data():\n    category_lines = {}     # dizionario\n    all_categories = [] \n\n    def find_files(path):\n        return glob.glob(path)    # glob??? The glob module finds all the pathnames matching a specified pattern according to ...\n    \n    # leggi un file e spezzalo in linee\n    def read_lines(filename):\n        lines = io.open(filename, encoding='utf-8').read().strip().split('\\n')\n        return [unicode_to_ascii(line) for line in lines]\n    \n    for filename in find_files('data/names/*.txt'):\n        category = os.path.splitext(os.path.basename(filename))[0]\n        all_categories.append(category)\n    \n        lines = read_lines(filename)\n        category_lines[category]  =lines\n        \n    return category_lines, all_categories\n        \n# trova l'indice di posizione associato ad una lettera nalla parola\n\ndef letter_to_index(letter):\n    return ALL_LETTERS.find(letter)\n\n# trasforma una lettera in un tensore 1 x n letters (tensore riga)\n\ndef letter_to_tensor(letter):\n    tensor =torch.zeros(1, N_LETTERS)  \n    tensor[0][letter_to_index(letter)]=1\n    return tensor\n\n# trasforma una linea in una &lt;line_length x 1 x n_letters&gt;\n# o un array hon-hot letter\n\ndef line_to_tensor(line):\n    tensor = torch.zeros(len(line), 1, N_LETTERS)\n    for i, letter in enumerate(line):\n        tensor[i][0][letter_to_index(letter)]=1\n    return tensor\n\ndef random_training_example(category_lines, all_categories):\n    \n    def random_choice(a):\n        random_idx = random.randint(0,len(a)-1)\n        return a[random_idx]\n    \n    category = random_choice(all_categories)\n    line =random_choice(category_lines[category])\n    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n    line_tensor = line_to_tensor(line)\n    return category, line, category_tensor, line_tensor\n\n\n###############################################################################\n###############################################################################\n###############################################################################\n#print(ALL_LETTERS)\n#category_lines , all_categories = load_data()\n#print(category_lines['Italian'][:5])\n#print(letter_to_tensor('J'))                # trasforma la lettera J (maiuscola) in un tensore one-hot encoding (sono 1D con 57 ingressi)\n#print(line_to_tensor('Jones').size())       # Jones contiene 5 lettere, ognuna e' trasformata in un tensore 1D con 57 ingressi \n\n#test = line_to_tensor('Jones')\n#print(test)\n##################  ok sopra funge correttamente   ###################\n\n\n# ho gia'importato torch sopra\nimport torch.nn  as nn\nimport matplotlib.pyplot as plt\nimport time\n\n# from utils import ALL_LETTERS, N_LETTERS # qui non serve perche' fanno gia' parte di questo listato\n# from load_data, letter_to_tensor, ...  \n\n#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device('cpu')\n\n\n# esiste gia' un RNN in Torch, qui pero' lo creiamo da zero.\n\nclass RNN(nn.Module):  \n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.i2h = nn.Linear(input_size + hidden_size , hidden_size)   # ricorda che servono solo le dimensioni: dim tensore combinato, dim uscita\n        self.i2o = nn.Linear(input_size + hidden_size , output_size)   # input 2 output\n        self.softmax = nn.LogSoftmax(dim=1) # input ha dimensione 1,57, quindi softmax sulle colonne\n        \n    \n    def forward (self, input_tensor, hidden_tensor):\n        combined = torch.cat((input_tensor, hidden_tensor ),1)   #concatena input tensor e hidden tensor: nuova dimensione= input_size+hidden_size\n\n        hidden = self.i2h(combined)      # qui spara fuori l'oggetto hidden, i pesi di questo layer non sono l'oggetto hidden!\n        output = self.i2o(combined)      # qui indica la guess riguardo la nazione\n        output = self.softmax(output)    # qui usa la softmax per ottenere valori di probabilita'\n        return output, hidden            # restituisce sia l'output che l'hidden per il prossimo passo\n    \n    def init_hidden(self):                             # inizializza lo hidden_tensor alla dimensione hidden_size\n        return torch.zeros(1, self.hidden_size)\n\n\ncategory_lines, all_categories = load_data()  # chiave valore, nazione chiave, nome valore, e poi tutte le nazioni\nn_categories = len(all_categories)\n#print(n_categories)\n\nn_hidden  =128   # selto da me\nrnn = RNN(N_LETTERS, n_hidden, n_categories).to(device)  # qui ho inizializzato il modello, servono i parametri del costruttore\n\n\n\n# likelyhood di ogni nazione, vogliamo l'indice della categoria massima\ndef category_from_output(output):\n    category_idx  = torch.argmax(output).item()\n    return all_categories[category_idx]\n    \n#print(category_from_output(output))\n#print(output)\n\n####### facciamo il training ######\ncriterion = nn.NLLLoss()      # negative log likelihood loss\nlearning_rate = 0.005         #\noptimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n\n#  funzione helper che fa il training metto il tensore e la sua label\ndef train(line_tensor, category_tensor):    \n\n    hidden = rnn.init_hidden().to(device)                    # azzero l'hidden tensor iniziale\n    #        hidden = hidden.to(device)\n    #line_tensor = line_tensor.to(device)\n    for i in range (line_tensor.size()[0]): \n        # lunghezza del nome\n        #l2d = line_tensor[i].to(device)\n        \n#        output, hidden = rnn(l2d, hidden)\n        output, hidden = rnn(line_tensor[i], hidden)  # inserisco i 2 tensori di input: lettera one-shot e hidden\n     \n    category_tensor = category_tensor.to(device)\n    #output = output.to(device) # inventato da me ma da comunque errore\n    loss = criterion(output, category_tensor)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n\n    return output, loss.item()\n\n\n\n\ncurrent_loss = 0\nall_losses  = []\nplot_steps, print_steps = 100000, 100000\nn_iters = 100000\n\n\nsince = time.time()     # il momento d'inizio\nfor i in range (n_iters):\n    category, line, category_tensor, line_tensor = random_training_example(category_lines, all_categories)\n    \n    line_tensor = line_tensor.to(device)\n    \n    output, loss = train(line_tensor, category_tensor)\n    current_loss += loss\n    \n    if (i+1)% plot_steps == 0:\n        all_losses.append(current_loss /plot_steps)\n        current_loss =0\n        \n    if (i+1)% print_steps ==0:\n        guess = category_from_output (output)\n        correct = \"Corretto\" if guess == category else f\" Sbagliato ( {category})\"\n        print (f'{i} {i/n_iters*100} {loss:.4f} {line}/{guess}{correct}  ' )\n        \n        \n    if (i+1)% 100000 ==0:\n        print('Tempo impiegato ', time.time() -since)   \n        \n        \n#plt.figure()\n#plt.plot(all_losses)\n\n#############  data una stringa in ingresso \ndef predict(input_line):\n    print(f'\\n&gt; {input_line}')                        # la riscrive \n    with torch.no_grad(): \n        line_tensor  = line_to_tensor(input_line)     # trasforma in un tensore\n        \n        hidden = rnn.init_hidden()                    # crea lo stato iniziale vuoto da dare in pasto\n        \n        for i in range (line_tensor.size()[0]):       # gira sui tensori one-hot encoded\n            output, hidden = rnn(line_tensor[i], hidden)   # usa la rete neurale, uno dietro l'altro, cosi' hidden si aggiorna\n            \n        guess = category_from_output(output)          # Ottiene dal numero il nome della nazione\n        print(guess)                                  # stampa il nome della nazione \n    \n            \n########## qui si imparano molte cose #######\nwhile True:\n    sentence = input(\"Inserisci un nome (quit per terminare)\")      # scrive a video\n    if sentence  == 'quit':                     # esci dal ciclo se scrivi quit\n        break\n    predict(sentence)                           # usa la rete neurale e scrivi la predizione\n\n\n\n99999 99.99900000000001 1.3037 Woo/Chinese Sbagliato ( Korean)  \nTempo impiegato  319.30727434158325\nInserisci un nome (quit per terminare)quit\n\n\nRNN, GRU e LSTM\n\nIl video\ndi Python Enginner contiene un esempio di RNN. E’ basato fortemente sulle note\n di PyTorch.\n\nRecurrent Neural Networks cheatsheet di Stanford\ne’ molto completa e succinta! Probabilmente e’ la guida piu’ precisa, la matematica usa delle notazioni diverse dalle altre due \n(per esempio l’hidden tensor viene indicato con a), ma suppongo che sia la piu’ affidabile.\n\nIn questa guida \nillustrata delle LSTM e dell GRU si cerca di non mettere la matematica, ma ci sono delle gif animate.\n\nIn questa pagina vengono indicate anche le formule associate ai vari passaggi;\n   ma sospetto che le formule non corrispondano alle immagini (ha preso le immagini da qualche parte e le formule altrove). \nDi buono mette anche le formule per la backpropagation!\n\nIl Codice\n\nQui usiamo i moduli gia’ creati per Long Short Term Memory e per GRU. Si prende come punto di partenza il tutorial 13 di Python Engineer.\n\nInvece che guardare a tutta una immagine per volta vogliamo prendere una sequenza di righe\n\nUsiamo Architettura Many to 1 (molti input e un solo output)\n\nCommentando e decommentando le parti con GRU e LSTM si ottengono tutte e 3 le architetture.\n In realta’ sono solo 2 le righe che vanno cambiate tra GRU e RNN e 3 per LSTM (si deve mettere anche la cella)!\n\nNel codice qui sotto si fa una sorta di estensione rispetto al lavoro fatto nel capitolo 13 (Feed Forward NN )\n\nRNN di torch.nn.RNN e’ una Elman: \n\n\n  $h_t$ hidden state al tempo $t$\n  $h_{t-1}$ hidden state al tempo $t-1$ (eh… abbastanza ovvio)\n  $x_t$ input al tempo $t$\n  $W_{ih}$ sono i pesi che contribuiscono a $h_t$ dal tensore di input $x_t$\n  $b_{ih}$ sono i bias che contribuiscono a $h_t$ dal tensore di input\n  $W_{hh}$ sono i pesi che contribuiscono a\n  $b_{hh}$ sono i bias (non chiaro perche’ vengano distinti rispetto a b_{ih}, alla fine sono delle costanti…\n  $x_t$ vettore di input al tempo t\n  $\\hat{y}_t$ vettore di output al tempo t\n  $y_t$ le label vere (ground truth) al tempo t\n\n\n\n\nEmpirical Loss:\n\n  Quando si ha una RNN si hanno diversi output per ognuno dei “tempi” t\n  Si sommano i valori delle loss.\n\n\nok a questo punto pero’ dovrebbero anche esserci i pesi per l’output, nella formula sopra vedo solo l’equazione per l’hidden state.\n\nVediamo un grafico per LSTM:\n\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# device config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#device = torch.device('cpu')\n\n# Hyper parametri \n#input_size = 28*28    #  =784 sono le dimensioni delle immagini\nhidden_size  = 128   #  scelto da me\nnum_classes = 10      #  devo classificare immagini di numeri\nnum_epochs = 2        #  quanti giri completi vengono fatti\nbatch_size = 100        #  questo no so come sia stato scelto\nlearning_rate = 0.001 #  piccolo\n\ninput_size = 28        # singolo input e' la riga     RNN\nsequence_length =28    # ci sono 28 righe             RNN\nnum_layers = 2         # di default =1                RNN\n\n\n\ntrain_dataset = torchvision.datasets.MNIST(root= './data/', train= True, \n                                           transform =transforms.ToTensor(),\n                                          download = True)\n\ntest_dataset = torchvision.datasets.MNIST(root= './data/', train= False, \n                                           transform =transforms.ToTensor(),\n                                          download = False) # \n\ntrain_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader (dataset=  test_dataset, batch_size = batch_size, shuffle=False)\n\n### nota che la dimensione dei sample e' la seguente\n# 100  = numero di immagini nel batch (se non metti batch_size, di default vale 1)\n#   1  = numero di canali solitamente i colori\n#  28  =  numero di ingressi sull'asse delle x\n#  28  = numero di ingressi sull'asse delle y\n        \n\n############  MODELLO ####################\n\nclass RNN(nn.Module):   \n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(RNN, self).__init__()\n        self.num_layers = num_layers     # RNN\n        self.hidden_size = hidden_size   # RNN\n        #self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)  # RNN , l'ordine e' importante batch set first dimension RNN\n        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)  # GRU \n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)  # LSTM         \n        \n        # x -&gt; batch_size, seq, input_size\n        self.fc = nn.Linear(hidden_size, num_classes) # RNN questo e' per l'ultimo passo della sequenza per avere la classificazione\n       \n    \n    # RNN da documentazione ora servono 2 input, uno e' lo stato e l'altro e' l'hidden state\n    def forward (self, x): \n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)  # RNN numero di layer, batch size, hidden size\n        \n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)  # LSTM initial cell  \n        \n        \n        #out, _ = self.rnn(x, h0) # RNN restituisce 2 outputs, uno out e hidden state per step n\n        #out, _ = self.gru(x, h0) # GRU restituisce 2 outputs, uno out e hidden state per step n       \n        out, _ = self.lstm(x, (h0,c0)) # LSTM restituisce 2 outputs, uno out e hidden state per step n       \n        \n        # RNN batch_size, sequence_length, hidden_size\n        \n        # RNN vogliamo l'hidden state dell'ultimo step\n        # RNN out (N, 28, 28)\n        out = out[:, -1, :]  # RNN serve solo l'ultimo time step quindi metto -1 e tutte le feature dell'hidden size\n        # RNN out(N, 128)\n        out = self.fc (out)  # RNN\n        return out\n        \n        \n\n############### ISTANZIO MODELLO, Loss, optimizer  ########\nmodel = RNN(input_size, hidden_size, num_layers,  num_classes).to(device)\ncriterion  = nn.CrossEntropyLoss()                                         # \noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)       # \nn_total_steps = len(train_loader)\n\n\n\nfor epoch in range(num_epochs):                          #   \n   for i, (images,labels) in enumerate (train_loader):   #      \n        # 100, 1, 28, 28  (batch, canali, x, y) forma del tensore images\n        # 100, 28x28=784  forma voluta dall'hidden layer\n        images = images.reshape(-1, sequence_length, input_size).to(device)     # Ora vogliamo solo righe e tante.\n        labels = labels.to(device)\n              \n        outputs = model (images)        #  non chiama il metodo forward: perche'?\n        loss = criterion(outputs, labels)\n                 \n        # backward pass\n        optimizer.zero_grad()    # \n        loss.backward()          # \n        optimizer.step()         # \n        \n        if (i+1) % 100 ==0:\n            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}')        \n\n            \n############ TEST LOOP e' identico a RNN e FeedForward! #################\nwith torch.no_grad():    \n    n_correct = 0         # numero di predizioni azzeccate\n    n_samples = 0         # ? \n    for images, labels in test_loader:\n        images = images.reshape(-1,sequence_length, input_size).to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)               # qui il modello e' gia' trainato!\n        \n        _, predictions = torch.max(outputs,1) # prendo la classe che ha il valore massimo\n        n_samples += labels.shape[0]          # numero di samples nel batch corrente (nell'ultimo sono diversi spesso)\n        n_correct += (predictions == labels).sum().item()\n        \n    acc = 100.0  * n_correct / n_samples # accuratezza in percentuale\n    print(f'accuracy ={acc}')            \n\n\nepoch 1 / 2, step 100/600, loss= 0.9440\nepoch 1 / 2, step 200/600, loss= 0.5394\nepoch 1 / 2, step 300/600, loss= 0.3369\nepoch 1 / 2, step 400/600, loss= 0.1903\nepoch 1 / 2, step 500/600, loss= 0.2440\nepoch 1 / 2, step 600/600, loss= 0.1913\nepoch 2 / 2, step 100/600, loss= 0.1267\nepoch 2 / 2, step 200/600, loss= 0.1024\nepoch 2 / 2, step 300/600, loss= 0.0285\nepoch 2 / 2, step 400/600, loss= 0.1911\nepoch 2 / 2, step 500/600, loss= 0.1058\nepoch 2 / 2, step 600/600, loss= 0.1007\naccuracy =97.46"
					}
					
				
			
		
			
				
					,
					
					"pytorch-9": {
						"id": "pytorch-9",
						"title": "Pytorch 9 Autoencoder",
						"categories": "italiano",
						"url": " /Pytorch-9",
						"content": "tocIn this post\n  \n  \n\n  Autoencoder    \n      Senza convoluzioni\n      Con Convoluzioni\n      My Playground\n    \n  \n\n\n  \n\n\nIndice Globale degli argomenti tra i vari post:\n\n 1.1.                                    Indice degli argomenti.\n 1.1.                                      Introduzione e fonti.\n 1.1.                                  Lingo - Gergo utilizzato.\n 1.2.                                        Tensori in Pytorch.\n 2.1.                                      Chainrule e Autograd.\n 2.2.                                           Backpropagation.\n 3.1.                                          Loss e optimizer.\n 3.2.                                        Modelli di Pytorch.\n 3.3.                                      Dataset e Dataloader.\n 3.4.                                       Dataset Transforms.\n 3.5.                              Softmax e Cross-Entropy Loss.\n 3.6.                                       Activation Function.\n 4.1.                                Feed Forward Neural Network.\n 5.1.                               Convolutional Neural Network.\n 5.2.                                          Transfer Learning.\n 5.3.                                                Tensorboard.\n 6.1.                              I/O Saving and Loading Models.\n 7.1.                                  Recurrent Neural Networks.\n 7.2.                                            RNN, GRU e LSTM.\n 8.1.                                          Pytorch Lightning.\n 8.2.                                               LR Scheduler.\n 9.1.                                                Autoencoder.\n\nAutoencoder\n\nVideo-lezione di Python Engineer con una spiegazione su come scrivere i codici\ne una introduzione alla teoria.\n\nLa teoria viene spiegata molto bene in questa\nvideo-lezione\ndel corso MIT 6.S191, dove vengono anche introdotti ulteriori concetti come i Variational AutoEncoders (VAE).\n\nUn autoencoder e’ una rete neurale che cerca di “riassumere i tratti principali dell’input. L’idea e’ molto sempice, \nPensiamo a delle immagini. Si prende e si fanno vari strati che hanno via via meno parametri. A quel punto si fanno i passi inversi (letteralemente) in modo da riottenere un medesimo numero di valori finali. Come funzione di Loss si usa una MSE. E’ intuitivo. se ho una immagine in ingresso voglio vedere la STESSA immagine in uscita (o almeno avvicinarmi)\n\nRisorsa da cui sono in pratica presi i codici:\nhttps://www.cs.toronto.edu/~lczhang/360/lec/w05/autoencoder.html\n\nQui il corso da cui sono prese i codici particolari dell’autoencoder:\nhttps://www.cs.toronto.edu/~lczhang/360/\n\nSenza convoluzioni\n\nimport torch\nimport torch.nn as nn  \nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\n\ntransform = transforms.ToTensor()\nmnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ndata_loader = torch.utils.data.DataLoader(dataset =mnist_data,\n                                         batch_size=64, shuffle=True)\n\ntype(mnist_data[1])\nlen(mnist_data[59999][0][0])\ntype(mnist_data[59999][0][0].numpy())\nmnist_data[59999][0][0].numpy().size\n\n\n784\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \ndataiter  = iter(data_loader)\nimages, labels = dataiter.next()\n\n\nclass Autoencoder (nn.Module):\n    def __init__(self):\n        super().__init__()\n        # N= 784 (28x28)\n        self.encoder = nn.Sequential(      # funzione di pytorch che fa andare uno dopo l'altro varie funzioni\n            nn.Linear(28*28,128),           # numero di punti in ingresso (28*28) e neuroni in uscita(128)\n            nn.ReLU(()), \n            nn.Linear(128,64),              \n            nn.ReLU(()),             \n            nn.Linear(64,12),               \n            nn.ReLU(()),             \n            nn.Linear(12,6),                # \n        )\n        \n        self.decoder = nn.Sequential(      # funzione di pytorch che fa andare uno dopo l'altro varie funzioni\n            nn.Linear(6,12),           # numero di punti in ingresso (28*28) e neuroni in uscita(128)\n            nn.ReLU(()), \n            nn.Linear(12,64),              \n            nn.ReLU(()),             \n            nn.Linear(64,128),               \n            nn.ReLU(()),             \n            nn.Linear(128,28*28)                # \n        )\n        \n    \n    def forward (self,x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\n\nmodel = Autoencoder ().to(device)\ncriterion = nn.MSELoss()\noptimizer  = torch.optim.Adam(model.parameters(), lr= 1e-3 , weight_decay = 1e-5)\n\n\nnum_epochs = 10\noutputs = []  \nfor epoch in range(num_epochs):\n    for (img, _) in data_loader:\n        img   = img.reshape(-1,28*28).to(device)\n        recon = model(img).to(device)\n        loss = criterion(recon, img)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        \n        \n    print(f'Epoch: {epoch+1}, Loss:{loss.item():.4f}')\n    outputs.append((epoch, img, recon))\n\n\nEpoch: 1, Loss:0.0426\nEpoch: 2, Loss:0.0405\nEpoch: 3, Loss:0.0284\nEpoch: 4, Loss:0.0297\nEpoch: 5, Loss:0.0298\nEpoch: 6, Loss:0.0283\nEpoch: 7, Loss:0.0273\nEpoch: 8, Loss:0.0265\nEpoch: 9, Loss:0.0249\nEpoch: 10, Loss:0.0265\n\n\nci sono dei problemi di visualizzazione rispetto al codice scritto da Python Engineer. Riguardando un po’ \nla struttura ho trovato la soluzione\n\n#print(len(outputs[0]) )\noutputs[1][2].shape\nvarie = outputs[0][2].detach().reshape(-1,28*28).numpy()\nu=varie[0,:].reshape(28,28)\nu.shape\nplt.imshow(u)\n#plt.imshow(outputs[0][2].detach().reshape(-1,28*28).numpy())\n\n\n&lt;matplotlib.image.AxesImage at 0x1d0474e0730&gt;\n\n\n\n\nfor k in range(0, num_epochs,4):\n    plt.figure(figsize= (9,2))\n    plt.gray() \n    imgs  = outputs[k][1].detach().numpy()\n    recon = outputs[k][2].detach().numpy()\n    \n    for i, item in enumerate(imgs):\n        if i&gt;=9:break               # prendi solo le prime 9\n        plt.subplot(2,9,i+1)\n        item = item.reshape(-1,28*28)\n        plt.imshow(item[0].reshape(28,28))\n    \n    for i, item in enumerate(recon):\n        if i&gt;=9:break               # prendi solo le prime 9\n        plt.subplot(2,9,9+i+1)\n        item = item.reshape(-1,28*28)\n        plt.imshow(item[0].reshape(28,28))\n\n\n\n\n\n\n\n\nCon Convoluzioni\nqui sotto prendo un modello migliore, che sfrutti le convoluzioni e riesca a dare dei risultati piu’ precisi nella ricostruzione.\n\nimport torch\nimport torch.nn as nn  \nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\n\ntransform = transforms.ToTensor()\nmnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ndata_loader = torch.utils.data.DataLoader(dataset =mnist_data,\n                                         batch_size=64, shuffle=True)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \ndataiter  = iter(data_loader)\nimages, labels = dataiter.next()\n\n\nclass Autoencoder (nn.Module):\n    def __init__(self):\n        super().__init__()\n        # N= 784 (28x28)\n        self.encoder = nn.Sequential(      # funzione di pytorch che fa andare uno dopo l'altro varie funzioni\n            nn.Conv2d(1, 16, 3, stride=2, padding =1),    # canali input, output, kernel, stride, padding | N 16 14 14\n            nn.ReLU(()), \n            nn.Conv2d(16,32, 3, stride=2, padding =1),    # N 32 7  7         \n            nn.ReLU(()),             \n            nn.Conv2d(32,64, 7 )    # N 64  1  1 (64 parametri in uscita)             \n        )\n        \n        self.decoder = nn.Sequential(      # funzione di pytorch che fa andare uno dopo l'altro varie funzioni\n            nn.ConvTranspose2d(64, 32, 7),   # N 32 7 7   \n            nn.ReLU(()), \n            nn.ConvTranspose2d(32, 16, 3, stride=2, padding =1, output_padding=1),   # N 16 14 14                 \n            nn.ReLU(()),             \n            nn.ConvTranspose2d(16,  1, 3, stride=2, padding =1, output_padding=1),   # N 1 28 28                  \n            nn.Sigmoid()             \n        )\n        \n    \n    def forward (self,x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n    \n# nn.MaxPool2d  e  nn.MaxUnpool2d    \n\n\nmodel = Autoencoder ()   .to(device)\ncriterion = nn.MSELoss()\noptimizer  = torch.optim.Adam(model.parameters(), lr= 1e-3 , weight_decay = 1e-5)\n\n\nnum_epochs = 10\noutputs = []  \nfor epoch in range(num_epochs):\n    for (img, _) in data_loader:\n        img   = img.to(device)          #.to(device)\n        #recon = model(img)             #.to(device)\n        recon = model (img).to(device)\n        loss = criterion(recon, img)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        \n        \n    print(f'Epoch: {epoch+1}, Loss:{loss.item():.4f}')\n    outputs.append((epoch, img, recon))\n\n\nEpoch: 1, Loss:0.0097\nEpoch: 2, Loss:0.0062\nEpoch: 3, Loss:0.0047\nEpoch: 4, Loss:0.0039\nEpoch: 5, Loss:0.0036\nEpoch: 6, Loss:0.0035\nEpoch: 7, Loss:0.0028\nEpoch: 8, Loss:0.0030\nEpoch: 9, Loss:0.0031\nEpoch: 10, Loss:0.0027\n\n\nfor k in range(0, num_epochs,4):\n    plt.figure(figsize= (9,2))\n    plt.gray() \n    imgs  = outputs[k][1].cpu().detach().numpy()\n    recon = outputs[k][2].cpu().detach().numpy()\n    \n    for i, item in enumerate(imgs):\n        if i&gt;=9:break               # prendi solo le prime 9\n        plt.subplot(2,9,i+1)\n        item = item.reshape(-1,28*28)\n        plt.imshow(item[0].reshape(28,28))\n    \n    for i, item in enumerate(recon):\n        if i&gt;=9:break               # prendi solo le prime 9\n        plt.subplot(2,9,9+i+1)\n        item = item.reshape(-1,28*28)\n        plt.imshow(item[0].reshape(28,28))\n\n\n\n\n\n\n\n\nMy Playground\n\n\n  nota che quando fai andare prima il modello lineare e poi quello convoluzionale due volte i parametri continuano ad aggiornarsi, quindi la seconda volta ottieni dei valori piu’ precisi!\n  per esempio provo a mettere un parametro: min_par che indica il numero minimo di parametri (nell’esempio e’ 64, io provo 32, ecc\n\n\nimport torch\nimport torch.nn as nn  \nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\n\ntransform = transforms.ToTensor()\nmnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ndata_loader = torch.utils.data.DataLoader(dataset =mnist_data,\n                                         batch_size=64, shuffle=True)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \ndataiter  = iter(data_loader)\nimages, labels = dataiter.next()\n\n\nmin_par=4\n\nclass Autoencoder (nn.Module):\n    def __init__(self):\n        super().__init__()\n        # N= 784 (28x28)\n        self.encoder = nn.Sequential(      # funzione di pytorch che fa andare uno dopo l'altro varie funzioni\n            nn.Conv2d(1, 16, 3, stride=2, padding =1),    # canali input, output, kernel, stride, padding | N 16 14 14\n            nn.ReLU(()), \n            nn.Conv2d(16,32, 3, stride=2, padding =1),    # N 32 7  7         \n            nn.ReLU(()),             \n            nn.Conv2d(32,min_par, 7 )    # N 64  1  1 (64 parametri in uscita)             \n        )\n        \n        self.decoder = nn.Sequential(      # funzione di pytorch che fa andare uno dopo l'altro varie funzioni\n            nn.ConvTranspose2d(min_par, 32, 7),   # N 32 7 7   \n            nn.ReLU(()), \n            nn.ConvTranspose2d(32, 16, 3, stride=2, padding =1, output_padding=1),   # N 16 14 14                 \n            nn.ReLU(()),             \n            nn.ConvTranspose2d(16,  1, 3, stride=2, padding =1, output_padding=1),   # N 1 28 28                  \n            nn.Sigmoid()             \n        )\n        \n    \n    def forward (self,x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n    \n# nn.MaxPool2d  e  nn.MaxUnpool2d    \n\n\nmodel = Autoencoder ()   .to(device)\ncriterion = nn.MSELoss()\noptimizer  = torch.optim.Adam(model.parameters(), lr= 1e-3 , weight_decay = 1e-5)\n\n\nnum_epochs = 10\noutputs = []  \nfor epoch in range(num_epochs):\n    for (img, _) in data_loader:\n        img   = img.to(device)          #.to(device)\n        #recon = model(img)             #.to(device)\n        recon = model (img).to(device)\n        loss = criterion(recon, img)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        \n        \n    print(f'Epoch: {epoch+1}, Loss:{loss.item():.4f}')\n    outputs.append((epoch, img, recon))\n\n\nEpoch: 1, Loss:0.0467\nEpoch: 2, Loss:0.0362\nEpoch: 3, Loss:0.0390\nEpoch: 4, Loss:0.0337\nEpoch: 5, Loss:0.0352\nEpoch: 6, Loss:0.0327\nEpoch: 7, Loss:0.0348\nEpoch: 8, Loss:0.0359\nEpoch: 9, Loss:0.0347\nEpoch: 10, Loss:0.0356\n\n\nfor k in range(0, num_epochs,4):\n    plt.figure(figsize= (9,2))\n    plt.gray() \n    imgs  = outputs[k][1].cpu().detach().numpy()\n    recon = outputs[k][2].cpu().detach().numpy()\n    \n    for i, item in enumerate(imgs):\n        if i&gt;=9:break               # prendi solo le prime 9\n        plt.subplot(2,9,i+1)\n        item = item.reshape(-1,28*28)\n        plt.imshow(item[0].reshape(28,28))\n    \n    for i, item in enumerate(recon):\n        if i&gt;=9:break               # prendi solo le prime 9\n        plt.subplot(2,9,9+i+1)\n        item = item.reshape(-1,28*28)\n        plt.imshow(item[0].reshape(28,28))"
					}
					
				
			
		
			
				
					,
					
					"pytorch-8": {
						"id": "pytorch-8",
						"title": "Pytorch 8 Lightning",
						"categories": "italiano",
						"url": " /Pytorch-8",
						"content": "tocIn this post\n  \n  \n\n  PyTorch Lightning\n  LR Scheduler\n\n\n  \n\n\nIndice Globale degli argomenti tra i vari post:\n\n 1.1.                                    Indice degli argomenti.\n 1.1.                                      Introduzione e fonti.\n 1.1.                                  Lingo - Gergo utilizzato.\n 1.2.                                        Tensori in Pytorch.\n 2.1.                                      Chainrule e Autograd.\n 2.2.                                           Backpropagation.\n 3.1.                                          Loss e optimizer.\n 3.2.                                        Modelli di Pytorch.\n 3.3.                                      Dataset e Dataloader.\n 3.4.                                       Dataset Transforms.\n 3.5.                              Softmax e Cross-Entropy Loss.\n 3.6.                                       Activation Function.\n 4.1.                                Feed Forward Neural Network.\n 5.1.                               Convolutional Neural Network.\n 5.2.                                          Transfer Learning.\n 5.3.                                                Tensorboard.\n 6.1.                              I/O Saving and Loading Models.\n 7.1.                                  Recurrent Neural Networks.\n 7.2.                                            RNN, GRU e LSTM.\n 8.1.                                          Pytorch Lightning.\n 8.2.                                               LR Scheduler.\n 9.1.                                                Autoencoder.\n\nPyTorch Lightning\nVideo-lezione\ndi Python Engineer.\n\nPyTorch Lightning  e’ un wrapper per velocizzare la scrittura di reti neurali, con Pytorch.\n\nSito di Pytorch Lightning\nhttps://www.pytorchlightning.ai/\n\nPer istallarlo: conda install pytorch-lightning -c conda-forge\n\nNon e’ piu’ necessario:\n\n  model.train() (ovvero settare il modello  in  training mode)\n  model.eval()  (ovvero settare il modello  in  evaluation mode)\n  definire una device e fare model.to(device)  si puo’ “sconnettere” la GPU facilmente\n  optimizer.zero_grad()\n  loss.backwards()\n  optimizer.step()\n  with torch.nograd()\n  x= x.detach\n\n\nBonus\n\n  stampa consigli e aiuti!\n  supporto Tensorboard: viene costruito un folder chiamato lightning_logs.\nPer usare tensorboard tensorboard  --logdir lightning_logs  (e’ il nome della dir creata in automatico, nel video fa un errore e scrive log_dir)\n\n\nA questo punto per fare inspecting del training, creiamo un altro dict.\n\nUsiamo il codice del tutorial 13 e lo modifichiamo per PyTorch Lightning.\n\nSuggerimenti:\n-suggerisce di usare il metodo validation_epoch_end() per accumulare statistiche. Nota che nel video Loeber copia i metodi dal sito e li modifica per l’occasione. Questo metodo viene poi piazzato all’interno del modello\n\nDomande:\nmi viene GPU present = True, used False, devo accendere l’uso della GPU. Si va nel metodo Trainer e si mette: trainer=Trainer(gpus=1, max_epochs=num_epochs, fast_dev_run =True). Ok ho controllato e ora la GPU e’ presente e usata… ma il tempo di esecuzione praticamente non cambia!\n\n  Si puo’ usare anche una TPU e anche un distributed backend una DDP\n  Si puo’ passare a precisione 16 bit\n  in Trainer si puo’ mettere anche il karg: auto_lr_find =True per il learning rate\n  in Trainer si puo’ mettere anche il karg: deterministic =True per riprodurre esattamente i risultati\n  in Trainer si puo’ mettere anche il karg: gradient_clip_val =0.3 (un numero tra 0 e 1 per fare clipping dei gradienti)\n\n\nProblemi:\n\n  nel video si vede la loss che scende in basso a dx mentre per me e’ un NAN. Ok il problema era che non facevo “ritornare” nulla dal metodo training_step che invece deve restituire un dict della forma {‘loss’:loss}, che viene preso direttamente dal PL e mostrato nella barra sotto\n  non vedo apparire la fase di validazione con una barra che si riempie (nel video c’e’)\n  mi da il seguente warning: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\nPlease use self.log(…) inside the lightningModule instead.\n#log on a step or aggregate epoch metric to the logger and/or progress bar (inside LightningModule)\nself.log(‘train_loss’, loss, on_step=True, on_epoch=True, prog_bar=True)\nwarnings.warn(*args, **kwargs)\n  In tensor borad non riesco a trovare train_loss (e’ uno scalare ma non lo trovo)\n\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport time\n\nimport torch.nn.functional as F \n\nimport pytorch_lightning as pl # PL\nfrom pytorch_lightning import Trainer \n\n%matplotlib inline\n\n# device config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Hyper parametri \ninput_size = 28*28      #  =784 sono le dimensioni delle immagini\nhidden_size  = 500      #  scelto da me\nnum_classes = 10        #  devo classificare immagini di numeri\nnum_epochs = 2          #  quanti giri completi vengono fatti\nbatch_size = 100        #  questo non so come sia stato scelto\nlearning_rate = 0.001   #  piccolo\n\n#train_dataset = torchvision.datasets.MNIST(root= './data/', train= True, transform =transforms.ToTensor(), download = True)\n#test_dataset = torchvision.datasets.MNIST(root= './data/', train= False, transform =transforms.ToTensor(), download = False) # ho gia' scaricato tutto con il train_datast\n\n#train_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle=True)\n#test_loader = torch.utils.data.DataLoader (dataset=  test_dataset, batch_size = batch_size, shuffle=False)\n\n\n############  MODELLO ####################\n\n\n#class NeuralNet(nn.Module):             #vecchi\nclass LitNeuralNet(pl.LightningModule):  # nome scelto da noi, pl.LightningModule e' la versione super di nn.Module    \n    def __init__(self, input_size, hidden_size, num_classes):\n        super(LitNeuralNet, self).__init__()\n        self.input_size = input_size\n        self.l1 = nn.Linear(input_size, hidden_size)  \n        self.relu = nn.ReLU()\n        self.l2 = nn.Linear(hidden_size, num_classes)\n       \n    def forward (self, x):    # x e' l'input.\n        out = self.l1(x)      # \n        out = self.relu(out)  # \n        out = self.l2(out)\n        return out            # \n\n    \n    def training_step(self, batch, batch_idx):  # PL non uso piu' i loop!!!! \n        #x,y = batch           # unpack\n        images, labels  =batch # PL unpack\n        images = images.reshape(-1,28*28)   # non e' piu' necessairo to(device)\n        \n        #y_hats = self(x)     # ????\n        outputs  = self(images)  # PL questo e' il forward pass! usiamo self perche' usiamo direttamente questo modulo\n        \n        #loss = F.cross_entropy(y_hat, y)\n        loss =F.cross_entropy(outputs, labels)\n        \n        tensorboard_logs = {'train_loss':loss}    # devo metterlo anche nel validatio_epoch_end\n        return {'loss':loss, 'log':tensorboard_logs}   # PL i nomi delle chiavi sono FISSI: e' log non Log\n        #return {'loss': loss}\n    \n    \n    \n    def configure_optimizers(self):  # PL ma il nome e' fissato da PL? penso di si'\n        #optimizer = torch.optim.Adam(self.parameters(), lr = learning_rate)  # non ho capito se serve o no...   \n        return torch.optim.Adam(self.parameters(), lr= 0.001)  #  PL self e' l'istanza del modello\n    \n    def train_dataloader(self):\n        #dataset = MNIST(os.getcwd(), train=True, download=True, transform =transforms.ToTensor())\n        #loader = DataLoader (dataset, batch_size= 32, num_workers=1, shuffle=True)   #lui ha messo num_workers = 4\n        train_dataset = torchvision.datasets.MNIST(root= './data/', train= True, transform =transforms.ToTensor(), download = True)\n        train_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size = batch_size, num_workers=4, shuffle=True)\n        return train_loader\n    \n    # il nome deve essere questo!\n    def val_dataloader(self):\n        val_dataset = torchvision.datasets.MNIST(root= './data/', train= False, transform =transforms.ToTensor(), download = False) # ho gia' scaricato tutto con il train_datast\n        val_loader = torch.utils.data.DataLoader (dataset= val_dataset, batch_size = batch_size, num_workers=4, shuffle=False)\n        return val_loader    \n    \n    \n    # questo viene eseguito dopo ogni epoch di validazione\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n     \n        tensorboard_logs  = {'tavg_val_loss': avg_loss} # PL per ora non lo guardiamo\n        return {'tavg_val_loss': avg_loss, 'log':tensorboard_logs}\n        #return {'val_loss': avg_loss}    \n    \n\nstart = time.time()\n#trainer = Trainer(max_epochs = num_epochs, fast_dev_run = False)  # PL Trainer e' importato da PL\ntrainer = Trainer(gpus=1,max_epochs = num_epochs, fast_dev_run = False)  # PL Trainer e' importato da PL\n\nmodel = LitNeuralNet(input_size, hidden_size, num_classes)        # PL istanzio il modello  \ntrainer.fit(model)                                                # faccio il training sul modello\nprint(\"Tempo training+test= \", time.time()-start)    \n    \n\n\n\nGPU available: True, used: True\nTPU available: None, using: 0 TPU cores\n\n  | Name | Type   | Params\n--------------------------------\n0 | l1   | Linear | 392 K \n1 | relu | ReLU   | 0     \n2 | l2   | Linear | 5.0 K \n--------------------------------\n397 K     Trainable params\n0         Non-trainable params\n397 K     Total params\n1.590     Total estimated model params size (MB)\n\n\n\nHBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…\n\n\n\nTempo training+test=  12.651966094970703\n\n\nLR Scheduler\nvideo di riferimento di Python Engineer.\n\nVediamo come sfruttare le funzioni di Pytorch che automaticamente modificano il learning rate per ottenere dei risultati ottimali.\n\nSpesso (intuitivamente) si vuole diminuire il Learning Rate. La logica a mio avviso e’ la seguente, quando mi avvicino al minimo se non diminuisco il LR rischio di saltare da una parte all’altra del minimo stesso.\n\nPer questo si usa uno scheduler.\nOnestamente non mi pare ultra necessario, uno puo’ costruire delle funzioni custom che facciano la cosa ogni volta.  Anzi se uso una funzione che non ho scritto io c’e’ la possibilita’ che io non controlli perfertamente.\n\nUna interessante e’ che si riduce solo se una certa metrica ha raggiunto un plateau.\n\nOsservazioni\n\n  in python // e’ floor division."
					}
					
				
			
		
			
				
					,
					
					"pytorch-6": {
						"id": "pytorch-6",
						"title": "Pytorch 6 Input Output",
						"categories": "italiano",
						"url": " /Pytorch-6",
						"content": "tocIn this post\n  \n  \n\n  I/O Saving and Loading Models    \n      Salvare modelli da GPU\n    \n  \n\n\n  \n\n\nIndice Globale degli argomenti tra i vari post:\n\n 1.1.                                    Indice degli argomenti.\n 1.1.                                      Introduzione e fonti.\n 1.1.                                  Lingo - Gergo utilizzato.\n 1.2.                                        Tensori in Pytorch.\n 2.1.                                      Chainrule e Autograd.\n 2.2.                                           Backpropagation.\n 3.1.                                          Loss e optimizer.\n 3.2.                                        Modelli di Pytorch.\n 3.3.                                      Dataset e Dataloader.\n 3.4.                                       Dataset Transforms.\n 3.5.                              Softmax e Cross-Entropy Loss.\n 3.6.                                       Activation Function.\n 4.1.                                Feed Forward Neural Network.\n 5.1.                               Convolutional Neural Network.\n 5.2.                                          Transfer Learning.\n 5.3.                                                Tensorboard.\n 6.1.                              I/O Saving and Loading Models.\n 7.1.                                  Recurrent Neural Networks.\n 7.2.                                            RNN, GRU e LSTM.\n 8.1.                                          Pytorch Lightning.\n 8.2.                                               LR Scheduler.\n 9.1.                                                Autoencoder.\n\nI/O Saving and Loading Models\nVideo-lezione \ndi Python Engineer sul soggetto.\n\nUn modello viene salvato come un dictionary.\n\ni 3 metodi da ricordare:\n\n  torch.save(arg, PATH) posso salvare tensor, model o dictiionary  (e posso usare Pickle)\n  torch.load(PATH)\n  model.load_state_dict(arg)\n\n\nCi sono 2 modi per salvare un modello: il modo lazy e modo raccomandato\n\n\n  lazy: usando torch.save(arg, PATH) e poi carico il modello con model =torch.load(PATH)\nA questo punto si usa:\nmodel.eval() in questo modo si entra in modalita’ evaluation (da controllare)\n\n\nIl difetto del metodo lazy e’ che i dati “serializzati” (intende compressi con pickle) seguono esattamente la classe e la struttura di quando sono salvati.\n\n\n  modo raccomandato: basta salvare SOLO i parametri del modello stesso: \ntorch.save(model.state_dict(), PATH)\n\n\nA questo punto devo creare un nuovo modello, e poi importare i parametri: \nmodel= Model(*args, **kwargs)\nmodel.load_state_dict(torch.load(PATH)) \nmodel.eval()\n\n\n  i modelli vengono salvati in file che hanno come estensione pth\n\n\nSalviamo anche i checkpoint:\nun check point e’ un dizionario di dizionari!\n\n  i parametri del modello sono un dizionario\n  i parametri dell’optimizer sono un dizionario\n -….\n\n\nQuindi quello che facciamo e’ un dizionario in cui la prima key e’ “model” e associamo\n il dizionario del modello, poi la chiave “optimizer” e il dizionario dell’ottimizzatore.\n Alla fine quando abbiamo bisogno usiamo checkpoint[“model”] e lui mi restituisce il dizionario\n con i parametri del modello (o se ho scritto optimizer, quelli dell’ottimizzatore).\n\n######## LAZY method #################\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):  # eredita un oggetto nn.Module\n    def __init__(self , n_input_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(n_input_features, 1)\n\n    def forward(self, x):\n        y_pred = torch.sigmoid(self.linear(x))\n        return y_pred\n        \nmodel =  Model(n_input_features=6)\n\n\n######## SALVO IL MODELLO ############\nFILE = \"model.pth\"       # solitamente i modelli hanno come estensione pth ?\ntorch.save(model, FILE)     \n\n######## CARICO IL MODELLO ###########\nmodel = torch.load(FILE)\nmodel.eval()\n\nfor param in model.parameters():\n    print(param)\n\n\nParameter containing:\ntensor([[-0.3695,  0.2621,  0.0619, -0.2925, -0.3088, -0.2284]],\n       requires_grad=True)\nParameter containing:\ntensor([-0.2680], requires_grad=True)\n\n\n########## Metodo raccomandato ###########\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):  # eredita un oggetto nn.Module\n    def __init__(self , n_input_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(n_input_features, 1)\n\n    def forward(self, x):\n        y_pred = torch.sigmoid(self.linear(x))\n        return y_pred\n        \nmodel =  Model(n_input_features=6)\n#for param in model.parameters():\n#    print('Prima',param)\n\n######## SALVO IL MODELLO ############\nFILE = \"model-raccomandato.pth\"       # solitamente i modelli hanno come estensione pth ?\ntorch.save(model.state_dict(), FILE)  # salvo solo i parametri del modello   \n\n######## Prima devo definire un modello #####\nloaded_model = Model(n_input_features=6)        # creo un modello con la stessa struttura\nloaded_model.load_state_dict(torch.load(FILE))  # carico i parametri\nloaded_model.eval()                             # setto il modello in eval mode.\n\n\n#for param in loaded_model.parameters():\n#    print('Dopo', param)\n\n\nModel(\n  (linear): Linear(in_features=6, out_features=1, bias=True)\n)\n\n\n############# Check point  ####################\n\nimport torch\nimport torch.nn as nn\n\nclass Model(nn.Module):  # eredita un oggetto nn.Module\n    def __init__(self , n_input_features):\n        super(Model, self).__init__()\n        self.linear = nn.Linear(n_input_features, 1)\n\n    def forward(self, x):\n        y_pred = torch.sigmoid(self.linear(x))\n        return y_pred\n        \nmodel =  Model(n_input_features=6)\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)\n\nprint(optimizer.state_dict())\n\n####### CHECK point ######\n\ncheckpoint  = {         # e' un dizionario\n    \"epoch\":90,         # per esempio siamo alla epoca 90\n    \"model_state\": model.state_dict(),\n    \"optim_state\": optimizer.state_dict()\n}\n\ntorch.save(checkpoint, \"checkpoint.pth\")\n\n#  a questo punto posso caricare:\n\nloaded_checkpoint  =torch.load(\"checkpoint.pth\")\nepoch  =loaded_checkpoint[\"epoch\"] \nmodel = Model(n_input_features=6)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0) # mettiamo 0 e poi carichiamo la corretta lr\nmodel.load_state_dict(checkpoint[\"model_state\"])\noptimizer.load_state_dict(checkpoint[\"optim_state\"])\n\nprint(optimizer.state_dict())\n\n\n\n\n\n\n{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1]}]}\n{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1]}]}\n\n\nSalvare modelli da GPU\nMinuto 16 circa.\n\nGli esempi sopra fungono se tutt il modello e’ tenuto sulla CPU (sia per load che train, validation).\n\nmap_location\nargomento di load_state_dict(PATH, map_location=device)\n\nnon e’ chiaro cosa intenda per save on GPU (io salvo su disco! magari intende che il modello e’ sulla GPU e poi lo metto su disco)\n\nimport torch\nimport torch.nn as nn\n\n# SAVE sulla GPU, load sulla CPU\n\ndevice = torch.device(\"cuda\")\nmodel.to(device)\ntorch.save(model.state_dict(), PATH)\n\n\ndevice =torch.device(\"cpu\")\nmodel = Model(*args, **kwargs)\nmodel.load_state_dict(torch.load(PATH, map_location=device))\n\n#####################################\n\n# SAVE sulla GPU, load sulla GPU\n\ndevice = torch.device(\"cuda\")\nmodel.to(device)\ntorch.save(model.state_dict(), PATH)\n\n\ndevice =torch.device(\"cpu\")\nmodel = Model(*args, **kwargs)\nmodel.load_state_dict(torch.load(PATH))\nmodel.to(device)                      \n\n\n#####################################\n\n# SAVE sulla CPU, load sulla GPU\n\n\ntorch.save(model.state_dict(), PATH)\n\n\ndevice =torch.device(\"cuda\")\nmodel = Model(*args, **kwargs)\nmodel.load_state_dict(torch.load(PATH, map_location=\"cuda:0\")  # 0 e' per la GPU zerp\nmodel.to(device)"
					}
					
				
			
		
			
				
					,
					
					"pytorch-5": {
						"id": "pytorch-5",
						"title": "Pytorch 5 Convolutional Neural Network",
						"categories": "italiano",
						"url": " /Pytorch-5",
						"content": "tocIn this post\n  \n  \n\n  Convolutional Neural Network    \n      Come misurare le dimensioni dei tensori in uscita\n    \n  \n  Transfer Learning    \n      Image Folder\n      Scheduler\n      Fine Tuninig\n      Domande\n      Tempo\n      Train() e Eval()\n    \n  \n  Tensorboard\n\n\n  \n\n\nIndice Globale degli argomenti tra i vari post:\n\n 1.1.                                    Indice degli argomenti.\n 1.1.                                      Introduzione e fonti.\n 1.1.                                  Lingo - Gergo utilizzato.\n 1.2.                                        Tensori in Pytorch.\n 2.1.                                      Chainrule e Autograd.\n 2.2.                                           Backpropagation.\n 3.1.                                          Loss e optimizer.\n 3.2.                                        Modelli di Pytorch.\n 3.3.                                      Dataset e Dataloader.\n 3.4.                                       Dataset Transforms.\n 3.5.                              Softmax e Cross-Entropy Loss.\n 3.6.                                       Activation Function.\n 4.1.                                Feed Forward Neural Network.\n 5.1.                               Convolutional Neural Network.\n 5.2.                                          Transfer Learning.\n 5.3.                                                Tensorboard.\n 6.1.                              I/O Saving and Loading Models.\n 7.1.                                  Recurrent Neural Networks.\n 7.2.                                            RNN, GRU e LSTM.\n 8.1.                                          Pytorch Lightning.\n 8.2.                                               LR Scheduler.\n 9.1.                                                Autoencoder.\n\nConvolutional Neural Network\n\nVideo-Lezione del MIT sulle CNN (Inglese).\n\nUna video-lezione estesa sugli stessi argomenti e dagli stessi autori qui\n\nMateriale della lezione:\nhttp://introtodeeplearning.com​\n\nqui vediamo degli esempi specifici riguardo le reti convoluzionali.\n\n  L’esempio e’ basato sul dataset CIFAR-10.\n  10 classi, 6000 immagini per classe.\n  ogni immagine sono 32 x 32\n  ogni immagine ha 3 canali\n  50 000 immagini di training e 10 000 immagini di test\n  Il dataset sembra gia’ essere diviso in batches\n\n\nProblema ho implementato fino a criterion ma ho un errore quando istanzio il modello (prima di averlo riempito…\nforse e’ per quello). 'ConvNet' object has no attribute '_modules'\n\n-Domanda: Non mi e’ chiaro come vengano gestiti i casi di 3 canali di colore. Come faccio ad associarli a una singola immagine?\n-Risposta. Posso pensare i 3 canli come un’immagine una sopra l’altra. Le convoluzioni applicano in modo indipendente ai 3 canali, ma alla fine quando faccio un flatten li metto tutti in un unico tensore 1D (forse)\n\nRegola del numero di punti restanti in funzione di una convoluzione/ pooling,\n\n  w  = larghezza dell’immagine.\n  F  = larghezza del filtro\n  P  = larghezza del padding\n  S  = stride\n\n\nRisultato (minuto 14:00 del tutorial 14): \n\n(in questo caso P =0 dato che non ho padding, e S=1 in quanto il kernel si muove di un quadretto per volta)\n\n\n(nota che i quadrati colorati successivi sono un po’ piu’ piccoli per evitare sovrapposizioni ma riguardano \ntutti i punti delle celle che toccano)\nOra viene implementata una rete neurale con la seguente (immagine da internet, non penso sia di Loeber) struttura:\n\n\n\n\n  conv + relu\n  pooling\n  conv + relu\n  pooling\n  fully connected\n  fully connected\n  fully connected\n\n\nCome misurare le dimensioni dei tensori in uscita\n\nQuando si hanno delle convoluzioni o dei pooling, la dimensione dei tensori in uscita non\ne’ facilissima da calcolare al volo, fortunatamente esiste una formula semplice.\n\n\n  In torch le convoluzioni nn.Conv2d(3,6,5) hanno 3 parametri:\n\n\n\n  il primo parametro e’ il numero di canali in ingresso (per esempio 3, associati a r g b).\n  il secondo parametro e’ il numero di canali in USCITA, nell’esempio sopra 6. Cosa significa? significa che ho preso 6 \nkernel differenti (riempiti con valori random) e li ho applicati tutti e 6 (ipotesi mia)!\n  \n    il terzo parametro e’ la dimensione del kernel\n  \n  ci sono i canali (in entrata di solito sono i colori, in uscita non hanno questo significato, in quanto possono cambiare.\n\n\n\n  I max pooling hanno 2 parametri, per esempio: nn.MaxPool2d(2,2):\n    \n      la dimensione del kernel\n      lo stride\n    \n  \n\n\nRiassumendo si usa la formula (w - f +2p )/s +1 sia per convoluzione che per pooling:\n\n  prima convoluzione (kernel 5 x 5) passo da 3 canali 32 x 32 a   : (32-5-0)/1+1  = 28 x 28   ( 6 canali ,scelto da me)\n  primo pooling (kernel 2 x 2) con stride 2 passo da 6 canali 28 x 28 -&gt; (28-2-0)/2 + 1 = 14 x 14 ( 6 canali, non modificabile)\n  seconda convoluzione (kernel 5 x5) passo da 6 canali 14 x 14 a -&gt; (14 - 5 -0)/1+1 = 10 x 10 (16 canali, scelto da me)\n  secondo pooling (kernel 2 x 2) passp da 16 canali 10 x 10 a -&gt; (10-2 -0)/2 +1 = 5 x 5 (16 canali non modificabile)\n\n\nQuindi quando faccio un flatten alla fine ottengo: 5 x 5 x 16  esatto come nel video!\n\nIn grassetto metto i valori che scelgo io (per esempio i canali di ouput con la convolione)\n\n\n\n\n  \n    \n      operazione\n      canali input\n      canali output\n      kernel\n      Stride\n      figura input\n      figura output\n    \n  \n  \n    \n      I convoluzione\n      3\n      6\n      5 x 5\n      1\n      32 x 32\n      (32-5-0)/1+1 =28\n    \n    \n      I max pooling\n      6\n      6\n      2 x 2\n      2\n      28 x 28\n      (28-2-0)/2+1 =14\n    \n    \n      II convoluzione\n      6\n      16\n      5 x 5\n      1\n      14 x 14\n      (14-5-0)/1+1 =10\n    \n    \n      II max pooling\n      16\n      16\n      2 x 2\n      2\n      10 x 10\n      (10-2-0)/2+1 = 5\n    \n  \n\n\nOsservazione\n\n  alla funzione di convoluzione vengono passati come argomenti solo: i canali di ingresso, canali di uscita e la dimensione del kernel, per esempio: nn.Conv2d(3,6,5)\n  Non si passa la dimensione delle figure, viene presa in automatico!\n  alla funzione di max pool invece si passano solo: la dimensione del kernel e dimensione della stride:nn.MaxPool2d(2,2)\n\n\nProblemi:\n\n\n  ho provato ha mettere dei valori custom degli strati finali fully connected, non mi prende hidden_size2,\nma se metto un valore preciso lo prende… perche? Il motivo era che avevo messo queste quantita’ dentro la classe\nindentando. Se le metto fuori, vengono prese come variabili globali!\n\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# device config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Hyper parametri \ninput_size = 32*32    #  =1024 sono le dimensioni delle immagini\nnum_classes = 10      #  devo classificare immagini di numeri\nnum_epochs = 6        #  quanti giri completi vengono fatti\nbatch_size = 4        #  questo no so come sia stato scelto\nlearning_rate = 0.001 #  piccolo\nhidden_size1  = 220   #  scelto da me\nhidden_size2  = 184   #  scelto da me \n\ntransform =  transforms.Compose( [transforms.ToTensor(), transforms.Normalize( (0.5,0.5,0.5), (0.5,0.5,0.5)  )  ] )\n\n\ntrain_dataset = torchvision.datasets.CIFAR10(root= './data/', train= True, \n                                           transform =transform,            # uso le trasformazioni indicate sopra\n                                          download = True)\n\ntest_dataset = torchvision.datasets.CIFAR10(root= './data/', train= False, \n                                           transform =transform,\n                                          download = False) # ho gia' scaricato tutto con il train_datast\n\ntrain_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader (dataset=  test_dataset, batch_size = batch_size, shuffle=False)\n\n# Pytorch lavora con numeri, qui assegno i nomi corrispondenti\n#             0       1       2       3      4      5       6       7       8        9 \nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\ndef imshow(img):\n    img = img /2 + 0.5 # \"denormalizza\" forse per avere dei colori migliori\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1,2,0)))\n\n\n######### MODELLO ###############\n\nclass ConvNet(nn.Module):\n\n    \n    def __init__(self):\n        super(ConvNet, self).__init__()\n        self.conv1  = nn.Conv2d(3, 6, 5)     # input channel size, output channel size,  Kernel size 5 (5x5)\n        self.pool   = nn.MaxPool2d(2,2)      # kernel size, stride  (e' un quadrato 4x4 diviso in 4 parti 2x2)\n        self.conv2  = nn.Conv2d(6, 16, 5)    # input channel size = out di prima = 6, scelgo l'out= 16 e kernel size 5 (5x5)  \n        self.fc1    = nn.Linear(16*5*5, hidden_size1) # fully connected (spiegato dopo) ingresso, e 120 in uscita\n        self.fc2    = nn.Linear(hidden_size1, hidden_size2)     # in ingresso prende l'uscita del precedente e in output un tensor 1D con 84 ingressi\n        self.fc3    = nn.Linear(hidden_size2, 10)      # in uscita ho solo le 10 classi di oggetti (riga 38)            \n        \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))  #  MaxPool(ReLU(convoluzione(immagine))\n        x = self.pool(F.relu(self.conv2(x)))  #  MaxPool(ReLU(convoluzione( ))\n        x = x.view(-1, 16*5*5)                #  metto l'immagine processata in un vettore 1D\n        x = F.relu(self.fc1(x))               #  ReLU(fc())\n        x = F.relu(self.fc2(x))               #  ReLU(fc())\n        x = self.fc3(x)                       #  qui non faccio la ReLU, perche' poi nella cross entropy c'e' softmax\n        return x\n\n\n\nmodel = ConvNet().to(device)                  # metto sul device    \n    \ncriterion = nn.CrossEntropyLoss()             # serve per fare la LOSS, include la softmax per l'ultimo strato\noptimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n    \nn_total_steps  = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        # forma [4, 3, 32, 32] -&gt; [4, 3, 1024]       4 immagini, 3 canali di colore, 32 x 32 \n        # input layer: 3 canali di input, 6 canali di uscita, 5 kernel size\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # forward\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # backward e ottimizzazione dei pesi\n        optimizer.zero_grad()\n        loss.backward()              # chain rule\n        optimizer.step()             # step di ottimizzazione dato il learning rate\n        \n        if (i+1) % 1000 ==0:\n            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}')     \nprint(\"Training Terminato\")\n\n# qui faccio la fase di testing:\n\nwith torch.no_grad():\n    n_correct = 0\n    n_samples = 0\n    n_class_correct = [0 for i in range(10)]  # e' una lista uso una list-comprehension\n    n_class_samples = [0 for i in range(10)]  # non chiaro cosa sia questo\n    \n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        \n        _, predicted = torch.max(outputs, 1)\n        n_samples += labels.size(0)      # non serve una quadra?\n        n_correct += (predicted == labels).sum().item()       # questa da capire bene \n        \n        for i in range (batch_size):\n            label = labels[i]        # gira nel batch, label della singola immagine\n            pred = predicted[i]      # guarda la riga 90\n            \n            if (label == pred):\n                n_class_correct[label] += 1  # fa un istogramma\n            n_class_samples [label] +=1      # ne ho trovsata una un piu' della classe label\n    \n    acc = 100.0 * n_correct / n_samples      # percentuale di corrette sul totale dei sample\n    print(f'Accuracy  = {acc}:.4f')\n        \n    for i in range(10):\n        acc = 100.0 *n_class_correct[i]/ n_class_samples[i]  # accuracy della singola classe\n        print(f'Accuracy della classe {classes[i]}: {acc} %'  )\n    \n        \n\n\nFiles already downloaded and verified\nepoch 1 / 6, step 1000/12500, loss= 2.3000\nepoch 1 / 6, step 2000/12500, loss= 2.3080\nepoch 1 / 6, step 3000/12500, loss= 2.3117\nepoch 1 / 6, step 4000/12500, loss= 2.2834\nepoch 1 / 6, step 5000/12500, loss= 2.2788\nepoch 1 / 6, step 6000/12500, loss= 2.2987\nepoch 1 / 6, step 7000/12500, loss= 2.2965\nepoch 1 / 6, step 8000/12500, loss= 2.3122\nepoch 1 / 6, step 9000/12500, loss= 2.1770\nepoch 1 / 6, step 10000/12500, loss= 2.2453\nepoch 1 / 6, step 11000/12500, loss= 1.9151\nepoch 1 / 6, step 12000/12500, loss= 2.1131\nepoch 2 / 6, step 1000/12500, loss= 2.2575\nepoch 2 / 6, step 2000/12500, loss= 1.6527\nepoch 2 / 6, step 3000/12500, loss= 1.3318\nepoch 2 / 6, step 4000/12500, loss= 1.4340\nepoch 2 / 6, step 5000/12500, loss= 2.3746\nepoch 2 / 6, step 6000/12500, loss= 1.9364\nepoch 2 / 6, step 7000/12500, loss= 2.1739\nepoch 2 / 6, step 8000/12500, loss= 2.1157\nepoch 2 / 6, step 9000/12500, loss= 1.5521\nepoch 2 / 6, step 10000/12500, loss= 1.7367\nepoch 2 / 6, step 11000/12500, loss= 1.6836\nepoch 2 / 6, step 12000/12500, loss= 1.8475\nepoch 3 / 6, step 1000/12500, loss= 1.7431\nepoch 3 / 6, step 2000/12500, loss= 2.2294\nepoch 3 / 6, step 3000/12500, loss= 2.5908\nepoch 3 / 6, step 4000/12500, loss= 1.4687\nepoch 3 / 6, step 5000/12500, loss= 1.6939\nepoch 3 / 6, step 6000/12500, loss= 1.4162\nepoch 3 / 6, step 7000/12500, loss= 1.5874\nepoch 3 / 6, step 8000/12500, loss= 1.5107\nepoch 3 / 6, step 9000/12500, loss= 1.7396\nepoch 3 / 6, step 10000/12500, loss= 1.6814\nepoch 3 / 6, step 11000/12500, loss= 2.7111\nepoch 3 / 6, step 12000/12500, loss= 1.9274\nepoch 4 / 6, step 1000/12500, loss= 1.4081\nepoch 4 / 6, step 2000/12500, loss= 1.0557\nepoch 4 / 6, step 3000/12500, loss= 1.9581\nepoch 4 / 6, step 4000/12500, loss= 1.2325\nepoch 4 / 6, step 5000/12500, loss= 2.0073\nepoch 4 / 6, step 6000/12500, loss= 1.1686\nepoch 4 / 6, step 7000/12500, loss= 2.1211\nepoch 4 / 6, step 8000/12500, loss= 1.8252\nepoch 4 / 6, step 9000/12500, loss= 1.3711\nepoch 4 / 6, step 10000/12500, loss= 0.7326\nepoch 4 / 6, step 11000/12500, loss= 1.5150\nepoch 4 / 6, step 12000/12500, loss= 1.2301\nepoch 5 / 6, step 1000/12500, loss= 1.7059\nepoch 5 / 6, step 2000/12500, loss= 1.4075\nepoch 5 / 6, step 3000/12500, loss= 1.5126\nepoch 5 / 6, step 4000/12500, loss= 1.4504\nepoch 5 / 6, step 5000/12500, loss= 1.7903\nepoch 5 / 6, step 6000/12500, loss= 1.4010\nepoch 5 / 6, step 7000/12500, loss= 1.5074\nepoch 5 / 6, step 8000/12500, loss= 1.0711\nepoch 5 / 6, step 9000/12500, loss= 0.9101\nepoch 5 / 6, step 10000/12500, loss= 1.4603\nepoch 5 / 6, step 11000/12500, loss= 1.5229\nepoch 5 / 6, step 12000/12500, loss= 1.2879\nepoch 6 / 6, step 1000/12500, loss= 0.9052\nepoch 6 / 6, step 2000/12500, loss= 1.2526\nepoch 6 / 6, step 3000/12500, loss= 1.0965\nepoch 6 / 6, step 4000/12500, loss= 1.1149\nepoch 6 / 6, step 5000/12500, loss= 1.2192\nepoch 6 / 6, step 6000/12500, loss= 1.1820\nepoch 6 / 6, step 7000/12500, loss= 1.4098\nepoch 6 / 6, step 8000/12500, loss= 1.8098\nepoch 6 / 6, step 9000/12500, loss= 1.0243\nepoch 6 / 6, step 10000/12500, loss= 1.3008\nepoch 6 / 6, step 11000/12500, loss= 0.9658\nepoch 6 / 6, step 12000/12500, loss= 1.0129\nTraining Terminato\nAccuracy  = 52.13:.4f\nAccuracy della classe plane: 49.5 %\nAccuracy della classe car: 71.5 %\nAccuracy della classe bird: 49.9 %\nAccuracy della classe cat: 33.7 %\nAccuracy della classe deer: 29.7 %\nAccuracy della classe dog: 32.7 %\nAccuracy della classe frog: 78.4 %\nAccuracy della classe horse: 50.6 %\nAccuracy della classe ship: 69.7 %\nAccuracy della classe truck: 55.6 %\n\n\nTransfer Learning\nIn questo paragrafro viene spiegato come usare parzialmente dei modelli gia’ “trainati” per fare dei nuovi compiti simili.\nCuriosamente questo sembra funzionare molto bene.\nDico curiosamente perche’ non e’ chiaro il motivo per cui una rete neurale che ha un training su degli oggetti possa andare bene anche su degli oggetti differenti. A meno che, in qualche modo, si siano imparate delle caratteristiche generali dal primo training.\n\nQuello che e’ davvero potente e’ che modificando l’ultimo layer posso cambiare \nil numero di valori in uscita. Con Resnet18 ci sono 1000 classi in uscita. Cambio l’ultimo layer e \nme ne servono solo 2 in uscita: no problem!\n\n\n  per esempio faccio il training per un modello che classifica uccelli e gatti\n  con una piccola modifica gli faro’ classificare api  e cani\n\n\nOsservazione\n\n  gli uccelli hanno caratteristiche in comune alle api (non mi pare scelto a caso!)\n  i cani hanno caratteristiche in comune ai gatti (anche questo non mi pare a caso)\n\n\nQuindi il transfer learning, intuitivamente, funziona bene quando le modifiche da fare sono piccole (e’ un pensiero mio).\n\nSi cambia solo l’ultimo strato fully connected (rispetto al caso precedente gli ultimi 3 strati),\nquesto e’ infatti lo strato di classificazione. Gli strati precedenti tramite le convoluzioni e i pooling dovrebbero estrarre le caratteristiche dei vari oggetti.\n\n\n  Intuitivamente mi viene da dire che gli strati convoluzionali prendono i “pezzi” (p.es le ali, le zampe, ecc, ma nella realta’ prendono dettagli molto piu’ piccoli)\n  gli strati finali mettono insieme questi pezzi elementari.\n  quindi mi viene da dire che dovrebbe bastare 1 strato fully connected.\n  in realta’ nel video di 3blue1brown si vede che non e’ molto chiaro cosa venga preso nei vari passaggi.\n\n\nIn questo caso vediamo anche come caricare un modello gia’ “trainato” (devo trovare un nome migliore…ma dire con i pesi ottimizzati e’ lungo e anche modello ottimizzato non mi piace):\nResnet18NN\n\n  basato sul Imagenet database (con piu’ di 1 000 000 immagni)\n  ha 18 strati\n  classifica oggetti di 1000 categorie.\n\n\nAttenzione che qui fa una cosa leggemente diversa da quanto fatto finora, dove si costruisce il modello e lo si lancia da un loop.\n\nIn questo caso costruisce una funzione\n\nImage Folder\nCostruire un folder dove mettere le immagini che devono servire per train e test. \nIl folder che contiene le immagini che vogliamo usare come nuovo training ha il seguente formato:\n\n  train\n    \n      ants\n      bees\n    \n  \n  val\n    \n      ants\n      bees\n    \n  \n\n\nQuindi se la struttura e’ questa chiamando datasets.Imagefolder posso leggere e trasformare in un dataset.\nPosso inoltre usare l’attributo classes.\n\nScheduler\n\n  E’ una funzione che modifica il learning rate durante il training per ottimizzare la discesa dei gradienti.\n\n\nFine Tuninig\ntengo tutto il modello pre-trainato ma modifico solo l’ultimo layer\n\nDomande\nper come e’ scritto il codice sembra che in varie epoche i modelli siano diversi, non ci sia un aggiornamento continuo. In pratica fa una deepcopy del miglior modello (ma io dovrei salvare, altrimenti perdo tutto e devo rifare)\n\nNon riesco a trovare il modello!? dove lo ha caricato? Non lo ha ancora caricato!\n\n\n  model.train()  metodo che fa il training?\n\n\nTempo\n\n  se freezo il train tranne l’ultimo layer ci mette 1:42 s\n  se re-train tutto il modello ci ha messo circa 2:14 s\n\n\n(ricorda che partiva gia’ trainato)\n\nTrain() e Eval()\nsono due metodi associati al modello che precedentemente non avevo usato\n\n# prendo e modifico il codice di prima secondo quanto scritto nella lezione 14\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler  # nuovo non ancora  caricato prima\nimport torchvision\n#import torchvision.transforms as transforms\nfrom torchvision import datasets, models, transforms  # \nimport matplotlib.pyplot as plt\nimport time                      # per controllare l'orario\nimport os                        # per interagire con l'os\nimport copy                      # per fare una deep copy del modello che e' un oggetto complesso (non vogliamo shallow copy)\nimport sys                       # per bloccare (c'e' una funzione tipo  stop del fortran)\n%matplotlib inline\n\n# device config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmean = np.array([0.485, 0.456, 0.406])   # queste non so come sono state scelte\nstd = np.array([0.229, 0.224, 0.225])    # idem\n\n\n# Hyper parametri \ninput_size = 32*32    #  =1024 sono le dimensioni delle immagini\nnum_classes = 10      #  devo classificare immagini di numeri\nnum_epochs = 6        #  quanti giri completi vengono fatti\nbatch_size = 4        #  questo no so come sia stato scelto\nlearning_rate = 0.001 #  piccolo\nhidden_size1  = 220   #  scelto da me\nhidden_size2  = 184   #  scelto da me \n\n\n# qui faccio un dizionario che contiene le trasformazioni da applicare\ndata_transforms = {\n    'train': transforms.Compose([transforms.RandomResizedCrop(224), \n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean,std)])\n    ,\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean,std)\n    ])\n}\n\n# import data\ndata_dir = 'data/hymenoptera_data'         # dove ci sono le api? Imenotteri\nsets  = ['train', 'val']                   # lista che contiene mi sa che poi non lo usa\n\n\n# Questo sotto e' da pensare un momento\n# e' una list comprehension (in un dictionary)\n# dove in realta' ci sono 2 directory, poteva mettere il path... e forse scriveva meno.\n# in ogni caso la parte che non mi e' chiarissima sono i : dopo la x\n# no e' banale: e' un dictionary e la x sono le chiavi e le datasets.Image... sono i valori\n# tutti ottenuti con una list comprehension finale\nimage_datasets= {x:datasets.ImageFolder( os.path.join(data_dir, x), data_transforms[x] )\n                 for x in ['train', 'val'] }\n\ndataloaders  = {x: torch.utils.data.DataLoader(image_datasets[x],\n                    batch_size = batch_size,\n                    shuffle= True,\n                    num_workers= 0) for x in  ['train', 'val']}\n\n\ndataset_sizes  = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names  = image_datasets['train'].classes      # .classes e' un attributo \n\nprint(class_names)\n#sys.exit()                      # per fermare qui\n\n\n######### funzione che contiene il training loop  ##############\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25): \n    since = time.time()     # penso chen questo sia il momento d'inizio\n\n    best_model_wts = copy.deepcopy(model.state_dict())  # fa una deep copy del modello\n    best_acc = 0.0                                      # \n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs-1}')\n        print('-'* 10)                             # disegna una riga orizzontale\n        \n        # In ogni epoca si ha una fase di training e validation:\n        for phase in ['train', 'val']:\n            if phase== 'train':\n                model.train()              # set model to train mode  #######################\n            else:\n                model.eval()               # set model to evaluation mode\n            \n            running_loss = 0.0             # in qualche modo voglio vedere live se il training va bene\n            running_corrects =0\n            \n\n            for inputs, labels in dataloaders[phase]:       # distinguo tra le fasi train/val\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n            \n                ################  forward pass\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs =  model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs,labels)\n            \n                ################ backward pass\n                    if phase == 'train':\n                        optimizer.zero_grad()      # non mi seve quando faccio l'ottimizzazione\n                        loss.backward()            # chain rule\n                        optimizer.step()           # mi muovo in funzione del gradiente\n                 \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds==labels.data)  \n            \n            if phase =='train':\n                scheduler.step()    # =========================  questo aggiorna il learning_rate\n            \n            epoch_loss =running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            \n            print(f'{phase} Loss: {epoch_loss:.4f}  Acc: {epoch_acc:.4f} ')\n\n            # deep copy model\n            \n            if phase =='val' and epoch_acc &gt; best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())   # questo copia il dizionario associato al miglior modello\n        \n        print()\n    time_elapsed = time.time() -since\n    print(f'Training completato in {time_elapsed//60:.0f}  minuti {time_elapsed%60:.0f}s ')\n           \n    model.load_state_dict(best_model_wts)    \n    return model    \n        \n######### importiamo il MODELLO ############### \n\nmodel = models.resnet18(pretrained=True )       # qui il modello e' importato da torchvision e lo mette nella cache\n\n# se voglio bloccare tutti i parametri tranne quelli dell'ultimo layer basta che \n# li blocco:!\n\nfor param in model.parameters():\n    param.requires_grad = False     # non fa il gradiente!\n\nnum_ftrs = model.fc.in_features                 # ho preso il layer fully connected (ultimo) e queste sono le input features?\n\n# ora creo un nuovo layer e lo assegno come ultimo layer. \n# come faccio a sapere che l'ultimo layer si chiama `fc`?\n\nmodel.fc = nn.Linear(num_ftrs, 2)  # ho solo 2 classi in uscita.  DI DEFAULT ha requires_grad = True\nmodel.to(device)                    \n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001 )   # occhio che lui aveva importato in modo diverso e chiama solo optim.SGD\n\n############ SCHEDULER che fa una update del lr #######\n\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # ogni 7 epoch lr =lr*gamma (diventa 1/10)\n\n#for epoch in range(100):\n#    train()   # optimizer.step()\n#    evaluate()\n#    scheduler.Step()\n    \nmodel = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=20)\n\n# qui alla fine ho trovato il modello ottimale, e potrei salvarlo volendo.\n\n\n\n['ants', 'bees']\nEpoch 0/19\n----------\ntrain Loss: 0.6456  Acc: 0.6230 \nval Loss: 0.5187  Acc: 0.8039 \n\nEpoch 1/19\n----------\ntrain Loss: 0.5606  Acc: 0.7049 \nval Loss: 0.4390  Acc: 0.8627 \n\nEpoch 2/19\n----------\ntrain Loss: 0.5181  Acc: 0.7623 \nval Loss: 0.4065  Acc: 0.8301 \n\nEpoch 3/19\n----------\ntrain Loss: 0.4886  Acc: 0.7910 \nval Loss: 0.3304  Acc: 0.8954 \n\nEpoch 4/19\n----------\ntrain Loss: 0.4584  Acc: 0.8197 \nval Loss: 0.3134  Acc: 0.8954 \n\nEpoch 5/19\n----------\ntrain Loss: 0.4822  Acc: 0.7623 \nval Loss: 0.2991  Acc: 0.9085 \n\nEpoch 6/19\n----------\ntrain Loss: 0.4221  Acc: 0.8115 \nval Loss: 0.2734  Acc: 0.9216 \n\nEpoch 7/19\n----------\ntrain Loss: 0.4034  Acc: 0.8156 \nval Loss: 0.2741  Acc: 0.9216 \n\nEpoch 8/19\n----------\ntrain Loss: 0.3629  Acc: 0.8852 \nval Loss: 0.2734  Acc: 0.9216 \n\nEpoch 9/19\n----------\ntrain Loss: 0.4139  Acc: 0.8197 \nval Loss: 0.2570  Acc: 0.9216 \n\nEpoch 10/19\n----------\ntrain Loss: 0.4058  Acc: 0.8402 \nval Loss: 0.2794  Acc: 0.9085 \n\nEpoch 11/19\n----------\ntrain Loss: 0.4000  Acc: 0.8238 \nval Loss: 0.2611  Acc: 0.9346 \n\nEpoch 12/19\n----------\ntrain Loss: 0.4265  Acc: 0.8156 \nval Loss: 0.2510  Acc: 0.9346 \n\nEpoch 13/19\n----------\ntrain Loss: 0.3911  Acc: 0.8648 \nval Loss: 0.2729  Acc: 0.9085 \n\nEpoch 14/19\n----------\ntrain Loss: 0.4748  Acc: 0.7787 \nval Loss: 0.2668  Acc: 0.9216 \n\nEpoch 15/19\n----------\ntrain Loss: 0.3790  Acc: 0.8443 \nval Loss: 0.2865  Acc: 0.9020 \n\nEpoch 16/19\n----------\ntrain Loss: 0.3815  Acc: 0.8730 \nval Loss: 0.2611  Acc: 0.9412 \n\nEpoch 17/19\n----------\ntrain Loss: 0.3946  Acc: 0.8197 \nval Loss: 0.2722  Acc: 0.9020 \n\nEpoch 18/19\n----------\ntrain Loss: 0.4166  Acc: 0.8525 \nval Loss: 0.2828  Acc: 0.9085 \n\nEpoch 19/19\n----------\ntrain Loss: 0.3790  Acc: 0.8484 \nval Loss: 0.2649  Acc: 0.9216 \n\nTraining completato in 1  minuti 42s \n\n\nTensorboard\n\nhttps://pytorch.org/docs/stable/tensorboard.html\n\ninstallazione, io ho usato conda: conda install -c conda-forge/label/cf202003 tensorboard\n\nTensorboard e’ un metodo per visualizzare tramite delle dashboard visibili da browser:\n\n  il grafo computazionale\n  l’evoluzione dei parametri (Loss, accuracy, ecc…)\n  nota che e’ sviluppato per Tensorflow (ma funge anche con Pytorch)\n  visualizzare istogrammi dei pesi e dei bias\n  visualizzare immagini, testi, audio (eh si lavora anche con quelli)\n  fare un profiling dei programmi di TensorFlow\n  Project embeddings in lower dimensional spaces   ?????\n\n\nViene usato il codice del tutorial numero 13 (il riconoscimento delle immagini dei numeri da 0 a 9). Da quel codice ho tolto quasi tutti i commenti in modo che i commenti rimanenti siano solo per \nl’utilizzo di tensorboard\n\n\n  \n    Quando si lancia Tensorboard bisogna specificare il path dove verranno salvati i logfile. Di default vengono messi nella directory chiamata run (suppongo che sia una sottodir dell’installazione di Tensorboard\n  \n  \n    per fare partire Tensorboad (dalla dir dove si e’ lanciato il Python):  \ntensorboard --logdir=runs \na questo punto si apre un browser alla pagina: \nhttp://localhost:6006\n  \n\n\n(CTRL+C = quit)\n\n\n  La prima cosa che si fa e’ essenzialmente istanziare un writer: writer=SummaryWriter('runs/mnist') (riga 12).\nIl writer  in pratica scrive dei valori in formato JSON (controllare) con specifiche che tensorboard va a leggere nella dir runs e, note le chiavi le mette nella dashboard.\n\n\nIn pratica a quanto capisco, il writer scrive i dati in un formato particolare che viene poi\nletto da tensorboard e mandato nella dashboard al localhost:6006. Questo e’ il motivo per cui l’oggetto fondamentale e’ un writer che ha dei vari metodi in grado di scrivere le informazioni dei vari oggetti in modo che Tensorboard le interpreti correttamente.\n\nI Esempio di utilizzo: visualizzo i dati nel browser, consiste di 3 passi (piu’ l’istanza del writer appena fatta):\n\n\n  Costruisco una griglia di immagini img_grid  = torchvision.utils.make_grid(example_data) (usando le utility di torchvision)\n  Do in pasto la griglia al writer, tramite il metodo add_image:  writer.add_image('Immagini di Mnist', img_grid),\nil primo argomento una label per la image grid, il secondo e’ la griglia stessa\n  uso il metodo writer.close() per assicurarmi che tutti i dati siano mandati\n\n\nII Esempio di utilizzo: visualizzo il grafo computazionale. Consiste di 2 passi.\n\n  uso il metodo   writer.add_graph(model, examples_data.reshape(-1,28*28).to(device)),quindi il primo argomento e’ il modello e il secondo sono ancora gli esempio (che ho flattenato). Attento, dato che sto mettendo tutto sul device, devo farlo anche per quanto riguarda examples_data, nel video non viene fatto! (questo perche’ il notebook usato non ha una scheda grafica dedicata e quindi sono comunque tutti sull’host.\n  chiudo il writer per assicurarmi che tutti i dati vengano passati: writer.close()\n\n\nNota che dopo avere scritto l’esempio II,  appare una seconda scelta in tensorboard (in alto), chiamata graph. Si vede quindi il grafo computazionale che viene visualizzato. Con dei doppi click si aprono nel dettaglio i grafi!\n\nIII Esempio di utilizzo: mando la loss e la accuracy durante l’esecuzione. Consiste di 2 passi. Vogliamo la loss media durante il training, quindi aggiungo delle variabili al mdoello.\n\n  uso un nuovo metodo: writer.add_scalar('Training loss', running_loss/100, epoch* n_total_steps + i)\nNota che ho definito prima delle nuove quantita’ da mandare al writer tramite add_scalar\n\n\nAttento se continuo a fare girare la rete neurale nel notebook, i dati in Tensorboard si accumulano a quelli dei run precedenti. Devo trovare un modo per azzerare i dati.\nSoluzione:\ndevi rinominare la dir  dove vengono salvati i dati per ogni run diverso. In questo modo si avranno delle righe di colore diverso per ogni run. Altrimenti provo ad andare a cancellare il contenuto della dir runs/mnist (occhio che e’ una cartella che viene creata nella stessa dir di dove gira il python!) (magari esiste un metodo migliore devo investigare). Ho cancellato tutto ma non funge… ok funge, li teneva in memoria! ho riavviato tensorboard ed e’ sparito tutto. La cosa curiosa e’ che aprendo gli eventi sembrano vuoti… Solo il primo contiene molti valori, il resto sono gli incrementi sul primo direi.\n\nAttento quando ci sono degli scalari (dei grafici) di default Tensorboard aggiunge una linea di smoothing (e’ nella modale(?) subito a sinistra).\n\nIV Eempio di utilizzo: aggiungere una precision e recall curve (riguarda le note sulla confusoin matrix per le definizioni esatte). Esiste un metodo apposta per aggiungere la precision. Guarda il link: pytorch.org/docs/stable/tensorboard.html\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom torch.utils.tensorboard import SummaryWriter   ##############  TENSORBOARD\nimport sys \nimport torch.nn.functional as F\n\n##### costruisco un writer ####################\nwriter  =SummaryWriter('runs/mnist') # come argomento serve la dir dove vanno salvati i file\n#####    fine writer   ########################\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ninput_size = 28*28    \nhidden_size  = 100    \nnum_classes = 10      \nnum_epochs = 2        \nbatch_size = 100      \nlearning_rate = 0.001 \n\ntrain_dataset = torchvision.datasets.MNIST(root= './data/', train= True , transform =transforms.ToTensor(), download = True)\ntest_dataset  = torchvision.datasets.MNIST(root= './data/', train= False, transform =transforms.ToTensor(), download = False) # \n\ntrain_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader (dataset=  test_dataset, batch_size = batch_size, shuffle=False)\n\nexamples = iter(test_loader)\nexamples_data, examples_targets = examples.next()\n#for i in range(6):\n#    plt.subplot(2,3,i+1)\n#    plt.imshow(example_data[i][0], cmap='gray')\n\n    \nimg_grid  = torchvision.utils.make_grid(examples_data)\nwriter.add_image('Immagini di Mnist' , img_grid)    \nwriter.close()     # questo assicura che tutti gli output sono flushati\n#sys.exit()    # per non dover fare tutto il training    \n\n############  MODELLO ####################\nclass NeuralNet(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(NeuralNet, self).__init__()\n        self.l1 = nn.Linear(input_size, hidden_size)  \n        self.relu = nn.ReLU()\n        self.l2 = nn.Linear(hidden_size, num_classes)\n       \n    def forward (self, x):\n        out = self.l1(x)       \n        out = self.relu(out)   \n        out = self.l2(out)\n        return out             \n\n############### ISTANZIO MODELLO, Back e Forw ########\nmodel = NeuralNet(input_size, hidden_size, num_classes).to(device)\ncriterion  = nn.CrossEntropyLoss()   # non ha bisogno di parametri\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)        \n\n\n######  Aggiungo un altro grafo alla dashboard di Tensorboard,\n###### ora uso il metodo     add_graph   (prima ho usato add_image)\nwriter.add_graph(model, examples_data.reshape(-1,28*28).to(device))\nwriter.close()\n#sys.exit()\n\n############### TRAINING LOOP ############\nn_total_steps = len(train_loader)\n\n\nrunning_loss = 0.0      # questo e' il valore aggiornato in tempo reale\nrunning_correct = 0     # idem\n\nfor epoch in range(num_epochs):                           \n   for i, (images,labels) in enumerate (train_loader):         \n        images = images.reshape(-1, 28*28).to(device)     \n        labels = labels.to(device)\n              \n        outputs = model (images)                           \n        loss = criterion(outputs, labels)\n                 \n        optimizer.zero_grad()     \n        loss.backward()            \n        optimizer.step()          \n        \n################ da mandare a TENSORBOARD ####################        \n        running_loss += loss.item()  # aggiorno il totale\n        _, predicted  =torch.max(outputs.data, 1)\n        running_correct += (predicted == labels).sum().item()\n################ ##################### ########################        \n        \n        \n        if (i+1) % 100 ==0:\n            #print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}')        \n\n############## qui aggiungo alla dashboard un nuovo oggetto TENSORBOARD ######\n            writer.add_scalar('Training loss', running_loss/100, epoch* n_total_steps + i)\n            writer.add_scalar('Accuracy', running_correct/100, epoch* n_total_steps + i) \n            running_loss = 0.0     # riazzero\n            running_correct = 0    # riazzero\n            writer.close()\n######################################################            \n            \n            \n\n        \n        \n        \n################ per Tensorboard ########################\nlabels2 = []   #occhio che aveva gia' definito labels sotto, ho messo un 2 Tensorboard\npreds = []\n#########################################################\n        \n############ TEST LOOP #################\nwith torch.no_grad():    \n    n_correct = 0         \n    n_samples = 0           \n    for images, labels in test_loader:\n        images = images.reshape(-1, 28*28).to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)    \n        \n        _, predictions = torch.max(outputs,1)  \n        n_samples += labels.shape[0]           \n        n_correct += (predictions == labels).sum().item()\n        \n        class_predictions = [F.softmax(output, dim=0) for output in outputs]  # ho bisogno di probabilita', quindi serve softmax\n        preds.append(class_predictions)\n        labels2.append(predicted)   # per TENSORBOARD\n        \n    preds = torch.cat ([torch.stack(batch) for batch in preds ]) # tensorboard 2D oggetto 1000, 1\n    labels2 = torch.cat(labels2)   # Tensorboard concateno le liste in un oggetto 1D        1000\n    \n    classes = range(10)   # tutte le possibili classi  0-9  Tensorboard\n    for i in classes:\n        labels_i = labels2 == i    # Tensorboard    non chiaro cosa fa\n        preds_i = preds[:,i]      # Tensorboard \n        writer.add_pr_curve(str(i), labels_i, preds_i, global_step =0) # TEnsorboard\n        writer.close()       # chiudo il writer\n    \n    \n    acc = 100.0  * n_correct / n_samples       \n    print(f'accuracy ={acc}')            \n\n\naccuracy =95.03"
					}
					
				
			
		
			
				
					,
					
					"pytorch-4": {
						"id": "pytorch-4",
						"title": "Pytorch 4 Feed Forward Neural Network",
						"categories": "italiano",
						"url": " /Pytorch-4",
						"content": "tocIn this post\n  \n  \n\n  Feed Forward Neural Network    \n      il Modello\n      Criterion e Optimizer\n      Training loop\n      Test Loop\n      Prove sul modello\n      Prova senza funzioni di attivazione: e’ un modello lineare!\n    \n  \n\n\n  \n\n\nIndice Globale degli argomenti tra i vari post:\n\n 1.1.                                    Indice degli argomenti.\n 1.1.                                      Introduzione e fonti.\n 1.1.                                  Lingo - Gergo utilizzato.\n 1.2.                                        Tensori in Pytorch.\n 2.1.                                      Chainrule e Autograd.\n 2.2.                                           Backpropagation.\n 3.1.                                          Loss e optimizer.\n 3.2.                                        Modelli di Pytorch.\n 3.3.                                      Dataset e Dataloader.\n 3.4.                                       Dataset Transforms.\n 3.5.                              Softmax e Cross-Entropy Loss.\n 3.6.                                       Activation Function.\n 4.1.                                Feed Forward Neural Network.\n 5.1.                               Convolutional Neural Network.\n 5.2.                                          Transfer Learning.\n 5.3.                                                Tensorboard.\n 6.1.                              I/O Saving and Loading Models.\n 7.1.                                  Recurrent Neural Networks.\n 7.2.                                            RNN, GRU e LSTM.\n 8.1.                                          Pytorch Lightning.\n 8.2.                                               LR Scheduler.\n 9.1.                                                Autoencoder.\n\nFeed Forward Neural Network\nQuesto e’ il primo esempio di rete neurale funzionante. Nota che qui NON vengono fatti i passaggi preliminari per conoscere la struttura del datset, per vedere se le classi sono bilanciate, o per fare delle trasformazioni. L’ipotesi di partenza e’ che il dataset sia ok.\n\nScopo:\n\n  costruire una fully connected neural network con 1 hidden layer (Feed Forward: una volta fatto il passo il lavoro e’ finito).\n  per il riconoscimento di immagini del dataset MNIST  (sono i numeri da 0 a 9 scritti a mano da varie persone, in immagini 28 x28 pixel con un solo canale di colore)\n\n\nMetodo:\n\n\n  Dataset e Dataloader:\n    \n      Si importa un dataset, per esempio: torchvision.datasets.MNIST(...)\n      Si creano 2 dataloader, uno per il train e uno per il test, per esempio: torch.utils.data.DataLoader(...)\n    \n  \n  Costruzione e istanziazione del modello:\n    \n      si importa la classe nn.Model, a cui si devono poter passare come parametri le dimensioni dei tensori iniziali, hidden e output…\n      in nn.Model, all’interno del metodo __init__ si costruiscono i metodi e gli attributi che serviranno al grafo computazionale (per esempio self.l1= nn.Linear, self.n_output= n_output…)\n      in nn.Model si definiscono anche le ReLU, SoftMax, ecc  self.relu= nn.ReLU()\n      eventualmente gli oggetti vengono mandati sul device: .to(device)\n      in nn.Model si costruisce il metodo forward() (il nome deve essere proprio forward) in cui si mettono i vari passaggi costruire il grafo computazionale\n      Finita la costruzione del modello se ne fa un’istanza passando come argomenti i valori corretti delle dimensioni dei tensori\n      si usa il metodo per mandare il modello sulla GPU: modello = NeuralNet(input_size,...).to(device)  in modo che sia sulla GPU\n    \n  \n  Scelta della funzione di loss (criterion) e del metodo di ottimizzazione (optimizer)\n    \n      si sceglie una funzione di loss (che per esempio possiamo chiamare criterion) (occhio che la CrossEntropy include gia’ softmax)\n      si applica optimizer.zero_grad() per evitare che l’ottimizzatore entri nel grafo computazionale\n      ci si ricorda di\n      loss.backwards() costruisce i gradienti rispetto ai pesi (che hanno autograd =True) tramite la chain rule. Il gradiente della loss serve poi per l’ottimizzazione\n      si sceglie una funzione di ottimizzazione optimizer:  SGD, Adam, … : per esempio: optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) Nota che bisogna passare i parametri del modello che vengono ottenuti tramite model.parameters(), perche’ l’ottimizzatore sappia cosa deve modificare.\n      optimizer.step() fa un passo nella direzione dell’ottimizzazione in funzione del learning rate.\n    \n  \n  Loop sulle epoche e sui batch.\n    \n      si fa un loop sulle epoche (sceglo io quante).\n      si fa un loop per tutti i batch di ogni epoca.\n      con enumerate si spacchettano le immagini e le label dal dataloader.\n      si usa view o reshape per trasformare gli oggetti in 1D (il risultato e’ lo stesso)\n      NON chiaro, che differnza c’e’ tra passare un’immagine e un batch di immagini al modello? come viene gestito?\n      NON si chiama forward, ma si passano gli oggetti da classificare al modello (perche’ il modello nn.Model ha gia’ implementato un metodo __call__ e questo in pratica fa si che quando si chiami il modello come se fosse una funzione, allora si fa entrare in azione il metodo forward)\n      si crea una loss= criterion(output, labels)  (posso comodamente cambiare la loss cambiando il criterio)\n      optimizer.zero_grad() ci si assicura che la backpropagation e l’ottimizzazione non modifichino i gradienti. Si evita quindi che entrino nel grafo computazionale.\n      si costruisce la chain rule con:  loss.backward()\n      si ottimizzano i pesi usando un metodo del criterio di ottimizzazione: criterion.step()\n    \n  \n  Si fa la validazione del modello tramite il test set\n    \n      in questo caso si vuole evitare che i gradienti vengano fatti: with torch.no_grad()\n      si fanno i loop su tutti i batch (non ha senso sulle epoche) del test dataloader\n      si usano delle metriche, per esempio l’accuracy.\n    \n  \n\n\nNote:\n\n  Per supporto GPU si costruisce un oggetto device come alla riga 8\n  piu’ tardi si fara’ un push to device, ottenuto sia per il modello che per i tensori tramite il metodo .to(device) (con l’oggetto device opportunamente definito prima, riga 8.\n  Occhio che non esiste “transform.ToTensor” ma “transforms”.ToTensor con una s dopo transform!!!! python mi dava errore: non esiste transform, ma l’errore era una semplice dimenticanza.\n  nota che la prima volta che carico il dataset ci mette un po’, la seconda volta MOLTO meno (lo mette da qualche parte in memoria forse)\n\n\nAll’inizio ci serve l’oggetto Module preso da nn. Questo oggetto e’ una specie di contenitore che connette le varie parti di una rete neurale.\n\nUn layer fully connected da nn.Module ha bisogno di 3 parametri:\n\n  input size (numero di punti dell’immagine)\n  hidden size (numero di nodi nascosti)\n  output size (in questo caso sono le classi in uscita che voglio trovare).\n\n\nRicordiamoci di chiamare il metodo super. Questo mi consente di poter usare i metodi della superclass (la classe che ho ereditato) senza dover riscriverli da zero. Una buona spiegazione: https://realpython.com/python-super/\n\nIl metodo forward ha 2 argomenti: self e x\n\n  self serve perche’ siamo dentro la classe e vogliamo accedere a tutti gli della istanza\n  x e’ invece l’immagine (il batch di immagini) che vogliamo catalogare\n\n\nposso prendere invece che self.relu   nn.ReLU ? (provare)\n\n\n  Non applico la softmax alla fine perche’ la cross entropy \nha gia’ la softmax incorporata\n\n\nForward pass: ho un problema mi dice che non sono allineati gli oggetti\nsu cpu e gpu, in particolare dice che :\n\n  out e’ su CPU\n  il tensore passato come argomento uno al modello e’ su CPU\n  ma lui se li aspetta sulla GPU\n\n\nRISOLTO: dovevo usare il metodo to.(device) quando istanziavo il modello! (riga 17 del modello)\nAttento che lui nel video non lo faceva (probabilmente perche’ ha piu’ volte detto che il suo laptop non ha supporto GPU, quindi ovunque lui mandi qualcosa su device, resta su cpu)!\n\nNel seguito, prima spezzo in varie celle i passaggi, e poi per ultimo costruisco una cella con tutti i passaggi congiunti in modo da avere un luogo dove fare qualche esperimento.\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# device config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # device, dove mandare i vari oggetti \n\n# Hyper parametri \ninput_size = 28*28    #  =784 sono le dimensioni delle immagini\nhidden_size  = 1000   #  scelto da me, e' la dimensione della hidden layer\nnum_classes = 10      #  devo classificare immagini di numeri da 0 a 9, quindi la dimensione dell'output =10\nnum_epochs = 2        #  faccio 2 giri completi sul dataset di train\nbatch_size = 100      #  questo no so come sia stato scelto, comunque posso modificare\nlearning_rate = 0.001 #  piccolo (potrei poi usare delle funzioni per cambiare questo parametro durante l'evoluzione)\n\n#carico i dataset MNIST\n#  root e' dove viene messo il dataset quando viene caricato \n#  gli diciamo poi che e' un dataset usato per il _training_\n#  Occhio che poi quando facciamo train=False per costruire il dataset di test, lui splitta automaticamente\n#  mi domando in quale percentuale. \n#  Trasformiamo le immagini facendo diventare le immagini in tensori\n#  lo scarico se non e' gia' nella dir data\n\ntrain_dataset = torchvision.datasets.MNIST(root= './data/', train= True, \n                                           transform =transforms.ToTensor(),\n                                          download = True)\n\ntest_dataset = torchvision.datasets.MNIST(root= './data/', train= False, \n                                           transform =transforms.ToTensor(),\n                                          download = False) # ho gia' scaricato tutto con il train_datast\n\n\n# costruisco i dataloader:\n#DataLoader necessita di almeno 2 parametri:\n#  il nome del dataset\n#  il la dimensione del batch\n#  poi si fa shuffle = True/False\n\ntrain_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader (dataset=  test_dataset, batch_size = batch_size, shuffle=False)\n\n## guardiamo un batch dei dati:\n\nexamples =  iter(train_loader)\nsamples, labels = examples.next()\n\nprint(samples.shape, labels.shape)\n### nota che la dimensione dei sample e' la seguente\n# 100  = numero di immagini nel batch (se non metti batch_size, di default vale 1)\n#   1  = numero di canali solitamente i colori\n#  28  =  numero di ingressi sull'asse delle x\n#  28  = numero di ingressi sull'asse delle y\n\n\ntorch.Size([100, 1, 28, 28]) torch.Size([100])\n\n\nqui disegno i sample, ricorda che subplot, indica la struttra, righe e colonne e poi l’indice dice quale di questi e’.\n\nfor i in range(6):\n    plt.subplot(2,3,i+1)     # i primi parametri indicano 2 righe e 3 colonne, e poi il numero dell'immagine corrente.\n    plt.imshow(samples[i][0], cmap= 'gray')  # occhio che c'e' solo samples[i][0], le label sono state messe in labels.\n\n\n\n\n\nil Modello\n\n# qui costruisco il modello: e' una classe\n\nclass NeuralNet(nn.Module):                                    # lo chiamo NeuralNet e lo importo da nn.Module\n    def __init__(self, input_size, hidden_size, num_classes):  # il costruttore\n        super(NeuralNet, self).__init__()                      # super per ereditare da nn.Module\n        self.l1 = nn.Linear(input_size, hidden_size)           # L MAIUSCOLA per Linear\n        self.relu = nn.ReLU()                                  # funzione di attivazione ReLU \n        self.l2 = nn.Linear(hidden_size, num_classes)          # secondo(ultimo) strato fully connected\n       \n    def forward (self, x):    # l'argomento self indica che viene lanciato su se stessi, la x e' il batch di immagini\n        out = self.l1(x)      # sfrutto il metodo self.l1 a cui ho gia' dato dei parametri prima\n        out = self.relu(out)  # ReLU non aveva bisogno di parametri: posso prendere nn.ReLU ?\n        out = self.l2(out)\n        return out            # DEVE restituire qualcosa: l'output\n    \n\n# qui creo una istanza del modello:\nmodel = NeuralNet(input_size, hidden_size, num_classes).to(device)\n\n\nCriterion e Optimizer\n\n  Qui sotto costruisco la funzione di LOSS\n  Poi costruisco l’optimizer, ovvero il metodo che mi “aggiusta” i pesi della rete neurale secondo determinati schemi. Attento, devo passare degli argomeni all’optimizer.\nIn particolare c’e’ un metodo del modello che si chiama model.parameters()\n\n\ncriterion  = nn.CrossEntropyLoss()                                    # non ha bisogno di parametri\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)  # qui devo passare i parametri del modello!\n\n\nTraining loop\nQui sotto faccio il training che e’ composto da un loop esterno epoch e uno interno sui batch della singola epoch.\n\nOsservazioni:\n\n\n  Il loop sui batches e’ fatto in modo interessante, con enumerate(dataloader). In questo modo ho un indice che mi dice in quale batch sono, inoltre ho creato una tupla contenente sia l’immagine che la corrispondente label (tra tonde)\n  devo mandare sia le immagini che le label sul device .to(device)\n  uso il modello, non uso il metodo del modello (se faccio model.forward() cosa succede? niente funziona allo stesso modo!)\n\n\nn_total_steps = len(train_loader)\n\nfor epoch in range(num_epochs):                  # Loop sulle epochs\n   # for steps in range(n_total_steps):           # loops sui batches \n   for i, (images,labels) in enumerate (train_loader):   # loop sui batch     \n        # 100, 1, 28, 28  (batch, canali, x, y) forma del tensore images\n        # 100, 28x28=784  forma voluta dall'hidden layer\n        images = images.reshape(-1, 28*28).to(device)     #usando reshape con il -1\n        labels = labels.to(device)\n        \n        # forward pass\n        # print (images.is_cuda)        \n        outputs = model (images)        #  non chiama il metodo forward: perche'?\n        loss = criterion(outputs, labels)\n                 \n        # backward pass\n        optimizer.zero_grad()   # non voglio che vengano inseriti nel backward pass\n        loss.backward()          #  &lt;========  fa tutto lui, calcola chain rule\n        optimizer.step()         # aggiorna i pesi\n        \n        if (i+1) % 100 ==0:\n            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}')        \n\n\nepoch 1 / 2, step 100/600, loss= 0.3839\nepoch 1 / 2, step 200/600, loss= 0.2682\nepoch 1 / 2, step 300/600, loss= 0.1468\nepoch 1 / 2, step 400/600, loss= 0.1664\nepoch 1 / 2, step 500/600, loss= 0.0730\nepoch 1 / 2, step 600/600, loss= 0.1700\nepoch 2 / 2, step 100/600, loss= 0.0749\nepoch 2 / 2, step 200/600, loss= 0.2193\nepoch 2 / 2, step 300/600, loss= 0.1413\nepoch 2 / 2, step 400/600, loss= 0.0539\nepoch 2 / 2, step 500/600, loss= 0.0470\nepoch 2 / 2, step 600/600, loss= 0.0669\n\n\nTest Loop\nqui calcolo l’accuracy con i dati di test.\n\n\n  La funzione torch.max restituisce: valori e l’indice. Noi vogliamo l’indice che e’ la classe.\n  per calcolare il numero totale di immagini processate, conto il numero di righe in labels.\n  per ogni predizione corretta aggiungo 1 “sum()” e estraggo dal tensore con item() (non chiarissimo il sum).\n  nota la scrittura con l’  ==, quindi facciamo una specie di if “online”\n\n\nwith torch.no_grad():    \n    n_correct = 0         # numero di predizioni azzeccate\n    n_samples = 0         # ? \n    for images, labels in test_loader:\n        images = images.reshape(-1, 28*28).to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)   # qui il modello e' gia' trainato!\n        \n        _, predictions = torch.max(outputs,1) # prendo la classe che ha il valore massimo\n        n_samples += labels.shape[0]          # numero di samples nel batch corrente (nell'ultimo sono diversi spesso)\n        n_correct += (predictions == labels).sum().item()\n        \n    acc = 100.0  * n_correct / n_samples # accuratezza in percentuale\n    print(f'accuracy ={acc}')\n\n\naccuracy =97.07\n\n\nProve sul modello\nIn questa cella faccio le mie varianti in modo da poter capire meglio i vari passaggi.\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# device config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#device = torch.device('cpu')\n\n# Hyper parametri \ninput_size = 28*28    #  =784 sono le dimensioni delle immagini\nhidden_size  = 2000   #  scelto da me\nnum_classes = 10      #  devo classificare immagini di numeri\nnum_epochs = 1        #  quanti giri completi vengono fatti\nbatch_size = 100        #  questo no so come sia stato scelto\nlearning_rate = 0.001 #  piccolo\n\ntrain_dataset = torchvision.datasets.MNIST(root= './data/', train= True, \n                                           transform =transforms.ToTensor(),\n                                          download = True)\n\ntest_dataset = torchvision.datasets.MNIST(root= './data/', train= False, \n                                           transform =transforms.ToTensor(),\n                                          download = False) # ho gia' scaricato tutto con il train_datast\n\ntrain_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader (dataset=  test_dataset, batch_size = batch_size, shuffle=False)\n\n### nota che la dimensione dei sample e' la seguente\n# 100  = numero di immagini nel batch (se non metti batch_size, di default vale 1)\n#   1  = numero di canali solitamente i colori\n#  28  =  numero di ingressi sull'asse delle x\n#  28  = numero di ingressi sull'asse delle y\n\ndef myActiv(x):    # e' difficile costruire delle funzioni di attivazioni CUSTOM (vedi sopra)\n    #return 1. +x/10. + 0.5*(x/10.)**2+1./6.*(x/10.)**3\n    return  -3*x**2+4*x-1\n        \n\n############  MODELLO ####################\n# qui costruisco il modello: e' una classe\n\nclass NeuralNet(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(NeuralNet, self).__init__()\n        self.l1 = nn.Linear(input_size, hidden_size)  # L MAIUSCOLA\n        self.relu = nn.ReLU()\n        self.sigmoid= nn.Sigmoid()\n        self.softplus = nn.Softplus()\n        self.my = myActiv\n        self.l2 = nn.Linear(hidden_size, num_classes)\n       \n    def forward (self, x):\n        out = self.l1(x)      # sfrutto il metodo self.l1 a cui ho gia' dato dei parametri prima\n        out = self.relu(out)  # ReLU non aveva bisogno di parametri: posso prendere nn.ReLU ?\n        #out = self.sigmoid(out)\n        #out = self.softplus(out)\n        #out = self.my(out)\n        out = self.l2(out)\n        return out            # DEVE restituire qualcosa\n\n\n############### ISTANZIO MODELLO ########\nmodel = NeuralNet(input_size, hidden_size, num_classes).to(device)\n\n############### CRITERION E OPTIMIZER ###\ncriterion  = nn.CrossEntropyLoss()   # non ha bisogno di parametri\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)       # qui devo passare i parametri del modello!\n\n############### TRAINING LOOP ############\nn_total_steps = len(train_loader)\n\n\ntot =0 # PA\nfor epoch in range(num_epochs):                  # Loop sulle epoch  \n   for i, (images,labels) in enumerate (train_loader):   # loop sui batch, uso enumerate cosi' so in che batch sono     \n        # 100, 1, 28, 28  (batch, canali, x, y) forma del tensore images\n        # 100, 28x28=784  forma voluta dall'hidden layer\n        images = images.reshape(-1, 28*28).to(device)     #usando reshape con il -1\n        labels = labels.to(device)\n              \n        #outputs = model (images)        #  non chiama il metodo forward: perche' nn.Model ha il __call__!\n        outputs = model.forward(images)        #  non chiama il metodo forward: perche' nn.Model ha il __call__!\n        \n        loss = criterion(outputs, labels)\n\n        tot = tot+1 # PA per fare delle modifiche sul Learning Rate\n        if (tot%200 == 0):\n            learning_rate = learning_rate *0.8\n            print(f'Learning rate {learning_rate}')\n            optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n        \n        \n        # backward pass\n        optimizer.zero_grad()   # non voglio che vengano inseriti nel backward pass\n        loss.backward()          #  &lt;========  fa tutto lui, calcola chain rule\n        optimizer.step()         # aggiorna i pesi\n        \n        if (i+1) % 100 ==0:\n            print(f'Epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}')        \n\n            \n############ TEST LOOP #################\nwith torch.no_grad():    \n    n_correct = 0         # numero di predizioni azzeccate\n    n_samples = 0         # ? \n    for images, labels in test_loader:\n        images = images.reshape(-1, 28*28).to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)   # qui il modello e' gia' trainato!\n        \n        _, predictions = torch.max(outputs,1) # prendo la classe che ha il valore massimo\n        n_samples += labels.shape[0]          # numero di samples nel batch corrente (nell'ultimo sono diversi spesso)\n        n_correct += (predictions == labels).sum().item()\n        \n    acc = 100.0  * n_correct / n_samples # accuratezza in percentuale\n    print(f'accuracy ={acc}')            \n\n\nEpoch 1 / 1, step 100/600, loss= 0.2884\nLearning rate 0.0008\nEpoch 1 / 1, step 200/600, loss= 0.1714\nEpoch 1 / 1, step 300/600, loss= 0.1254\nLearning rate 0.00064\nEpoch 1 / 1, step 400/600, loss= 0.1586\nEpoch 1 / 1, step 500/600, loss= 0.1043\nLearning rate 0.0005120000000000001\nEpoch 1 / 1, step 600/600, loss= 0.0829\naccuracy =97.06\n\n\nProva senza funzioni di attivazione: e’ un modello lineare!\nQuesti sono i risultati ottenuti quando elimino la activation function e lascio solo il\nmodello lineare sottostante, dove c’e’ il primo passo la fully connected tra le immagini e lo strato hidden\ne dallo strato hidden all’output. I risultati sono in funzione di vari parametri variati.\nCon questo dataset i risultati non sono male, si hanno delle  buone accuracy a condizione che \nil numero di neuroni sia paragonabile (anche 4 e’ sufficiente!) al numero di possibili output.\n\nNota pero’ che comunque ho la softmax finale per la cross entropy come loss.\n\n\n  senza attivazione: accuracy = 91.28    hidden_size  =2000 epoch =1\n  senza attivazione: accuracy = 90.69    hidden_size  =10   epoch =1\n  senza attivazione: accuracy = 92.54    hidden_size  =10   epoch =4\n  senza attivazione: accuracy = 38.22    hidden_size  =1    epoch =4\n  senza attivazione: accuracy = 41.95    hidden_size  =1    epoch =14\n  senza attivazione: accuracy = 67.53    hidden_size  =2    epoch =4\n  senza attivazione: accuracy = 86.04    hidden_size  =4    epoch =4\n\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# device config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#device = torch.device('cpu')\n\n# Hyper parametri \ninput_size = 28*28    #  =784 sono le dimensioni delle immagini\nhidden_size  = 4      #  scelto da me\nnum_classes = 10      #  devo classificare immagini di numeri\nnum_epochs = 4        #  quanti giri completi vengono fatti\nbatch_size = 100        #  questo no so come sia stato scelto\nlearning_rate = 0.001 #  piccolo\n\ntrain_dataset = torchvision.datasets.MNIST(root= './data/', train= True, \n                                           transform =transforms.ToTensor(),\n                                          download = True)\n\ntest_dataset = torchvision.datasets.MNIST(root= './data/', train= False, \n                                           transform =transforms.ToTensor(),\n                                          download = False) # ho gia' scaricato tutto con il train_datast\n\ntrain_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader (dataset=  test_dataset, batch_size = batch_size, shuffle=False)\n\n### nota che la dimensione dei sample e' la seguente\n# 100  = numero di immagini nel batch (se non metti batch_size, di default vale 1)\n#   1  = numero di canali solitamente i colori\n#  28  =  numero di ingressi sull'asse delle x\n#  28  = numero di ingressi sull'asse delle y\n\ndef myActiv(x):    # e' difficile costruire delle funzioni di attivazioni CUSTOM (vedi sopra)\n    #return 1. +x/10. + 0.5*(x/10.)**2+1./6.*(x/10.)**3\n    return  -3*x**2+4*x-1\n        \n\n############  MODELLO ####################\n# qui costruisco il modello: e' una classe\n\nclass NeuralNet(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(NeuralNet, self).__init__()\n        self.l1 = nn.Linear(input_size, hidden_size)  # L MAIUSCOLA\n        self.l2 = nn.Linear(hidden_size, num_classes)\n       \n    def forward (self, x):\n        out = self.l1(x)      # sfrutto il metodo self.l1 a cui ho gia' dato dei parametri prima\n        #out = self.relu(out)  # ReLU non aveva bisogno di parametri: posso prendere nn.ReLU ?\n        out = self.l2(out)\n        return out            # DEVE restituire qualcosa\n\n\n############### ISTANZIO MODELLO ########\nmodel = NeuralNet(input_size, hidden_size, num_classes).to(device)\n\n############### CRITERION E OPTIMIZER ###\ncriterion  = nn.CrossEntropyLoss()   # non ha bisogno di parametri\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)       # qui devo passare i parametri del modello!\n\n############### TRAINING LOOP ############\nn_total_steps = len(train_loader)\n\nfor epoch in range(num_epochs):                  # Loop sulle epoch  \n   for i, (images,labels) in enumerate (train_loader):   # loop sui batch, uso enumerate cosi' so in che batch sono     \n        # 100, 1, 28, 28  (batch, canali, x, y) forma del tensore images\n        # 100, 28x28=784  forma voluta dall'hidden layer\n        images = images.reshape(-1, 28*28).to(device)     #usando reshape con il -1\n        labels = labels.to(device)\n              \n        outputs = model (images)        #  non chiama il metodo forward: perche'?\n        loss = criterion(outputs, labels)\n                 \n        # backward pass\n        optimizer.zero_grad()   # non voglio che vengano inseriti nel backward pass\n        loss.backward()          #  &lt;========  fa tutto lui, calcola chain rule\n        optimizer.step()         # aggiorna i pesi\n        \n        if (i+1) % 100 ==0:\n            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}')        \n\n            \n############ TEST LOOP #################\nwith torch.no_grad():    \n    n_correct = 0         # numero di predizioni azzeccate\n    n_samples = 0         # ? \n    for images, labels in test_loader:\n        images = images.reshape(-1, 28*28).to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)   # qui il modello e' gia' trainato!\n        \n        _, predictions = torch.max(outputs,1) # prendo la classe che ha il valore massimo\n        n_samples += labels.shape[0]          # numero di samples nel batch corrente (nell'ultimo sono diversi spesso)\n        n_correct += (predictions == labels).sum().item()\n        \n    acc = 100.0  * n_correct / n_samples # accuratezza in percentuale\n    print(f'accuracy ={acc}')            \n\n\nepoch 1 / 4, step 100/600, loss= 1.4573\nepoch 1 / 4, step 200/600, loss= 1.0294\nepoch 1 / 4, step 300/600, loss= 0.8547\nepoch 1 / 4, step 400/600, loss= 0.6365\nepoch 1 / 4, step 500/600, loss= 0.4938\nepoch 1 / 4, step 600/600, loss= 0.6704\nepoch 2 / 4, step 100/600, loss= 0.5902\nepoch 2 / 4, step 200/600, loss= 0.4542\nepoch 2 / 4, step 300/600, loss= 0.5579\nepoch 2 / 4, step 400/600, loss= 0.7067\nepoch 2 / 4, step 500/600, loss= 0.4833\nepoch 2 / 4, step 600/600, loss= 0.6566\nepoch 3 / 4, step 100/600, loss= 0.6494\nepoch 3 / 4, step 200/600, loss= 0.4046\nepoch 3 / 4, step 300/600, loss= 0.7297\nepoch 3 / 4, step 400/600, loss= 0.3742\nepoch 3 / 4, step 500/600, loss= 0.4305\nepoch 3 / 4, step 600/600, loss= 0.4805\nepoch 4 / 4, step 100/600, loss= 0.6506\nepoch 4 / 4, step 200/600, loss= 0.3813\nepoch 4 / 4, step 300/600, loss= 0.3637\nepoch 4 / 4, step 400/600, loss= 0.6228\nepoch 4 / 4, step 500/600, loss= 0.5557\nepoch 4 / 4, step 600/600, loss= 0.5079\naccuracy =86.55"
					}
					
				
			
		
			
				
					,
					
					"pytorch-3": {
						"id": "pytorch-3",
						"title": "Pytorch 3 Loss Activation DataLoader",
						"categories": "italiano",
						"url": " /Pytorch-3",
						"content": "tocIn this post\n  \n  \n\n  LOSS e OPTIMIZER di PyTorch\n  Modelli di PyTorch\n  Dataset e DataLoader    \n      Dataset\n      DataLoader\n    \n  \n  Dataset Transforms\n  Softmax e Cross-Entropy Loss    \n      Cross-Entropy Loss\n      CrossEntropyLoss\n      Esempio Applicazione di Softmax\n    \n  \n  Activation Function\n\n\n  \n\n\nIndice Globale degli argomenti tra i vari post:\n\n 1.1.                                    Indice degli argomenti.\n 1.1.                                      Introduzione e fonti.\n 1.1.                                  Lingo - Gergo utilizzato.\n 1.2.                                        Tensori in Pytorch.\n 2.1.                                      Chainrule e Autograd.\n 2.2.                                           Backpropagation.\n 3.1.                                          Loss e optimizer.\n 3.2.                                        Modelli di Pytorch.\n 3.3.                                      Dataset e Dataloader.\n 3.4.                                       Dataset Transforms.\n 3.5.                              Softmax e Cross-Entropy Loss.\n 3.6.                                       Activation Function.\n 4.1.                                Feed Forward Neural Network.\n 5.1.                               Convolutional Neural Network.\n 5.2.                                          Transfer Learning.\n 5.3.                                                Tensorboard.\n 6.1.                              I/O Saving and Loading Models.\n 7.1.                                  Recurrent Neural Networks.\n 7.2.                                            RNN, GRU e LSTM.\n 8.1.                                          Pytorch Lightning.\n 8.2.                                               LR Scheduler.\n 9.1.                                                Autoencoder.\n\nLOSS e OPTIMIZER di PyTorch\nQqui vediamo qualche esempio di:\n\n  LOSS function (ovvero il criterion)\n  Optimizer, ovvero le metodologie che vengono usate per fare l’update dei pesi per migliorare la loss (dato che devo minimizzare la loss sto facendo una ottimizzazione, o minimizzazione nel dettaglio!)\n\n\nQuesto codice e’ molto simile al precedente. La differenza e’ nell’optimizer, ovvero che strategia viene portata avanti per minimizzare le LOSS. In pratica ci sono varie funzioni che prendono come argomento il gradiente rispetto ad un tensore e minimizzano la funzione.\n\nPassi:\n\n  si disegna il modello\n  si costruiscono la loss e l’optimizer\n  si fa un loop di training\n\n\nConsideriamo un grafo computazionale ancora del tipo linear regression.\n\noptimizer.step() e’ il metodo che ci fa muovere tra i parametri secondo l’algoritmo di ottimizzazione.\n\nimport torch\nimport torch.nn as nn\n\n# Linear regression\n# f = w * x \n\n# here : f = 2 * x\n\n# 0) Training samples\nX = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\nY = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n\nw = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)   # weights\n\ndef forward(x):\n    return w * x\n\nprint(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n\n# 2) Define loss and optimizer    \nlearning_rate = 0.01               # questo viene passato come parmetro all'optimizer\nn_iters = 100\n\n\nloss = nn.MSELoss()                # e' una funzione predefinita di Torch  \n\noptimizer = torch.optim.SGD([w], lr=learning_rate)  # Optimizer ha come parameri di imput [w] (pesi) e lr=learning_rate\n\nfor epoch in range(n_iters):       # TRAINING LOOP\n    y_predicted = forward(X)       # FORWARD \n    l = loss(Y, y_predicted)       # LOSS     \n    l.backward()                   # Backward (e' un metodo sul tensore dato dalla loss) \n\n    optimizer.step()               # Optimizer, uso il metodo .step() \n\n    optimizer.zero_grad()          # azzera i gradienti usati per l'ottimizzatore\n\n    if epoch % 10 == 0:\n        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\n\nprint(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n\n\n\nPrediction before training: f(5) = 0.000\nepoch  1 : w =  tensor(0.3000, requires_grad=True)  loss =  tensor(30., grad_fn=&lt;MseLossBackward&gt;)\nepoch  11 : w =  tensor(1.6653, requires_grad=True)  loss =  tensor(1.1628, grad_fn=&lt;MseLossBackward&gt;)\nepoch  21 : w =  tensor(1.9341, requires_grad=True)  loss =  tensor(0.0451, grad_fn=&lt;MseLossBackward&gt;)\nepoch  31 : w =  tensor(1.9870, requires_grad=True)  loss =  tensor(0.0017, grad_fn=&lt;MseLossBackward&gt;)\nepoch  41 : w =  tensor(1.9974, requires_grad=True)  loss =  tensor(6.7705e-05, grad_fn=&lt;MseLossBackward&gt;)\nepoch  51 : w =  tensor(1.9995, requires_grad=True)  loss =  tensor(2.6244e-06, grad_fn=&lt;MseLossBackward&gt;)\nepoch  61 : w =  tensor(1.9999, requires_grad=True)  loss =  tensor(1.0176e-07, grad_fn=&lt;MseLossBackward&gt;)\nepoch  71 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(3.9742e-09, grad_fn=&lt;MseLossBackward&gt;)\nepoch  81 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(1.4670e-10, grad_fn=&lt;MseLossBackward&gt;)\nepoch  91 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(5.0768e-12, grad_fn=&lt;MseLossBackward&gt;)\nPrediction after training: f(5) = 10.000\n\n\nModelli di PyTorch\nqui vediamo come usare i modelli preinstallati di pytorch.\n\n\n  model = nn.Linear(input_size, output_size)  modello lineare, ha 2 argomenti: i parametri in ingresso e in uscita.\n  X = torch.tensor([[1], [2], [3], [4]]) occhio al formato [1] = prima riga, [2] =seconda riga, [3] = terza riga, [4]= quarta riga. X.shape = 4 righe, 1 colonna.\n  ATTENTO: optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) all’ottimizzatore da’ in pasto un parametro, il learning rate.\n\n\nimport torch\nimport torch.nn as nn\n\n# Linear regression\n# f = w * x \n\n# here : f = 2 * x\n\n# 0) Training samples, watch the shape!\nX = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\nY = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n\nn_samples, n_features = X.shape                            # 4 righe, 1 colonna. 4 osservazioni 1 sola FEATURE (predictor)\nprint(f'#samples: {n_samples}, #features: {n_features}')\nprint(X.shape)\n\n\n#samples: 4, #features: 1\ntorch.Size([4, 1])\n\n\n# 0) create a test sample\nX_test = torch.tensor([5], dtype=torch.float32)        # costruisco un nuovo punto per testare\n\n# 1) Design Model, the model has to implement the forward pass!\n# Here we can use a built-in model from PyTorch\ninput_size = n_features                                \noutput_size = n_features\n\n# we can call this model with samples X\nmodel = nn.Linear(input_size, output_size)             # modello di PyTorch\n\n'''\nclass LinearRegression(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(LinearRegression, self).__init__()\n        # define diferent layers\n        self.lin = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x):\n        return self.lin(x)\n\nmodel = LinearRegression(input_size, output_size)\n'''\n\nprint(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n\n\nlearning_rate = 0.01                       # learning rate\nn_iters = 100                              # numero iterazioni  \n\nloss = nn.MSELoss()                        # funzione loss  \noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n# 3) Training loop\nfor epoch in range(n_iters):\n    # predict = forward pass with our model\n    y_predicted = model(X)\n\n    # loss\n    l = loss(Y, y_predicted)\n\n    # calculate gradients = backward pass\n    l.backward()\n\n    # update weights\n    optimizer.step()\n\n    # zero the gradients after updating\n    optimizer.zero_grad()\n\n    if epoch % 10 == 0:\n        [w, b] = model.parameters() # unpack parameters\n        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n\nprint(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n\n\nDataset e DataLoader\nQui viene definito il dataloader. Supponi di avere un classificatore di immagini. \nIn ingresso prende una immagine e  in uscita mi dice a che classe appartiene (per esempio gatto-cane).\n Non posso fare il training su una sola immagine, altrimenti farei un overfit. Quello che normalmente \nsi fa e’: passare dei batch (infornate di immagini), fare il training e poi fare il trainig su nuovi batch. \nIn alcuni casi in modo incrementale, ovvero batch successivi includono quelli precedenti.\n\nSecondo Python Engineer e’ anche vero il contrario. Se passp tutti i dati di training, allora fare delle gradient \ncalculations (backpropagation) diventa computazionalemtne oneroso.\n\nOsservazione di natura notazionale, di solito Loeber nelle istanze che crea, usa il medesimo \nnome della funzione/classe di Torch, ma con tutte le lettere minuscole. Per esmpio, in PyTorch \nesiste Dataset e lui chiama la sua istanza: dataset (minuscolo). Mi pare un’ottima \nconvenzione che aiuta a ricordare i nomi delle funzioni, metodi e classi.\n\n\n  si fa un loop (esterno) su tutte le epoch\n  per ogni epoch si fa un loop (interno) su tutti i batch\n  l’ottimizzazione viene fatta solo sul batch\n\n\nLingo:\n\n  epoch un passo forward e un backward di TUTTI i campioni del training.\n  batch un sottoinsieme di elementi del training dataset\n  batch_size numero di campioni di training in un forward/backward pass.\n  numero di iterazioni numero di passi, ogni passo(forward/backward) usa “batch_size” campioni\n\n\nPer esempio:\n\n  100 campioni\n  batch_size=20\n  5 iterazioni  formano  1 epoch\n\n\nI DataLoader sono CLASSI, fanno la computazione del batch (la gestiscono).\nVengono ereditati da “torch.utils.data import DataLoader.\n\n\n  implementano un Dataset custom (voluto dall’utente)\n  inherit Dataset\n  implement __init__, __getitem__, e __len__\n\n\nimport torch\nimport torchvision  \nfrom   torch.utils.data import Dataset, DataLoader \n\nimport numpy as np\nimport math\n\n\nclass WineDataset(Dataset):           # Eredito dalla classe \"Dataset\" di torch.utils.data\n\n    def __init__(self):               # metodo __init__, inizializza, leggi ecc \n        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n        self.n_samples = xy.shape[0]      # definisce attributo n_samples = numero di righe\n\n        # Costruisci due attributi: sono i dati di training e le labels (come tensori) \n        self.x_data = torch.from_numpy(xy[:, 1:])  # size [n_samples, n_features]\n        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1] (la colonna zero sono gli obiettivi)\n\n    # support indexing such that dataset[i] can be used to get i-th sample\n    def __getitem__(self, index):                     # questo mi fa scegliere i pezzi del dataset\n        return self.x_data[index], self.y_data[index]\n\n    # chiamando len(dataset) si ottiene la size \n    def __len__(self):\n        return self.n_samples\n    \ndataset = WineDataset()  # carico il dataset\n#first_data = dataset[0]\n#features, labels = first_data\n\n\nIn questo dataset ci sono 3 categorie di  vino e sono la prima colonna del dataset. Tutte le altre colonne sono le features. Quindi nella classe sopra ho diviso mettendo [0] per le label.\nA questo punto l’oggetto dataset contiene varie proprieta’.\n\nOra costruisco un dataloader, prendendo la classe che esiste gia’ in Torch. \nDato che ho gia’ importato l’oggetto DataLoader da torch.utils.data, basta che gli passo\ni parametri corretti.\n\nDataset\nIn torchvision ci sono gia’ molti dataset disponibili che consentono di fare molti esperiemnti.\nLe classi Dataset e Dataloader invece sono in torch.utils.data\n\n\n  un Dataset e’ subscriptable (ovvero se si chiama mioDataset e faccio mioDataset[1], ottengo l’oggetto al secondo posto del dataset)\n  nel dataset (solitamente) ci sono sia i dati che le label\n  non riesco a trasformare un dataset in una funzione iteratrice\n\n\nDataLoader\n\n\n  un  DataLoader non e’ subscriptable, ma posso trasformarlo in un iteratore tramite iter e accedere quindi ai pezzi uno per volta (saranno i batch)\n  uso la funzione iter() per trasformare il dataloader in una funzione iteratrice (da mettere nei loop) (ho creato una nuova funzione che e’ l’iteratore del dataloader)\n  a questo punto posso prendere i vari pezzi\n  Attenzione se faccio data=dataiter.next() ci possono essere dei problemi e il sistema puo’ non avere abbastanza memoria, per risolvere il problema si deve mettere:\nnum_workers= 0  (e non 2 come nell’esempio).\nhttps://stackoverflow.com/questions/60101168/pytorch-runtimeerror-dataloader-worker-pids-15332-exited-unexpectedly\n\n\nArgomenti di un Dataloader:\n\n  dataset= mio_dataset()  mio_dataset e’ un oggetto ereditato da dataset (usa dataset come nome standard, in modo da ricordare)\n  batch_size = 4             (oppure crea una variabile batch_size)\n  shuffle=True               (fa shuffling, non chiaro in quali circostanze usare, la logica vuole che quando si costruiscono i train e validation sets si facciano dei sampling random. Per questo si fa lo shuffling all’interno del dataset\n  num_workers                (occhio che se metto 4 come nel tutorial mi da errore: devo mettere 0)\n\n\n\nbatch_size = 4\nnum_workers = 0\n\ndataloader = DataLoader(dataset=dataset, batch_size = batch_size, shuffle = True, num_workers = num_workers)\ndataiter = iter(dataloader)  # trasformato in una funzione iteratrice\ndata = dataiter.next()        # prendo il prossimo oggetto (il primo)\n#data = next(dataiter)\n#features, labels = data\n#print(features, labels)\n\n\nA questo punto fa un training loop finto per provare a vedere come funge.\n\n\n  Attento in enumerate non mette la funzione iteratrice ma il dataloader.\n  ho provato a fare iterare su data ma da’ errore: too many values to unpack (expected 2)\n  occhio la cella sotto funge anche con dataiter solo se prima faccio girare la cella sopra.\n\n\n#for i, j in enumerate(dataloader):\n#    print(i,j)\ndataloader\n\n\n&lt;torch.utils.data.dataloader.DataLoader at 0x216799d3670&gt;\n\n\n#for i, j in enumerate(dataset):\n#    print(i,j)    \nid = iter(dataset)\nid.next()\n\n\n---------------------------------------------------------------------------\n\nAttributeError                            Traceback (most recent call last)\n\n&lt;ipython-input-33-4dc6e5e585ab&gt; in &lt;module&gt;\n      2 #    print(i,j)\n      3 id = iter(dataset)\n----&gt; 4 id.next()\n\n\nAttributeError: 'iterator' object has no attribute 'next'\n\n\nnum_epochs = 2\ntotal_samples = len(dataset)\nn_iterations = math.ceil(total_samples/batch_size) # ceil altrimenti arrotonda per difetto\n#n_iterations \n\nfor epoch in range(num_epochs):   # giro tra le epoche\n    for i, (inputs, labels) in enumerate(dataloader):    # qui ha passato il dataloader\n        if (i+1)%5 == 0:\n            #print( f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}' ) \n            pass  # se non voglio stampare altrimenti decommenta sopra\n        \n# Idea mia, e se invece di usare un enumerate usassi data (che e' una funzione iteratrice?)\n\n#j=0\n#for epoch in range(num_epochs):   # giro tra le epoche\n#    for inputs, labels in dataiter:   # qui ha passato il data (iteratrice)\n#        j=j+1\n#        print(j)\n#        if (j+1)%5 == 0:\n#            print( f'epoch {epoch+1}/{num_epochs}, step {j+1}/{n_iterations}, inputs {inputs.shape}' )    \n\n# dataset pre-installati:\n\n#torchvision.datasets.MNIST()  # occhio che e'  M N I S T\n# fashion-mnist\n# cifar\n# coco\n\n\nDataset Transforms\n\nIn pratica si deve passare un argomento transform alla classe associata al dataset.\n\nDocumentazione sulle possibili trasformazioni:\nhttps://pytorch.org/docs/stable/torchvision/transforms.html\n\nriassunto delle trasformazioni (UTILE, lo fa Python engineer):\n\nQuando carichi un dataset da torchvision puoi usare l’argomento: download=True!\n\nTraformazioni sulle Immagini:\n\n  CenterCrop, Grayscale, Pad, RandomAffine, RandomCrop, RandomHorizontalFlip, RandomRotation, Resize, Scale\n\n\nSui Tensori:\n\n  LinearTransformation, Normalize, RandomErasing\n\n\nConversion:\n-ToPILImage: da tensore o ndarray  (PILI = Pillow image)\n-ToTensor: da numpy.ndarray o PILImage\n\nGeneric:\n\n  lambda\n\n\nCustom:\n\n  Si puo’ scrivere una propria classe\n\n\nTrasformazioni composte multiple:\n\n  \n    composed = transforms.Compose( [Rescale(256] , RandomCrop(224)] )\n  \n  torchvision.transforms.ReScale(256)     # occhio che qui ha messo S maiuscola\n  torchvision.transforms.ToTensor()\n\n\nTrasformazioni \nOra prendo la classe usata sopra per i dataset e aggiungo un argomento: transform,\nche specifica quali trasformazioni posso applicare!\n\n\n  va passato qualcosa al momento della creazione della classe dataset\n  viene fatto un esempio con una trasformazione custom, usando una classe\n  ho un problema, mi dice che, al contrario del codice del corso, WineDataset non ha l’attributo transform. in particolare succede se faccio: \ndataset = WineDataset(transform =ToTensor())\ndataset[0] &lt;- qui e’ il problema\n\n\nimport torch\nimport torchvision\n\nfrom torch.utils.data import Dataset\nimport numpy as np\n\n#dataset = torchvision.datasets.MNIST(root='./data', download= True, transform=torchvision.transforms.ToTensor())\n\nclass WineDataset(Dataset):\n    def __init__(self,transform=None):   # posso anche non passare transform, di default = None\n        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n        self.n_samples = xy.shape[0] \n\n        self.x = xy[:, 1:]\n        self.y = xy[:,[0]]  # NOTA che scrivo [0]\n        \n        self.transform = transform # quando chiamo la trasformazione dall'istanza.\n    \n    def __getitem__(self, index):            # questo mi prende lo specifico dato alla posizione index\n        #return self.x[index], self.y[index]  # non ritorna l'oggetto, ma voglio trasformare!\n        sample =  self.x[index], self.y[index]  # costruisco l'oggetto\n        if self.transform:                      # se e' presente\n             sample = self.tranform(sample)\n                \n        return sample                           # lo metto qui in modo che ritorni qualcosa comunque  \n\n    def __len__(self):\n        return n_samples\n\n    \n############## trasformazione custom ###############\n############## abbiamo bisogno di un metodo chiamato __call__\nclass ToTensor:\n    def __call__(self, sample):   ##############  FONDAMENTALE ########## \n        inputs, targets = sample\n        return torch.from_numpy(inputs), torch.from_numpy(targets)\n    \n    \n\n#dataset = WineDataset(transform =None)\n#dataset = WineDataset(transform=ToTensor)\n#dataset = WineDataset(transform = ToTensor())\n#dataset[0]\n\n#first_data = dataset[0]        ################### NON FUNGE #################\n#features, labels  = first_data\n#print(type(features), type(labels))\n\n\n##  posso fare trasoformazioni multiple:\n\nclass MulTransform:\n    def __init__(self, factor):\n        self.factor = factor\n        \n    def __call__(self, sample):\n        inputs, targets = sample\n        inputs *= self.factor\n        return inputs, target\n\ncomposed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n\ndataset = WineDataset (transform = composed)\n#first_data = dataset[0]     ###################### NON FUNGE #####################\n\n\nSoftmax e Cross-Entropy Loss\nQueste sono tra le funzioni piu’ comuni per “schiacciare i risultati” (un po’ come la logit(p) =ln(p/1-p) =ln(odds) )\n\nSoftmax:\n\nI risultati vanno quindi tra 0 e 1.\nA denominatore sembra una funzione di ripartizione (ma i valori non sono negativi).\n\nChiaramente $ \\sum S(y_i) =1$ quindi le $S(y_i)$ possono essere interpretate come delle probabilita'. \nPer questo vengono applicate come layer in uscita dopo l’ultimo strato in modo che ad ognuna delle classi sia associata una probabilita’.\n\n\n\n  \n    Se fossero solo 2 le classi come nella regressione logistica si userebbe la sigmoid function (che e’ la versione non generalizzata ma con solo 2 classi in pratica):\n\n  \n  \n    Come Loss si potrebbe usare la nn.BCELoss()  (binary cross entropy loss). In questo caso pero’ BISOGNA implementare la sigmoide dopo l’ultimo strato.\n  \n  \n    La cross entropy di Pytorch implementa gia’ la softmax dall’ultimo strato, per questo bisogna evitare di applicare la softmax un’altra volta!\n  \n\n\nimport numpy as np\nimport torch.nn as nn\nimport torch\nimport matplotlib.pyplot as plt\n\n\ndef softmax(x):                                       # costruisco una softmax di un ARRAY x\n    return np.exp(x)/ np.sum(  np.exp(x) , axis = 0)  # ho tutti gli elementi\n\ndef sigmoid(x):\n    return 1./(1.+np.exp(-x))\n\nx = np.array([2.,1.,0.1])\n\nprint(softmax(x))\n\n########## qui uso una softmax gia' presente in Torch\nx  = torch.tensor([2.,1.0,0.1])\noutputs = torch.softmax(x, dim=0)  # devo specificare la dimensione dove giro\nprint(outputs)\n\nx= [i-500 for i in range(1000)]\nx = np.array(x)\nx = x *0.01\nexp = np.exp(x)\nx  =torch.from_numpy(x)\ny = torch.softmax(x, dim=0 )\n#y = sigmoid(x)\nplt.plot(x,y)\nplt.plot(x, sigmoid(x))\n#x\n\n\n[0.65900114 0.24243297 0.09856589]\ntensor([0.6590, 0.2424, 0.0986])\n\n\n\n\n\n[&lt;matplotlib.lines.Line2D at 0x2165c85f910&gt;]\n\n\n\n\nCross-Entropy Loss\nLa Cross-Entropy Loss e’ una funzione di Loss, che  viene spesso combinata alla soft-max.\n\nCome la maggior parte delle funzioni di Loss trasforma i valori ottenuti (output) e le label in un\nsingolo valore. Dato ci sono 2 vettori N-dimensionali:\n\n  il vettore calcolato (a partire dall’input) $\\hat{Y}= [0.7, 0.2, 0.1]$ Gli ingressi devono poter essere interpretabili come probabilita’, ergo devono essere nel range (0,1]. Questo e’ il motivo per cui gli si danno in pasto dei valori che sono gia’ stati convertiti con delle Softmax.\n  e quello osservato $Y= [1,0,0]$ (One-Hot Encoded labels) dubbio, ma cosi’ facendo non e’ manco piu’ una somma! tutte le $Y_i$ vengono azzerate tranne 1. E’ vero solo se faccio un oggetto per volta. Se faccio un batch di oggetti e quindi sommo i risultati (per ottenere la empirical loss), avro’ piu’ di un valore diverso da 0.\n\n\nla Cross Entropy Loss viene definita come:\n\nNota che la Cross-Entropy loss restituisce valori [0,1].\n\nMigliore la predizione, piu’ bassa e’ la Loss. \n\nDomanda: come ottengo questa formula a partiere dall’entropia di Shannon?\n\nQuindi e’ un’entropia di Shannon ma in cui da un lato inserisco i valori osservati e quelli ottenuti. Chiaramente serve che le Y e $\\hat{Y}$ siano in un range [0,1] se voglio ottenere dei risultati simili all’entropia di Shannon.\n\nAttenzione  nel codice del video, Loeber non segue la definizione in quanto non divide per il numero di oggetti, non so perche’. Quindi i risultati che ottiene non sono nel range [0,1]\n\ndef cross_entropy(actual, predicted):       # sono 2 array N-dim\n    loss = -(np.sum( actual * np.log(predicted) ))  /len(actual)\n    return loss\n\ny = np.array([1,0,0])\ny_pred_good = np.array([0.7,0.1,0.1])\ny_pred_bad  = np.array([0.1,0.4,0.5])\n\nl1  = cross_entropy(y, y_pred_good)\nl2  = cross_entropy(y, y_pred_bad)\n\nprint(f'Loss1 : {l1:.4f}')\nprint(f'Loss2 : {l2:.4f}')\n\n      \n\n\nLoss1 : 0.1189\nLoss2 : 0.7675\n\n\nCrossEntropyLoss\nla funzione nn.CrossEntropyLoss usa gia’:\nnn.LogSoftMax -&gt; nn.NLLLos  (negative log likelihood loss)\n\nPer questo NON le (a nn.LogSoftMax) si devono dare in pasto i vettori codificati tramite:\n\n\n  One Hot encoding (NO)\n  Softmax (NO)\n\n\nLa funzione di Loss in PyTorch consente di avere samples multipli. \nOvvero si ha una loss per il primo sample, una per il secondo sample, ecc in pratica viene un vettore di loss.\n\n######## QUI usiamo la cross entropy embedded in Torch\n\nY = torch.tensor([0])  # questa e' la classe corretta e' UN Solo valore\n\n#qui sotto la dimensione e' n_samples x n_classes =  1 x 3  (in questo caso)\n## e' un ARRAY di ARRAY\nY_pred_good = torch.tensor( [  [ 2.0, 1.0, 0.1] ] )  # e' buona perche' la classe 0 ha il valore maggiore\n\nY_pred_bad = torch.tensor( [  [ 0.5, 2.0, 0.3] ] )   # e' cattiva perche' il valore maggiore e' per la classe 1\n\nloss = nn.CrossEntropyLoss()  # istanzio la funzione\n\nprint(loss (Y_pred_good, Y ).item())\nprint(loss (Y_pred_bad , Y ).item())\n\n### per ottenere le predizioni:\n\n_, pred1 = torch.max (Y_pred_good, 1)  # il secondo ingresso e' la dimensione dove gira?\n_, pred2 = torch.max (Y_pred_bad, 1)\n\nprint(pred1)\nprint(pred2)\n\n############## sample multipli ###########################\n\nY = torch.tensor([2,0,1])   # vettore 3 (n_samples)\n\n                            # vettore n_labels x n_samples\nY_pred_good = torch.tensor( [  [ 0.1, 1.0, 2.1] ,\n                               [ 2.0, 1.0, 0.1] ,\n                               [ 0.1, 3.0, 0.1] ] )\n\nY_pred_bad = torch.tensor( [  [ 2.1, 1.0, 0.1] ,\n                               [ 0.1, 1.0, 2.1] ,\n                               [ 0.1, 3.0, 0.1] ] ) \n\nprint(loss (Y_pred_good, Y ).item())\nprint(loss (Y_pred_bad , Y ).item())\n\n_, pred1 = torch.max (Y_pred_good, 1)  # il secondo ingresso e' la dimensione dove gira?\n_, pred2 = torch.max (Y_pred_bad, 1)\nprint(pred1)\nprint(pred2)\n\n\n\n0.4170299470424652\n1.840616226196289\ntensor([0])\ntensor([1])\n0.3018244206905365\n1.6241613626480103\ntensor([2, 0, 1])\ntensor([0, 2, 1])\n\n\nEsempio Applicazione di Softmax\n\n  un solo hidden layer con hidden_size nodi\n  input_size e’ per esempio il num di punti dell’immagine\n  num_classes e’ il numero di possibili classi in uscita (output_size)\n\n\nimport torch \nimport numpy as np\nimport torch.nn as nn\n\nclass NeuralNet2(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(NeuralNet2, self).__init__()   # questo serve per ereditare il costruttore?\n        self.linear1 = nn.Linear(input_size, hidden_size)        #   \n        self.relu = nn.ReLU()                                    # metodo nuovo \n        self.linear2 = nn.Linear(hidden_size, num_classes)       # altro metodo che prende 2 arg   \n\n    def forward(self, x):            # devo passare l'input: x\n        out = self.linear1(x)\n        out = self.relu(out)\n        out = self.linear2(out)\n        # NON USARE softmax, e' gia' messa nella Loss che usiamo popi\n        return(out)\n       \nmodel = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)  # istanzio il modello\ncriterion = nn.CrossEntropyLoss()                                   # Applica gia' la Softmax di default.\n\n        \n################# Classificazione binaria ############################\n# num_classes = 1   # il risultato vale un numero da [0,1]\n# model = NeuralNet1(input_size = 28*28, hidden_size = 5)\n# critetrion = nn.BCELoss()\n\n\nActivation Function\n[Video] (https://www.youtube.com/watch?v=3t9lZM7SS7k&amp;list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&amp;index=12&amp;ab_channel=PythonEngineer)\ndi riferimento  di Python Engineer\n\n\n  ReLU  rectified linear unit _/\n\n\nLe funzioni di attivazione vengono applicate dopo avere fatto il prodotto scalare e si applicano a tutti i neuroni/nodi (hidden).\n\nNel video  dice che se non mettiamo delle funzioni di attivazione si ha un gigantesco livello lineare (il disegno e’ in un certo senso sbagliato, quello al minuto 1:15). All’inizio pensavo sbagliasse, ma ripensandoci ha completamente ragione. Per esempio supponiamo che ci siano solo due variabili di ingresso (x,y) e 2 nodi nel primo hidden layer:\n\n  $a_1x+b_1y$\n  $c_1x+d_1y$\n\n\n(evito i bias che tanto sono costanti). A questo punto mettiamo un secondo hidden layer con 2 nodi e ottengo:\n\n  $a_2(a_1x+b_1y) + b_2(c_1x+d_1y)$  $\\rightarrow$   $(a_2 a_1 +  b_2 c_1) x+(a_2 b_1 + b_2 d_1)y $\n  $c_2(a_1x+b_1y) + d_2(c_1x+d_1y)$  $\\rightarrow$   $(c_2 a_1 +  d_2 c_1) x+(c_2 b_1 + d_2 d_1)y $\n\n\nNon ho mai termini quadratici o cubici in x o y. \nSe non ci fossero le funzioni di attivazione sarebbe proprio un modello lineare, in cui non avrebbe nemmeno senso mettere tanti nodi al primo hidden layer (e tantomeno mettere piu’ di un layer!)\n\nAlla fine del capitolo successivo (il 13) ho provato a fare un modello senza funzioni di attivazione. I risultati sono interessanti.\n\nIn ogni caso le funzioni lineari applicate dopo ogni layer migliorano le prestazioni.\n\n\n  Step function $\\displaystyle f(x)= \\begin{cases} 0 &amp; \\text{if } x &lt; 0  \\ \n                                    1 &amp; \\text{if } x\\ge 0\\end{cases}$\n  Sigmoid nn.Sigomoid $\\displaystyle f(x) = \\frac{1}{1+e^{-x}}$\n  Tanh  nn.TanH   $\\displaystyle f(x) = \\frac{2}{1+e^{-2x}} -1$\n  ReLU  nn.ReLU   $\\displaystyle f(x)= \\begin{cases} 0 &amp; \\text{if } x &lt; 0  \\ \n                                    x &amp; \\text{if } x\\ge 0\\end{cases}$\n  Leacky ReLU nn.LeakyReLU $\\displaystyle f(x)= \\begin{cases} ax &amp; \\text{if } x &lt; 0  \\ \n                                    x &amp; \\text{if } x\\ge 0\\end{cases}$  con $a &lt; 1$\n  Softmax nn.Softmax  $\\displaystyle S(y_i) = \\frac{e^y_i}{ \\sum_i e^{y_i}}$\n\n\nSono disponibili anche come funzioni di Torch, ma in questo caso i nomi sono tutti in minuscolo:\n\n  nn.ReLU()  $\\leftrightarrow$ torch.relu()\n  nn.Sigmoid()  $\\leftrightarrow$ torch.sigmoid()\n  nn.Softmax()  $\\leftrightarrow$ torch.softmax()\n  nn.TanH()  $\\leftrightarrow$ torch.tanh()\n\n\nIn alcuni casi le funzioni non sono disponibili da Torch,\nma si deve passare da torch.nn.functional:\n\n\n  F.relu()\n  F.leaky_relu()\n\n\nimport torch \nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# opzione 1: creare un modulo nn \nclass NeuralNet1(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(NeuralNet1, self).__init__()   # questo serve per ereditare il costruttore?\n        self.linear1 = nn.Linear(input_size, hidden_size)        #   \n        self.relu = nn.ReLU()                                    # metodo nuovo \n        self.linear2 = nn.Linear(hidden_size, 1)       # altro metodo che prende 2 arg \n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):            # devo passare l'input: x\n        out = self.linear1(x)\n        out = self.relu(out)\n        out = self.linear2(out)\n        out = self.sigmoid(out)\n        return out \n    \n    \n        \n# opzione 2: usare le funzioni di attivazione di Torch \nclass NeuralNet2(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(NeuralNet2, self).__init__()   # questo serve per ereditare il costruttore?\n        self.linear1 = nn.Linear(input_size, hidden_size)        #   \n        self.linear2 = nn.Linear(hidden_size, 1)       # altro metodo che prende 2 arg \n\n    def forward(self, x):                     # devo passare l'input: x\n        out = torch.relu(self.linear1(x))     # ho usato le funzioni di torch\n        out = torch.sigmoid(self.linear2(out))\n        return out"
					}
					
				
			
		
			
				
					,
					
					"pytorch-2": {
						"id": "pytorch-2",
						"title": "Pytorch 2 Chainrule Autograd",
						"categories": "italiano",
						"url": " /Pytorch-2",
						"content": "tocIn this post\n  \n  \n\n  ChainRule e Autograd    \n      Introduzione ai grafi computazionali\n      Stop tracking\n    \n  \n  Backpropagation\n  Discesa del gradiente Manuale\n  Discesa del gradiente Autograd\n\n\n  \n\n\nIndice Globale degli argomenti tra i vari post:\n\n 1.1.                                    Indice degli argomenti.\n 1.1.                                      Introduzione e fonti.\n 1.1.                                  Lingo - Gergo utilizzato.\n 1.2.                                        Tensori in Pytorch.\n 2.1.                                      Chainrule e Autograd.\n 2.2.                                           Backpropagation.\n 3.1.                                          Loss e optimizer.\n 3.2.                                        Modelli di Pytorch.\n 3.3.                                      Dataset e Dataloader.\n 3.4.                                       Dataset Transforms.\n 3.5.                              Softmax e Cross-Entropy Loss.\n 3.6.                                       Activation Function.\n 4.1.                                Feed Forward Neural Network.\n 5.1.                               Convolutional Neural Network.\n 5.2.                                          Transfer Learning.\n 5.3.                                                Tensorboard.\n 6.1.                              I/O Saving and Loading Models.\n 7.1.                                  Recurrent Neural Networks.\n 7.2.                                            RNN, GRU e LSTM.\n 8.1.                                          Pytorch Lightning.\n 8.2.                                               LR Scheduler.\n 9.1.                                                Autoencoder.\n\nChainRule e Autograd\nIl pacchetto Autograd fornisce differenziazione automatica per le operazioni (funzioni) sui tensori:\nrequires_grad=True \nImmagina un tensore come una semplice variabile (multidimensionale) che entra in un grafo computazionale. Alla fine del grafo ho uno scalare (in genere) e voglio sapere come dipende questo scalare dal un particolare tensore, allora devo usare Autograd.\n\n\nIntroduzione ai grafi computazionali\nPer esempio:\n\n  costruisco un tensore x  (1D con 3 ingressi random)\n  costruisco un tensore y funzione di x: y=x+2\n  costruisco un tensore z funzione di y: z= 3y$^2$\n  ATTENTO il gradiente si puo’ calcolare solo se alla fine si hanno dei valori SCALARI (altrimenti ho un numero di gradienti pari alle componenti del vettore). La logica e’ chiara, alla fine io voglio vedere come varia una funzione di LOSS rispetto ai parametri che metto nella rete neurale. La LOSS e’ una funzione scalare e quindi non sono state implementate delle variazioni per funzioni vettoriali.\n  calcolo quindi il valore medio di u=&lt;z&gt; (per avere uno scalare)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe voglio conoscere la dipendenza di ${\\bf u}$ da parte di ${\\bf x}$, dal punto di vista matematico devo calcolare la derivata parziale di u rispetto a x:\n\n (indici ripetuti sono sommati)\n\n\n\n\n\nQuindi:\n\n\nSe il valore del tensore ${\\bf x_0} = (1, 1, 1)$, alora il gradiente rispetto alla variaibile x della funzione u e’ un vettore che vale:\n\n\n\n\nPensala cosi’: C’e’ una funzione di molte variabili che vengono combinate passo passo. Queste variabili pensale come proprio i pesi della rete neurale. Alla fine noi vogliamo minimizzare la LOSS. Quindi prendiamo il gradiente per trovare la pendenza massima e scendiamo lungo il gradiente di queste variabili con piccoli passi, sperando di raggiungere un buon minimo (occhio che la cosa non e’ garantita banalmente in quanto non siamo in un caso semplice di un solo massimo, potremmo finire in un minimo locale!).\n\nAttenzione\n\nQuando si fa il .backward() i valori dei gradienti vengono ACCUMULATI nell’attributo .grad\n\nx = torch.ones(3, requires_grad=True)   #  x = [x_1, x_2, x_3] = [1, 1, 1]\ny = x + 2                               #  y = [y_1, y_2, y_3]      \n\n##### Occhio y e' funzione di x, che ha requires_grad=True. Quindi ha come attributo grad_fn\nprint(y.grad_fn)\nz = y * y * 3                           #  z = [3 y_1^2, 3 y_2^2, 3 y_3^2] Lavorano sul singolo ingresso!\nz = z.mean()                            #  zmean = 1/3 ( 3 y_1^2 +  3 y_2^2 + 3 y_3^2 )      calcolo la media\n\nz.backward()                            # back propagation \nprint(x.grad)                           # dz/dx = dz/ dy * dy/dx CALCOLATO nel valore corrente delle x\n\n\n&lt;AddBackward0 object at 0x000001EE446B2BB0&gt;\ntensor([6., 6., 6.])\n\n\nSe l’output non e’ uno scalare si devono specificare gli argomenti per il metodo .backward(), non mi e’ chiaro come questi argomenti vengano usati.\n\n#x = torch.randn(3, requires_grad=True)     # tensore 1D\nx = torch.tensor([1.1,1.1, 1.1], requires_grad=True)     # tensore 1D\n\ny = x * 2                                  # altro tensore 1D\nfor _ in range(10):                        \n    y = y * 2                              # y * y * y * ... * y (10 volte +1 del passo precedente)  = x * 2**11\n\nprint(y)\nprint(y.shape)\nv = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n\ny.backward(v)         # qui ho specificato che voglio il gradiente rispetto a ... v? non chiaro forse fa derivata direzionale\n\nprint(x.grad)\n\n\ntensor([2252.8000, 2252.8000, 2252.8000], grad_fn=&lt;MulBackward0&gt;)\ntorch.Size([3])\ntensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n\n\nStop tracking\n\n  Supponiamo di volere fare un’update dei pesi durante il loop del training.\n  questo implica fare delle nuove funzioni sui pesi (le update), e quindi quando si fa  la back propagation si rischia che questa tenga conto anche delle update! Bisogna quindi dire al TENSORE di non tenere conto delle update. Ovvero si deve dire al TENSORE che deve essere tracciato solo lungo il network computazionale\n\n\n(non del tutto chiaro devo fare esperimenti)\n\n\n  x.requires_grad_(False)  (nota l’underscore _ finale per INPLACE)\n  x.detach()\n  wrap in with torch.no_grad():\n\n\nSe si usa il metodo .zero_() questo riempie il gradiente prima di un nuovo passo di ottimizzazione.\n\na = torch.randn(2, 2)         # qui NON accendiamo il requires_grad\nprint(a.requires_grad)        # e appunto se controlliamo da': False\nb = ((a * 3) / (a - 1))       # costruisco un nuovo Tensore b\nprint(b.grad_fn)              # e per qusto non c'e' l'attributo grad_fn che indica che c'e' una gradiente\n\na.requires_grad_(True)        # accendiamo INPLACE(_) il gradiente  \nprint(a.requires_grad)        # ora il risultato e' True\nb = (a * a).sum()             # creiamo uno scalare b con sum() fa la somma del Tensore. \nprint(b.grad_fn)              #  \n\n# .detach(): get a new Tensor with the same content but no gradient computation:\na = torch.randn(2, 2, requires_grad=True)\nprint(a.requires_grad)\nb = a.detach()\nprint(b.requires_grad)\n\n# wrap in 'with torch.no_grad():'\na = torch.randn(2, 2, requires_grad=True)\nprint(a.requires_grad)\nwith torch.no_grad():\n    print((x ** 2).requires_grad) # qui ho fatto un'altra funzione con x ma non contribuisce al gradiente!\n\n\nFalse\nNone\nTrue\n&lt;SumBackward0 object at 0x000001A0C4C411F0&gt;\nTrue\nFalse\nTrue\nFalse\n\n\n# -------------\n# backward() accumulates the gradient for this tensor into .grad attribute.\n# !!! We need to be careful during optimization !!!\n# Use .zero_() to empty the gradients before a new optimization step!\nweights = torch.ones(4, requires_grad=True)\n\nfor epoch in range(3):\n    # just a dummy example\n    model_output = (weights*3).sum()\n    model_output.backward()\n    \n    print(weights.grad)\n\n    # optimize model, i.e. adjust weights...\n    with torch.no_grad():                 # quando faccio l'ottimizzazione dei valori del tensore\n        weights -= 0.1 * weights.grad     # non voglio che facciano parte del grafo computazionale!  \n\n    # this is important! It affects the final weights &amp; output\n    weights.grad.zero_()   # se non azzeri c'e' accumulo (?)\n\nprint(weights)\nprint(model_output)\n\n# Optimizer has zero_grad() method\n# optimizer = torch.optim.SGD([weights], lr=0.1)\n# During training:\n# optimizer.step()\n# optimizer.zero_grad()\n\n\ntensor([3., 3., 3., 3.])\ntensor([3., 3., 3., 3.])\ntensor([3., 3., 3., 3.])\ntensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\ntensor(4.8000, grad_fn=&lt;SumBackward0&gt;)\n\n\nBackpropagation\nun esempio semplice di backpropagation.\n\n  costruisco un tensore 0D x=1  (e’ il predictor)\n  costruisco un tensore 0D y=2  (e’ la funzione obiettivo)\n  costruisco un tensore 0D w=1  (sono i pesi che voglio ottimizzare)\n  calcolo le y_predicted =w*x\n  calcolo la LOSS (y_predicted-y)$^2$  (tutto questo e’ il forward pass)\n  calcolo la BACKPROPAGATION (stando attento a non farla entrare nel grafo computazionale)\n  azzero i gradienti e ripeto varie epoche\n\n\nx = torch.tensor(1.0)                          # costruisco un tensore 0D (1 oggetto): i predictors\ny = torch.tensor(2.0)                          # un altro tensore 0D:                  la risposta ESATTA\n\nw = torch.tensor(1.0, requires_grad=True)      # questo tensore ha accesa la condizione requires_grad, i PESI\n\n# FORWARD PASS\ny_predicted = w * x                            # costruisco un grafo computazionale, ora y =w*x, la risposta CALCOLATA \nloss = (y_predicted - y)**2                    # la funzione di LOSS \nprint(loss)\n\n# BACKWARD PASS dLoss/dw                       # calcolo la dipendenza della LOSS in funzione dei PESI\nloss.backward()                               \n#print(w.grad)\n\n# A questo punto voglio fare una update dei PESI per cercare di fare predizioni migliori\n\n# \n# l'update dei PESI NON deve entrare nel grafo computazionale\nwith torch.no_grad():\n    w -= 0.01 * w.grad      # mi muovo lungo la direzione di massima crescita... al negativo di un passetto\n\nw.grad.zero_()              # NON dimenticare di azzerare i gradienti \n\n\n# FORWARD PASS\ny_predicted = w * x                            # nuovo forward pass \nloss = (y_predicted - y)**2                    # nuova funzione di LOSS \nprint(loss)\n\n############# faccio ora un ciclo ################\nfor epoch in range(100):\n    with torch.no_grad():\n        w -= 0.01 * w.grad      # mi muovo lungo la direzione di massima crescita... al negativo di un passetto\n\n    w.grad.zero_()              # AZZERO i gradienti\n\n    y_predicted = w * x                            # nuovo forward pass \n    loss = (y_predicted - y)**2                    # nuova funzione di LOSS \n    loss.backward()                                # backward! se non lo faccio il gradiente e' stato azzerato! \n    if (int(epoch/10)*10==epoch):\n        print(loss, i)\n\n\ntensor(1., grad_fn=&lt;PowBackward0&gt;)\ntensor(0.9604, grad_fn=&lt;PowBackward0&gt;)\ntensor(0.9604, grad_fn=&lt;PowBackward0&gt;) 99\ntensor(0.6412, grad_fn=&lt;PowBackward0&gt;) 99\ntensor(0.4281, grad_fn=&lt;PowBackward0&gt;) 99\ntensor(0.2858, grad_fn=&lt;PowBackward0&gt;) 99\ntensor(0.1908, grad_fn=&lt;PowBackward0&gt;) 99\ntensor(0.1274, grad_fn=&lt;PowBackward0&gt;) 99\ntensor(0.0850, grad_fn=&lt;PowBackward0&gt;) 99\ntensor(0.0568, grad_fn=&lt;PowBackward0&gt;) 99\ntensor(0.0379, grad_fn=&lt;PowBackward0&gt;) 99\ntensor(0.0253, grad_fn=&lt;PowBackward0&gt;) 99\n\n\nDiscesa del gradiente Manuale\nproviamo ora con un esempio 1D (prima era 0D) con una regressione lineare.\n\n\n  i vari passi vengono calcolati MANUALMENTE senza usare Torch\n  costruisco una funzione che fa il forward pass\n  costruisco una funzione che fa il backward pass\n  calcolo il gradiente (senza autograd)\n\n\nLa cosa interessante e’ che qui ho un array in ingresso.\nPrendo tutti i valori dell’array di ingresso e con essi faccio il training tutti insieme (calcolo infatti la LOSS su tutti).\nPoi il passo forward lo faccio su uno scalare! per vedere se la predizione funziona\n\nimport numpy as np \n\n# Regressione Lineare \n# f = w * x \n\n# here : f = 2 * x\nX = np.array([1, 2, 3, 4], dtype=np.float32)   # PREDICTORS\nY = np.array([2, 4, 6, 8], dtype=np.float32)   # OBIETTIVO\n\nw = 0.0                                        # pesi (ma non e' un tensore...) \n\n# MODEL OUTPUT \ndef forward(x):\n    return w * x                               # FORWARD PASS\n\n# LOSS MSE\ndef loss(y, y_pred):                           # LOSS MSE  \n    return ((y_pred - y)**2).mean()            # uso un metodo dei tensori .mean()\n\n# J = MSE = 1/N * (w*x - y)**2\n# dJ/dw = 1/N * 2x(w*x - y)\ndef gradient(x, y, y_pred):                    # calcolo il gradiente  \n    return np.dot(2*x, y_pred - y).mean()\n\nprint(f'Predizione prima del training: f(5) = {forward(5):.3f}')\n\n# Training\nlearning_rate = 0.01\nn_iters = 20\n\nfor epoch in range(n_iters):\n    \n    y_pred = forward(X)               # FORWARD\n    l = loss(Y, y_pred)               # LOSS\n    \n    dw = gradient(X, Y, y_pred)       # GRADIENTE (senza autograd) \n    w -= learning_rate * dw           # UPDATE   \n\n    if epoch % 2 == 0:\n        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n     \nprint(f'Predizione dopo il training: f(5) = {forward(5):.3f}')\n\n\n\nPrediction before training: f(5) = 0.000\nepoch 1: w = 1.200, loss = 30.00000000\nepoch 3: w = 1.872, loss = 0.76800019\nepoch 5: w = 1.980, loss = 0.01966083\nepoch 7: w = 1.997, loss = 0.00050332\nepoch 9: w = 1.999, loss = 0.00001288\nepoch 11: w = 2.000, loss = 0.00000033\nepoch 13: w = 2.000, loss = 0.00000001\nepoch 15: w = 2.000, loss = 0.00000000\nepoch 17: w = 2.000, loss = 0.00000000\nepoch 19: w = 2.000, loss = 0.00000000\nPrediction after training: f(5) = 10.000\n\n\nDiscesa del gradiente Autograd\ncome il punto precedente ma usando Autograd\n\n\n  ATTENZIONE il print non legge bene il formato dei “tensori”, devo usare il metodo .item() per ottenere il valore.\n  .backward() va fatto sulla loss\n  .grad  e’ automaticamente ottenuto come parametro del tensore (per esempio dei pesi)\n\n\nimport numpy as np \nimport torch\n\n# Regressione Lineare \n# f = w * x \n\n# here : f = 2 * x\nX = np.array([1, 2, 3, 4], dtype=np.float32)   # PREDICTORS\nY = np.array([2, 4, 6, 8], dtype=np.float32)   # OBIETTIVO\n\n#Nota che posso vedere sia dal punto di vista spaziale che temporale.\n# dal punto di vista temporale passo alla mia rete neurale un predictor per volta\n# (ma non e' manco piu' un vettore).\n# dal punto di vista spaziale, passo tutti i predictor e ottengo tutti gli obiettivi.\n\n\n# trasformo in TENSORI (avrei potuto direttamente usare torch.tensor(), ma cosi' uso from_numpy())\n\nX = torch.from_numpy(X)                        # autograd non serve\nY = torch.from_numpy(Y)                        # neanche qui \n\nw = torch.tensor([0.0], requires_grad=True)    # pesi: accendo Autograd  \n\n# MODEL OUTPUT \ndef forward(x):\n    return w * x                               # FORWARD PASS\n\n# LOSS MSE\ndef loss(y, y_pred):                           # LOSS MSE  \n    return ((y_pred - y)**2).mean()            # mean() e' un metodo dei tensori\n\nprint(f'Predizione prima del training: f(5) = {forward(5).item():.3f}')\n\n# Parametri del Training\nlearning_rate = 0.01\nn_iters = 50\n\nfor epoch in range(n_iters):\n    \n    y_pred = forward(X)               # FORWARD\n    LOSS = loss(Y, y_pred)            # LOSS\n    LOSS.backward()                   # BACKPROPAGATION (Autograd) \n    \n    with torch.no_grad():\n        w -= learning_rate * w.grad   # UPDATE   \n    w.grad.zero_()                    # AZZERO i gradienti\n        \n    if epoch % 10 == 0:\n        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {LOSS.item():.8f}')\n        #print(w)    \n#print(f'Predizione dopo il training: f(5) = {forward(5):.3f}')\n\n\n\nPredizione prima del training: f(5) = 0.000\nepoch 1: w = 0.300, loss = 30.00000000\nepoch 11: w = 1.665, loss = 1.16278565\nepoch 21: w = 1.934, loss = 0.04506890\nepoch 31: w = 1.987, loss = 0.00174685\nepoch 41: w = 1.997, loss = 0.00006770"
					}
					
				
			
		
			
				
					,
					
					"mapreduce": {
						"id": "mapreduce",
						"title": "MapReduce, Calcolo Parallelo, UNIMIB",
						"categories": "italiano",
						"url": " /mapReduce",
						"content": "MapReduce a.a. 2019-2020, in queste diapositive mostro un paio di modi\n  per fare il prodotto matrice-matrice tramite MapReduce; in pratica ho fatto un adattamento e traduzione di quanto fatto da\n http://www.norstad.org\n (Attenzione, il sito originale sembra non piu’ raggiungibile, probabilmente tramite quei servizi che contengono un archivio di internet e’ possibile trovarne una copia). \nQueste diapositive sono state usate durante il corso di “Sistemi di Calcolo Parallelo” tenuto persso il DISCo all’Universita’ degli Studi di Milano-Bicocca.\n\n\nHo usato inoltre due Jupyter notebook:\n\n\n  \n    HADOOP Streaming, qui viene introdotto come usare degli eseguibili scritti\n nel linguaggio preferito per usare  Hadoop (invece che dover usare Java)\n  \n  \n    MRJob, per utilizzare delle semplici classi di Python per\n job di tipo MapReduce anche complessi (e testarli facilmente in locale, senza dover installare Hadoop)\n  \n\n\ni notebook originali erano forniti in un corso del CINECA del 2015. Eventuali errori di queste versioni modificate sono miei e non da imputare agli autori dei notebook\noriginali.\n\nA chi e’ rivolto MapReduce?\n\nUna premessa: questa e’ l’ultima parte del corso, prima introduco MPI,\n poi OpenMP \ne CUDA\n, infine passo  HADOOP/MapReduce.\n\nI primi 3 argomenti sono pertinenti per chi e’ interessato a fare High Performance Computing. Richiedono di imparare \nnuove API, capire nel dettaglio come e’ fatto l’hardware sottostante e scrivere dei codici abbastanza complessi.\n\nSe invece lo scopo e’ quello di utilizzare hardware (quasi) commerciale e  cercare di evitare\nle problematiche legate ad imparare un nuovo linguaggio, allora ha senso pensare in termini di Hadoop/Mapreduce.\n\nL’ipotesi di lavoro e’ che si abbia a che fare con grandi moli di dati (che devono essere distribuiti su computer distinti).\n\nL’idea e’ proprio quella di facilitare buona parte della comunicazione necessaria quando si ha a che fare con\ntante macchine che lavorano in parallelo. Per questo, molto del lavoro e’ fatto dal filesystem distribuito (nel caso di HADOOP\nsi chiama HDFS). Il cuore di un calcolo MapReduce e’ di utilizzare coppie chiave-valore.\nIl compito/algoritmo da eseguire in parallelo deve poter essere spezzato in 2 fasi, una di seguito all’altra, chiamate:\n\n\n  \n    Map\n  \n  \n    Reduce\n  \n\n\nDurante la fase di Map, tanti computer in parallelo eseguono il medesimo compito (chiamato Mapping). \nIl risultato dell’esecuzione di ogni Mapper e’ l’emissione di molte coppie chiave-valore (intermedie).\nAttenzione, i Mapper lavorano in modo indipendente l’uno dall’altro: non comunicano tra loro! \nEssi fanno tutti la stessa cosa ma con parti diverse di dato (HDFS assegna i pezzi del dato senza un ordine particolare).\n Le coppie chiave-valore prodotte dai Mapper\nvengono ridistribuite (shuffling) da HDFS ai Reducer, in un modo specifico: ogni reducer riceve solo coppie chiave-valore\nche abbiano la stessa chiave (intermedia).\n\nTutta la comunicazione di un job MapReduce si riassume quindi nella fase di shuffling! Sta al programmatore scrivere dei Mapper che emettano\nle chiavi intermedie corrette, in modo che poi i reducer facciano il lavoro che ci si aspetta. Una volta fatto questo, la cominicazione e’ interamente\ngestita da  HDFS!\n\nA questo punto, tutti i Reducer lavorano con i dati ottenuti ed emettono a loro volta coppie chiave-valore (il risultato finale del calcolo MapReduce).\nTutti i Reducer fanno esattamente lo stesso algoritmo, ma ognuno ha dei dati diversi opportunamente re-distribuiti tramite l’uso di coppie\nchiave-valore.\n\nIl difficile di un job  MapReduce e’ proprio nel trovare le giuste coppie chiave-valore intermedie emesse dai Mapper che consentano di fare arrivare\nai Reudcer i dati corretti."
					}
					
				
			
		
			
				
					,
					
					"mpi": {
						"id": "mpi",
						"title": "MPI, Calcolo Parallelo, UNIMIB",
						"categories": "italiano",
						"url": " /MPI",
						"content": "MPI a.a. 2020-2021,  diapositive in formato handout.\nHo aggiunto varie animazioni, reso uniforme e modificato alcune parti rispetto all’anno precedente.\nIn totale ci Sono 162 diapositive.\n  \n  \n    MPI a.a. 2019-2020,  diapositive in formato handout.\nHo aggiunto varie animazioni, corretto errori e modificato alcune parti rispetto all’anno precedente.\n  \n  \n    MPI a.a. 2018-2019, queste diapositive sono in\n formato handout (scritte con Latex-beamer)\n  \n  \n    i file riguardanti gli esercizi proposti durante il corso sono qui.\n  \n\n\nIn questa pagina ci sono i link del materiale che ho scritto per la parte di MPI del corso di Sistemi di Calcolo Parallelo presso il DISCo \n all’Universita’ degli Studi di Milano-Bicocca.\n\nA chi e’ rivolto MPI?\n\nGrossolanamente parlando chi ha un cluster e vuole fare dei calcoli paralleli.\nIn partica ci si aspetta che le varie unita’ di calcolo abbiano risorse separate\ne per questo motivo debbano comunicare informazioni durante un calcolo parallelo.\nNon e’ un caso che questo standard si chiami infatti Message Passing Interface.\n\nLa curva di apprendimento e’ un po’ piu’ ripida, all’inizio, rispetto a \nOpenMP.\n\nIl punto di partenza che deve essere tenuto bene a mente e’ che ogni unita’\ndi calcolo, in linea di principio, esegue TUTTO il codice che abbiamo scritto.\nPer questo motivo si devono usare delle condizioni if/then abbinate a degli\nidentificativi della macchina stessa (forniti da MPI tramite apposite API) per suddividere un calcolo\ntra le varie unita’ di processazione."
					}
					
				
			
		
			
				
					,
					
					"cuda": {
						"id": "cuda",
						"title": "CUDA, Calcolo Parallelo, UNIMIB",
						"categories": "italiano",
						"url": " /Cuda",
						"content": "CUDA a.a. 2020-2021:\nAnche queste sono diapositive “estese”. Il numero totale di diapositive e’ meno di 90, pero’ il numero totale di pagine del documento pdf e’ circa 380. Faccio\napparire un punto per volta nelle liste, e faccio apparire un’immagine per volta quando voglio fare piccole animazioni.  Ho migliorato l’impaginazione rispetto\n all’anno scorso e  ho aggiunto un po’ di disegni (dato che ho trovato un modo migliore per impostare i passaggi da una slide all’altra senza dover salvare una per una tutte le diapositive, \nma inserendo un unico pdf! eureka). CUDA sta diventando sempre piu’ user friendly e quindi una buona parte delle raccomandazioni che erano \nnecessarie per le prime schede grafiche stanno diventando obsolete.\n  \n  \n    CUDA a.a. 2019-2020:\nqueste diapositive sono estese, ovvero contengono tutte le immagini e le “animazioni” (per esempio i punti di una lista possono comparire uno dopo l’altro).\nRispetto all’anno precedente, sono state fatte varie modifiche, sia di tipo strutturale (alcuni argomenti sono stati modificati e spostati) e sono state\naggiunte nuove immagini e “animazioni”.\n  \n  \n    CUDA a.a. 2018-2019: queste diapositive sono in formato “handout”, ovvero le\n animazioni del singolo frame sono condensate nell’ultima immagine del frame, e le liste appaiono tutte insieme (non una per volta).\nD’altra parte la quantita’ di memoria richiesta e’ minore, e sono piu’ facilmente studiabili.\n  \n\n\nI link qui sopra si riferiscono alle note che ho scritto su CUDA. Sono state usate durante il corso di “Sistemi di Calcolo Parallelo”, presso il\nDipartimento di Informatica, Sistemisitca e Comunicazione dell’Universita’ degli Studi di Milano-Bicocca.\nIn alcuni casi possono esserci dei richiami ad altre parti del corso, in particolare\na  MPI\n e OpenMP.\n\nA chi si rivolge CUDA?\n\n\n  \n    a chi ha una scheda grafica NVIDIA!\n  \n  \n    … e vuole velocizzare dei calcoli che richiedono molte volte la stessa operazione ma su dati differenti.\n  \n\n\nIn una GPU infatti, ci sono centinaia (migliaia) di Aritmetic Logic Units (ALU) che possono eseguire operazioni in modo concorrente,\n ma ci sono poche unita’ di controllo che gestiscono le ALU. Per questo motivo le \nALU devono lavorare in lockstep ovvero un gruppo (warp) di ALU deve eseguire la stessa operazione … su dati differenti.\n\nQuesto approccio e’ una specie di versione piu’ complessa rispetto a  OpenMP\n dove molti thread possono accedere ad aree di memoria condivise.\n\nIl punto chiave da comprendere quando si vogliono velocizzare \ndei calcoli tramite CUDA e’ spesso legato alla memoria (o meglio alle memorie).\nAvendo a disposizione molte unita’ di processazione, il problema puo’ diventare quello di portare i dati \ndalla memoria al chip. Se eseguire un calcolo puo’ richidere un solo ciclo di clock, \nla latenza necessaria per portare il dato sulla ALU ne puo’ richiedere centinaia!\n\nLe GPU sono progettate per “nascondere” la latenza con un trucco:\nmentre un warp aspetta la memoria, un altro warp puo’ essere attivato a costo zero ed eseguire operazioni. \nNelle normali CPU, questo passaggio (context switch), puo’ essere molto costoso e come risultato\nuna CPU puo’ passare molto tempo in stato di idle. Con una GPU e’ invece possibile ottenere \ndelle occupancy molto alte.\n\nDal punto di vista del programmatore, invece, \nper ottenere un codice che sfrutti al meglio le caratteristiche di CUDA \ne’ necessario conoscere bene come si relazionano le strutture fisiche (CUDA core,\nStreaming Multiprocessor,…) e le strutture logiche (thread, warp, blocco e griglia).\n\nE’ altrsi’ necessario sfruttare i vari tipi di memoria: registri, shared memory, cache, \nConstant, Texture e Global.\n\nUna buona applicazione di CUDA puo’ velocizzare notevolmente un calcolo, ma ha una\ncurva di apprendimento piu’ ripida rispetto ad OpenMP (e probabilmente anche di MPI)."
					}
					
				
			
		
			
				
					,
					
					"openmp": {
						"id": "openmp",
						"title": "OpenMp, Calcolo Parallelo, UNIMIB",
						"categories": "italiano",
						"url": " /OpenMP",
						"content": "OpenMP a.a. 2020-2021. In questa versione ci sono varie nuove immagini e altre\n correzioni. In totale sono 114 diapositive, ho espanso le transizioni e le immagini in modo che tutta la\npresentazione sia piu’ leggibile. In alcuni casi anche gli elenchi appaiono come multi-diapositiva. Questo perche’ ho essenzialmente\ncommentato i comandi “\\pause” ma alcuni elenchi sono fatti tramite scritture tipo “&lt;1,4&gt;”, “&lt;2,4&gt;” ecc che non sono rimuovibili\nvelocemente.\n Si noti che la presentazione e’ abbastanza auto-contenuta, ma a lezione aggiungevo parti,\nespandevo le spiegazioni e facevo domande. Chiaramente queste cose non sono incluse nelle diapositive.\n  \n  \n    OpenMP a.a. 2019-2020. Le differenze tra queste diapositive e quelle \ndell’anno precedente riguardano nuove immagini e la correzione di alcuni errori.\n  \n  \n    OpenMP a.a. 2018-2019, questa presentazione non contiene\n le soluzioni degli esercizi ed e’ in formato handout, quindi le “animazioni” non sono visibili, ma \nle diapositive sono piu’ leggibili in quanto non compaiono un pezzo per volta.\n  \n  \n    i \nfile da usare per gli esercizi proposti\nnon contengono le soluzioni ma velocizzano la scrittura del codice (si devono solo apportare le modifiche\nrichieste).\n  \n\n\nI link qui sopra si riferiscono alle note che ho scritto per la parte di OpenMP \ndel corso di “Sistemi di Calcolo Parallelo” presso il DISCo,\nall’Universita’ di Milano-Bicocca. Ho utilizzato varie fonti per scriverle\ne mi sono basato anche esperimenti numerici. \nCi possono essere alcuni richiami a  MPI\n(che viene presentato prima di OpenMP durante il corso).\n\nOpenMP: contesto:\n\ngrossolanamente parlando, OpenMP si rivolge a chi ha delle CPU multicore.\nI vari core condividono la memoria (shared memory) e comunicano tramite essa.\n\nOpenMP: perche’?\nSupponiamo che si abbia un ciclo for (C/C++) o un do loop (Fortran).\nCon una aggiunta di 3-4 righe al codice, OpenMP puo’ ridistribuire il calcolo\ndel ciclo tra i vari core. Smplice. Pulito. L’ideale per un fisico alle prime armi\nche debba velocizzare un codice senza dover impazzire a leggere centinaia di pagine di spiegazioni.\n\nOpenMP: attenzione.\n\nNonostante possa essere usato in modo molto semplice all’inizio, puo’ essere \ningannevole. Non e’ difficile cadere in condizioni di race-condition, ovvero\nquando i core accedono, leggono e (sovra) scrivono lo stesso oggetto. A causa\ndi una race-condition il risultato del calcolo non e’ deterministico:\ndipende dall’ordine di accesso dei core alla risorsa!"
					}
					
				
			
		
			
				
					,
					
					"prose-io": {
						"id": "prose-io",
						"title": "prose.io + ProWritingAid",
						"categories": "English",
						"url": " /prose-io",
						"content": "Editing help for GitHub Pages: prose.io + ProWritingAid works (more or less)!\n\nSome time ago, I wrote a post on this blog, about random numbers and  philosophy with my favourite editor: gvim.\n\nWhen using this editor, it is rather difficult to spot the little spelling mistakes, in particular before the markdown text has been compiled.\nI also made some syntax error where I used “too much + adverb” (while the correct version was “too + adverb”). For these reasons I was trying to use one of those nice apps like Grammarly in order to improve my prose…\n\nDuring this process, I found a useful service for managing the markdown posts for GitHub pages called:\n\n\n  prose.io\n\n\nto use it, you just need to grant access to your page, and it helps to manage posts, save them, commit, ecc.\n\nUnfortunately, Google Chrome extensions like Grammarly do not work properly with prose.io, i.e. they do not underline the mistakes or provide any suggestion. One needs to copy and paste the post on supported applications, correct the text and copy it back on the blog. This method is rather annoying.\nFor this reason I tried many other options, including:\n\n\n  webpage spell-check is a Google Chrome extension which works with prose.io, but it simply underlines the typos (no suggestions of any kind)\n  ProWritingAid is an extension similar to Grammarly, but it does not work with prose.io\n\n\nNo single Chrome extension I found provided both underlying typos and suggestions.\n\nHowever, I found a tricky solution by combining the two aforementioned products:\nwhen you turn on the “spell check” option of webpage spell-check everything becomes “editable”.\nThe cursor becomes like the one you use when entering text, even in webpages where there is no editable content. Actually, it is kind of annoying since (often) you cannot “click” on links!\n\nHowever, if you use it in conjunction with ProWritingAid it allows this latter to access the text of the posts you are editing with prose.io: at this point you get underlined typos and the suggestions.\n\nThis solution is not perfect:\n\n\n  It often suggests putting a period where you wrap a line although the sentence is not over\n  It takes a few seconds for the spell checks and suggestions to appear.\n  The suggestions can disappear magically, for example, when you change Windows desktop. At this point you need to turn off and on again the spell check of webpage spell-check (maybe a couple of times).\n  It is slow to edit the text when the suggestions are on! However, a click allows one to replace the old statement with the suggestion, making it easy, but …\n  The most annoying problem is that sometimes, after you click on the suggested correction, it remains on the editing window but it is not saved! In practice, in order to be sure that correction remain, you must edit them yourself rather than clicking for the automatic substitution.\n\n\nIn summary:\n\nIn order to use prose.io with editing suggestions, one needs to:\n\n  install webpage spell check on Chrome\n  install ProWritingAid on Chrome (and turn it on for the website prose.io)\n  enter prose.io (you need to give permission to access to your GitHub Pages site).\n  disable the spell check of webpage spell check (left click on the icon on Chrome, it is the bottom option) otherwise you not be able to click on prose buttons!\n  enter the dir containing the _posts and select the desired one.\n  turn on the spell check of webpage spell check and wait a few seconds, at this point the suggestions by ProWritingAid will appear under the text and by left-clicking on the underlined words one gets the suggestions, and the possibility to replace the text!"
					}
					
				
			
		
			
				
					,
					
					"figli": {
						"id": "figli",
						"title": "Probabilita', figli e misura",
						"categories": "italiano",
						"url": " /figli",
						"content": "Il Problema\n\nMi sono imbattuto in questo interessante e “semplice” problema di statistica \n(sarebbe meglio dire dalla semplice formulazione).\nQuesto mio post e’ in pratica una riassunto di questo bel video\n di Zach Star, a cui aggiungo qualche considerazione personale.\n\nUn’osservazione: e’ molto importante la definizione della domanda che verra’ posta,\nperche’ ci sono vari dettagli che possono sfuggire.\n\nVedremo inoltre una cosa molto interessante, non e’ sufficiente pensare in termini di popolazioni, \nma e’ necessario pensare anche in termini di come queste popolazioni vengono misurate.\n\ninfoSupponiamo di incontrare una persona in un bar, Tizio per gli amici. Durante una conversazione, \nTizio ci dice che ha 2 figli (senza specificarne il sesso), decide poi di darci \ndue informazioni aggiuntive, una dopo l’altra:\n\n\ninfo1. almeno uno dei figli e’ femmina \n\ninfo2. sua figlia Jane (come la morosa di Tarzan) guida il trattore.\n\nerror\nDomanda 1: quando il nostro interlocutore ci ha detto di avere almeno una\nfiglia femmina quale probabilita’ esiste che anche il secondo figlio sia una femmina? \n\nerror\nDomanda 2: quando aggiunge che la propria figlia si chiama Jane, la probabilita’ che il secondo figlio sia femmina cambia?\n\n\nProbabilita’\nPrima di procedere bisogna dare una definizione operativa di probabilita'. Ne prendiamo una ragionevole e\nsemplice (di tipo frequentista). Supponiamo che la situazione appena descritta si ripeta molte volte:\n incontro molti padri di famiglie diverse che mi dicono: ho due figli di cui almeno una figlia femmina. \nAumento di 1 sul taccuino il numero di famiglie con almeno una femmina; in seguito annoto sul taccuino anche il sesso dell’altro figlio.\nQuando ho una popolazione abbastanza grande (migliaia di casi), conto il numero di famiglie totali e conto quante di esse\n hanno 2 femmine. La probabilita' sara’ il rapporto tra le famiglie con 2 femmine sul totale delle famiglie\nannotate.\n\nIl tutto va ripetuto anche nel caso in cui il genitore ci dice di avere 2 figli, di cui almeno una femmina di nome Jane, segnandoci la famiglia e il sesso del secondo figlio. La probabilita’ sara’ anche in questo caso il numero dei casi\n favorevoli rispetto ai totali. Chiaramente l’insieme di famiglie con due figli, di cui uno femmina di nome Jane,\ne’ un sottoinsieme di quello con due figli di cui uno femmina.\n\nAttenzione: teniamo 2 conti separati per i due casi (potremmo usare due taccuini separati).\n\nPopolazione A\n\n\n\n  \n\n\n\nA questo punto il bravo statistico comincia a costruire un modello in cui ci sono tutti gli oggetti possibili (meglio se\nquesti sono equiprobabili, cosi’ basta contarli).\nIn questo caso parliamo di popolazioni e di famiglie equiprobabili.\n\nLe combinazioni di famiglie equiprobabili sono le seguenti (M=maschio, F=femmina):\n\n  MM    (primogenito= maschio, secondogenito= maschio)\n  MF    (primogenito= maschio, secondogenito= femmina)\n  FM    (primogenito= femmina, secondogenito= maschio)\n  FF    (primogenito= femmina, secondogenito= femmina)\n\n\nQuesto perche’ possiamo considerare che all’incirca ci sia il 50% di probabilita’ di avere un figlio\nmaschio e altrettanto di avere una femmina (inoltre il sesso del secondo figlio non e’ influenzato dal sesso del\n primo figlio, resta il 50%)\n\nL’insieme delle famiglie che comprende almeno una figlia femmina e’ un sottoinsieme del totale.\nChiamiamo questo sottoinsieme  popolazione A, restano  solo i casi:\n\n  MF\n  FM\n  FF\n\n\nOgnuna di questi tipi di famiglie ha la stessa probabilita’ dell’altra.\nData questa popolazione (2 figli, di cui almeno una femmina), possiamo dire che solo in 1/3 dei casi la seconda figlia sara’ femmina.\nSi noti che questo risultato e’ indipendente dal nome dei ragazzi.\n\nPopolazione B\n\n\n\n  \n\n\n\nCerchiamo ora la popolazione di famiglie per cui si ha almeno una figlia femmina di nome Jane. Questa popolazione, sara’ \nun sottoinsieme della popolazione A.\n\nPer facilitarci le idee, assegnamo delle quantita’ alle popolazioni. Per esempio ci sono 100 000 famiglie MF, 100 000 FM  e 100 000 FF.\nSupponiamo che la frazione di ragazze chiamate Jane sia 1/100.\n\nVediamo qual’e’ ora la popolazione di riferimento (popolazione B):\n\n\n  si passa da 100 000 famiglie MF  $\\rightarrow$  1000 famiglie del tipo MJ  (dove J sta per Jane)\n  si passa da 100 000 famiglie FM  $\\rightarrow$  1000 famiglie del tipo JM\n  dalle 100 000 famiglie FF $\\rightarrow$ si passa a famiglie del tipo JF  e FJ, quindi in totale 2000 famiglie\n con 2 femmine hanno una ragazza chiamate Jane.\n\n\n(nel grafico sono state sottolineate in verde le famiglie che contribuiscono alla popolazione totale)\nIn questo caso quindi la popolazione totale comprende 4000 famiglie che corrispondono alle caratteristiche: \n2 figli di cui una femmina di nome Jane (supponiamo inoltre che i due figli non possano avere lo stesso nome).\nA differenza del caso precednte 1/2 delle famiglie comprendera’ una seconda figlia femmina.\n\nParadosso\n\nUn momento:\n\n  se conosco il nome della ragazza questo cambia in modo consistente la probabilita' che l’altro figlio \nsia una femmina: si passa da 1/3 a 1/2.\n  Il cambio e’ indipendente dal nome della ragazza!\n  quando Tizio mi aveva detto di avere una figlia, io sapevo gia' che questa doveva avere un nome… solo non sapevo\nquale!\n\n\nQueste tre condizioni sembrano in qualche modo contradditorie. Se il passaggio da 1/3 ad un 1/2 e’ indipendente dal nome,\ndato che io sapevo gia’ che la ragazza aveva un nome, come e’ possibile che il fatto che mi venga comunicato cambi \nle probabilita? La probabilita’ o e’ indipendente dal nome, o dipende!\n\nSoluzione: a cosa corrispondono le probabilita’ 1/3 e  1/2?\n\nIl problema e’ molto semplice: le probabilita’ 1/3 e 1/2 non corrispondono al problema iniziale!\nQueste probabilita’ sono corrette se si campionano le popolazioni in un modo differente rispetto a quello enunciato\ndal problema. Vediamo ora un modo per ottenere quelle probabilita’.\nPrendiamo un campione rappresentativo di genitori con 2 figli e mettiamolo in uno stadio. \n A questo punto si chiede a tutti quelli con 2 figli maschi di uscire.\n\n\n  Si chiede a quelli con due figlie femmine di alzare la mano. E si ottiene 1/3 del totale dei presenti.\n\n\nSe invece, facciamo uscire dallo stadio tutti i genitori, tranne quelli che hanno almeno un figlio femmina chiamato Jane,\n e a questo punto chiediamo loro di alzare la mano se hanno anche una seconda figlia femmina, \notterremo che circa 1/2 dei presenti alzera’ la mano.\n\nOra inserisco una piccola digressione.\nEsiste un interessante teorema che indica che per un “metodo di scelta random” la media spaziale \n(ovvero in questo caso contare tutte le famiglie con una caratteristica) puo’ essere rimpiazzata\nda una media temporale, a patto proprio che il criterio di scelta delle famiglie sia sufficientemente “caotico/random”.\nPer questo posso ottenere lo stesso risultato indicato sopra se io chiedo a tutte le persone che \nincontro al bar, una dopo l’altra (supponendo che siano sinceri, ovviamente):\n\n  se hanno 2 figli di cui almeno uno femmina\n  se il hanno una figlia chiamata Jane\n\n\nSe uno guarda al problema dal punto di vista delle persone presenti allo stadio, il fatto di fare uscire\ndallo stadio tutti coloro che non corrispondono a “avere una figlia femmina” ha un effetto tangibile.\nQuando si chiede di uscire a tutti coloro che non corrispondono ad “avere una figlia femmina chiamata Jane” \nl’effetto sara’ diverso. Vengono fatti dei campionamenti differenti dalla popolazione iniziale e questo\nmodifica quindi le frazioni/probabilita’.\n\nerrorAttenzione: il modo di procedere appena esposto non corrisponde al problema iniziale!\n\nIl problema iniziale era invece: incontro Tizio ad un bar, ad un \ncerto punto lui mi dice  di avere due figli, di cui almeno una femmina e successivamente ci dice il nome della femmina: Jane.\n\nIn questo caso il campionamento delle popolazioni e’ fatto in modo differente!\nSono i vari possibili “Tizio” che incontro al bar che definiscono il campione. \nQuesto cambia molto il risultato. Vediamo come:\n\nPopolazione C\n\nSupponiamo che ogni padre abbia piu’ o meno la stessa probabilita’ di parlare dei propri figli\n (non e’ necessariamente vero ma e’ ragionevole), prendiamo ora la popolazione A e vediamo\ncome si modifica, con un campionamento spontaneo (e’ il genitore che decide di cosa parlare):\n\n  da 100 000 famiglie del tipo MF, e’ ragionevole pensare che solo 1/2 dei padri mi parlera’ della figlia femmina\nl’altra meta’ mi dira’ di avere un figlio maschio $\\rightarrow$ solo 50 000 famiglie di tipo MF vengono aggiunte al mio taccuino\n  da 100 000 famiglie del tipo FM $\\rightarrow$ 50 000 famiglie anche in questo caso solo la meta’ dei padri parlera’ della femmina\n  da 100 000 famiglie del tipo FF $\\rightarrow$ 100 000 famiglie: siamo certi che, se il padre\nparla di un solo figlio, dovra’ dire che ha almeno una femmina!\n\n\n\n\n  \n\n\n\nQuindi se io lascio che l’interlocutore decida di cosa parlare, invece di ottenere la popolazione A si ha la popolazione C:\n\n  50 000 famiglie del tipo MF\n  50 000 famiglie del tipo FM\n  100 000 famiglie del tipo FF\n\n\nNotiamo subito una cosa:\n\n  se chiedo attivamente informazioni riguardo alla famiglia ottengo un numero totale di famiglie segnato sul mio taccuino uguale a 300 000 (popolazione A).\n  Se invece lascio lascio l’iniziativa di parlare al padre ottengo segnero’ sul taccuino una popolazione totale di sole 200 000 famiglie (popolazione C).\n\n\nPer questo motivo se non si fa un campionamento attivo, quando si incontra Tizio al bar  e questi ci dice che\nha 2 figli di cui almeno uno femmina, la probabilita’ che anche l’altro figlio sia femmina e’ 1/2.\n\nPopolazione D\n\nVediamo ora cosa succede (partendo dalla popolazione C) lasciamo che Tizio ci indichi (o meno) che il nome della propria figlia e’ Jane (nome con un’occorrenza ipotetica di 1/100),\n chiamo questo insieme di famiglie popolazione D (sottoinsieme della popolazione C):\n\n  da 50 000 famiglie MF si passa a 500 famiglie MJ\n  da 50 000 famiglie FM si passa a 500 famiglie JM\n  da 100 000 famiglie FF si passa a 1000 famiglie composte la meta’ da Jf e l’altra meta’ da fJ (non e’ possibile dare lo stesso nome a due figli…)\n\n\nIn questo caso e’ interessante notare che un genitore con 2 figlie femmine, di cui una chiamata Jane, \npotrebbe decidere di dirci il nome dell’altra figlia (50% dei casi). Per questo, nonostante la sua famiglia rientri nelle caratteristiche che noi vorremmo, verra’ rimossa dalla popolazione totale perche’ lui ha deciso di rivelarci un’altra informazione!\n\nIn questo caso, il fatto che il genitore mi abbia indicato il nome della figlia non ha cambiato la probabilita’ che la seconda figlia sia femmina: resta 1/2.\n\n\n\n  \n\n\n\nQuando succede?\nE’ questo un discorso questo di lana caprina? No! se effettivamente potessimo fare un esperimento del genere e scommettessimo\ndei soldi sul sesso dell’altro figlio di un nostro interlocutore, potremmo vincere (in media, ripetendo l’esperimento molte volte)\nsolo chiedendo ATTIVAMENTE delle informazioni sulla sua famiglia. Altrimenti, lasciando \nall’interlocutore l’iniziativa di parlare e scommettendo sul sesso dell’altro figlio avremmo il 50% \ndelle probabilita’ di azzeccare.\n\nConclusioni\nIl modo in cui l’informazione viene raccolta (come si fa l’esperimento per un fisico) modifica in modo sostanziale la risposta. Non e’ una cosa nuova.\nTutti sanno, per esempio, che per studiare una popolazione di qualche natura, non posso basarmi sui dati\nche mi vengono spontaneamente dati. \nNel caso in questione, il fatto di chiedere attivamente all’interlocutore informazioni riguardo i\npropri figli, modifica quello che lui ci dira’. Nel caso di domande attive, le probabilita’ ottenute saranno quindi:\n\n  1/3 di coloro che ci dicono di avere una figlia femmina avra’ anche un’altra figlia femmina\n  1/2 di coloro che ci dicono di avere una figlia di nome Jane  avra’  anche un’altra figlia femmina.\n\n\nSe invece si registrano le informazioni fornite spontaneamente, anche se l’informazione fornita dall’interlocutore e’ la stessa rispetto \nal caso precedente, otterremo:\n\n  1/2 di coloro che ci dicono di avere una figlia femmina avra’ anche un’altra figlia femmina\n  1/2 di coloro che ci dicono di avere una figlia di nome Jane  avra’  anche un’altra figlia femmina.\n\n\nQuindi il motivo per cui la probabilita’ (nel caso di domanda attiva) e’ differente nei 2 casi e’ perche’ io\nseleziono delle famiglie particolari creando delle popolazioni specifiche. \nNel dettaglio, selezionare le famiglie con almeno una figlia femmina di nome Jane privilegia le famiglie con 2 \nfemmine. Per questo motivo la probabilita’ che anche il secondo figlio sia femmina passa da 1/3 a 1/2.\n\nDetto in altri termini, le popolazioni usate per ottenere le probabilita’ cambiano a seconda che l’informazione\nvenga data spontaneamente o meno. Questo perche’ il padre di due figli di cui uno e’ maschio e uno\nfemmina, potrebbe spontanemente decidere di parlarci del figlio maschio. Il risultato sarebbe che la sua famiglia\nverrebbe automaticamente esclusa dalla popolazione totale e quindi questo cambierebbe le probabilita’ finali!\n\nP.S:\nprobabilmente in un altro post descrivero’ cosa succede nel caso in cui ci sia del rumore e l’informazione non\nvenga passata correttamente.\n\nP.P.S:\n Una considerazione da fisico, questo tipo di fenomeno ricorda curiosamente\nil problema della misura in meccanica quantistica. L’evoluzione spontanea di un sistema e’ profondamente\ndifferente dall’evoluzione dove interviene una misura."
					}
					
				
			
		
			
				
					,
					
					"random-access": {
						"id": "random-access",
						"title": "Random numbers towards Philosophy",
						"categories": "English",
						"url": " /random_access",
						"content": "Random numbers and algorithms:\nI was once browsing a math newsgroup, at a certain point I found a tricky question which made me think a bit.\n\nThe question sounded like this:\n\n  consider all the numbers between 0 and 1 (Real or Rational, there is no big difference).\n  Now please extract a random number among them.\n  (within 3 seconds I thought: 0.4324), done?\n\n\nAt this point the person highlighted the following strange thing:\nIf a set contains infinite numbers, each of them has ZERO probability. How could you extract a number?\n\nThat made me think.\n\nThis is one of the typical paradoxes based on the fact that you are told by somebody to do something, you think that you have done it, but in reality it is not true. It is generally called false choice when used by magicians or mentalists. For example, they make you choose freely a card, but in reality your choice is guided… In this case, I think it was a genuine question.\n\nHow do you pick a random number?\nLet’s suppose that a human brain contains a natural mechanism which allows\n you to  select digits randomly (like those random number generators based\n on quantum mechanics). \nLet’s also suppose that a brain can think of 100 digits per second.\nIt took me 3 seconds to answer, so at most I had the time for thinking at a number with 300 digits: a lot! (well my brain is surely much slower…).\n\nUnfortunately, as long as the number of digits is finite, it means that the mechanism for picking random number works on a finite set of numbers (and not on an infinite set, as it appeared from the question).\nSo we can say that at least one of them has a probability different from zero.\n\nAnother way to see the same thing is to think that, even if I had the “possibility” to choose among an infinite set of numbers, for most of them the probability was zero. However, I don’t like very much this last interpretation. I can use it for the sake of math modelling but…. there are no infinities in real life.\n\nInfinities\n\nWell, this should be explained with a bit more of detail since in every course of undergrad physics, one deals with all sorts of infinities.\n\nThe potential of a point charge diverges at the center. Every time an integral is carried out we are dividing an interval in an infinite set of “points” and so on and so forth.\nThe models requiring infinities are in fact very pervasive, but curiously enough people tend to forget that no infinite quantity has ever been measured.\n\nThe reason for this is essentially the same one that prevents a person to pick a number from an infinite set. In order to measure an infinite quantity, which needs to be described with an infinite set of digits, one person needs too much time: infinite.\n\nEpistemology\n\nSince I am walking in the kingdom of philosophy, please let me walk a bit further.\n\nThe practical “feasibility” of an action should always be taken into account. Sometimes people have the tendency to think too theoretically. If something is theoretically feasible, then it is as if we have already done it.\n\nClearly, this is not true. If an action requires too much time to be completed it might become practically impossible. The same happens if the action requires too many resources.\n\nOne of the most popular definitions of science (due to Karl Popper), suggests\nthat a statement is scientific if it is possible to disprove it.\nIt is a very compact definition which grasps a lot of what is science, and that\nis probably the reason of its popularity.\n\nI notice however one of it limits with the following example.\nThere is at least a mushroom in Norway, underneath which lives a gnome.\nIt is enough to look under a mushroom to check, and the number of mushrooms in Norway is clearly finite. In this respect, there is a theoretical method to disprove the sentence, and somebody might think that for this reason it becomes “scientific”.\nNonetheless, the practical feasibility of checking all the mushrooms is essentially zero. According to my opinion, the scientific value of the sentence is essentially zero too.\n\nIn general, I believe that an adjustment of this definition of science should use weights for the sentences. The more “feasible” it is to disprove the sentence, the more scientific it becomes.\n\nAn even better way to see science should include not only partial disproofs but also partial proofs and hints. Think of Cosmology for example, it is a science which deals with the whole universe (and even more…) we can easily say that most of the cosmological theories, including the more accepted ones, can hardly be disproved. On the other hand, we can collect many hints which can guide our idea of the universe and build theories which are more and more solid as a function of the hints we have. I remember once at a school of general relativity with some of the big shots around, one of the finest lecturers was George Ellis, who provided a very nice survey of many possible variations regarding the structure of the universe. His approach being rather different from those of some science popularizers who give for granted that \nthe universe has 13.6 billion years and so on…\nAt the same school, there was  Andrei Linde, one of the fathers of inflationary cosmology.\nHe explained his idea according to which there are many inflationary “big bangs” generating infinite universes, each with its own constants of physics. When he was asked about the strength of his theory, he simply replied that he could not prove it. However, this theory was like a nice symphony and he would stick with it unless he heard a better one. The point here is that for some complex topics, the very idea of proving or disproving becomes blurry.\n\nI know that this modified definition of science has limits (for example, is very difficult to decide the weights defining to which extent an action is feasible). However, one might accept the fact that science is\nnot just a block of granite, but its boundaries are more like the seashore.\n\nP.S.:\nPeople who have seen an analog tester might claim that when you measure the\nresistance there is a scale with an  sign on it.\nThis is a bit misleading, it simply means that the resistance under observation\nexceeds the max range measurable by the tester.\n\nP.P.S:\nI think that, among the approaches dealing with science, the paradigms shifts by\n Thomas Kuhn are very appealing (but less compact than Popper ideas,\nand thus less easy to use)."
					}
					
				
			
		
			
				
					,
					
					"cpp": {
						"id": "cpp",
						"title": "Tutorial di C++ per utenti C",
						"categories": "italiano",
						"url": " /Cpp",
						"content": "Autore:  Eric Brasseur\n  Traduzione in italiano di Paolo Avogadro\n  Qui il link della versione originale (inglese)\n  Qui invece il pdf di questa pagina\n\n\nUn nuovo modo di includere librerie\n\nEsiste un nuovo modo per includere (#include) delle\nlibrerie (il vecchio metodo funziona comunque, ma il compilatore si\nlamenta). L’estensione .h non viene piu’ usata, mentre\ni nomi delle librerie standard del C devono ora cominciare con la\nlettera c. Per fare si’ che il porgramma usi queste\nlibrerie correttamente bisogna aggiungere la seguente linea di comandi:\nusing namespace std;\n\nusing namespace std;\n#include &lt;iostream&gt;    // questa e' una libreria chiave del C++ \n#include &lt;cmath&gt;       // questa e' la libreria standard del C chiamata math.h\nint main ()\n{\n  double a;\n  a = 1.2;\n  a = sin (a);\n  cout &lt;&lt; a &lt;&lt; endl;\n  return 0;\n}\n\n\n output:  0.932039\n\n\nQualche consiglio per chi ha poca esperienza:\n\nPer compilare questo programma, prima va scritto (o copiato) in un\neditor di testo (gedit, kwrite, kate, kedit, vi, emacs, nano, pico,\nmcedit, Notepad…), il file va salvato e e chiamato, per esempio\ntest01.cpp (se si e’ proprio dei principianti sarebbe utile mettere il\nfile all’interno della propria home directory, ovvero per esempio\n/home/jones in un sistema di tipo Unix).\n\nPer compilare questo file sorgente, bisogna scrivere questo comando\n(sulla maggior parte dei sistemi di tipo Unix) in una console o nella\nterminal window:\n\ng++ test01.cpp -o test01\n\n\n(questo produrra’ un binario eseguibile chiamato test01) per far\ngirare questo eseguibile prodotto dalla compilazione (supponendo che non\nci siano stati degli errori, nella fase di scrittura o copia), si deve\nscrivere:\n\n./test01\n\n\nOgni volta che si modifica il file sorgente test01.cpp, e’ necessario\ncompilarlo ancora se si vuole che le modifiche si propaghino\nall’eseguibile (per esempio con la freccia cursore in su si puo’\nscorrere la lista dei vecchi comandi lanciati).\n\nNuovi modi per commentare linee di codice\n\nE’ possibile usrare // per indicare che una linea non e’ codice ma un\ncommento:\n\nusing namespace std;    // uso del namespace della libreria standard\n#include &lt;iostream&gt;     // la libreria iostream e' molto utile\nint main ()             // la funzione principale del codice \n{\n  double a;             // dichiarazione della variabile a \n  a = 456.47;\n  a = a + a * 21.5 / 100; // un calcolo\n  cout &lt;&lt; a &lt;&lt; endl;      // mostra il contenuto di a\n  return 0;               // fine della funzione \n}\n\n\n554.611\n\n\n(La possibilita’ di usare // per i commenti e’ stata aggiunta al C nel\nC99 e nell’ ANSI C 2000)\n\nNuovi modi per fare leggere comandi da tastiera e scrivere a video\n\nPer interfacciare i comandi da tastiera e a schermo con il codice e’\npossibile usare dei nuovi comandi:\n\n\n  \n     cout &lt;&lt;\n  \n  \n     cin &gt;&gt;\n  \n\n\nusing namespace std;\n#include &lt;iostream&gt;\nint main()\n{\n  int a;         // a e' una variabile di tipo integer\n  char s [100];  // s punta a una stringa \n  cout &lt;&lt; \"Questo e' un programma di esempio.\" &lt;&lt; endl;\n  cout &lt;&lt; endl;         // endl e' identico a \\n (end of line)\n  cout &lt;&lt; \"Inserisci la tua eta': \";\n   cin &gt;&gt; a;\n  cout &lt;&lt; \"Inserisci il tuo nome: \";\n   cin &gt;&gt; s;\n  cout &lt;&lt; endl;\n  cout &lt;&lt; \"Ciao \" &lt;&lt; s &lt;&lt; \", hai \" &lt;&lt; a &lt;&lt; \" anni\" &lt;&lt; endl;\n  cout &lt;&lt; endl &lt;&lt; endl &lt;&lt; \"arrivederci\" &lt;&lt; endl;\n  return 0;\n}\n\n\n Questo e' un programma di esempio.\n Inserisci la tua era':  12\n Inserisci il tuo nome:  Paolo\n \n Ciao Paolo, hai 12 anni\n \n \n arrivederci\n\n\nDichiarazione delle variabili\n\nLe variabili possono ora essere dichiarate in qualunque parte del\ncodice:\n\nusing namespace std;\n#include &lt;iostream&gt;\nint main ()\n{\ndouble a;\ncout &lt;&lt; \"Ciao, questo e' un programma di prova.\" &lt;&lt; endl;\ncout &lt;&lt; \"Inserisci il parametro a: \";\ncin &gt;&gt; a;\na = (a + 1) / 2;\ndouble c;        // &lt;=========== variabile appena dichiarata\nc = a * 5 + 1;\ncout &lt;&lt; \"c contiene : \" &lt;&lt; c &lt;&lt; endl;\nint i, j;        // &lt;=========== variabili appena dichiarate\ni = 0;\nj = i + 1;\ncout &lt;&lt; \"j contiene : \" &lt;&lt; j &lt;&lt; endl;\nreturn 0;\n}\n\n\nCiao, questo e' un programma di prova.\nInserisci il parametro a: 7\nc contiene              : 21\nj contiene              : 1\n\n\nE’ consigliabile usare questa caratteristica per rendere il proprio\ncodice piu’ leggibile, e non piu’ disordinato. Come nel C, le variabili\npossono essere incapsulate tramite le parentesi graffe {}. In questo\ncaso sono locali nello scope definito proprio dalle\nparentesi graffe. Quello che succede a tali variabili all’interno della\nzona incapsulata non modifica eventuali variabili con\nlo stesso nome ma che si trovano all’esterno.\n\nusing namespace std;\n#include &lt;iostream&gt;\nint main ()\n{\n  double a;\n  cout &lt;&lt; \"Inserisci un numero: \";\n  cin &gt;&gt; a;\n  {\n    int a = 1;\n    a = a * 10 + 4;\n    cout &lt;&lt; \"Numero locale: \" &lt;&lt; a &lt;&lt; endl;\n  }\n  cout &lt;&lt; \"Tu hai inserito: \" &lt;&lt; a &lt;&lt; endl;\n  return 0;\n}\n\n\nInserisci un numero: 9\nNumero locale:       14\nTu hai inserito:  9\n\n\nInizializzazione di una variabile con dei calcoli\n\nUna variabile puo’ essere inizializzata con un calcolo di altre\nvariabili, per esempio:\n\nusing namespace std;\n#include &lt;iostream&gt;\nint main ()\n{\n  double a = 12 * 3.25;\n  double b = a + 1.112;\n  cout &lt;&lt; \"a contiene: \" &lt;&lt; a &lt;&lt; endl;\n  cout &lt;&lt; \"b contiene: \" &lt;&lt; b &lt;&lt; endl;\n  \n  a = a * 2 + b;\n  double c = a + b * a;\n  cout &lt;&lt; \"c contiene: \" &lt;&lt; c &lt;&lt; endl;\n  \n  return 0;\n}\n\n\na contiene: 39\nb contiene: 40.112\nc contiene: 4855.82\n\n\nVariabile dichiarate nella dichiarazione di un loop\n\nIl C++ consente di definire delle variabili locali per un loop:\n\nusing namespace std;\n#include &lt;iostream&gt;\nint main ()\n{\n  int i;\n  i = 487;                     // dichiarazione di i\n  for (int i = 0; i &lt; 4; i++)  // dichiarazione locale di i\n  {\n     cout &lt;&lt; i &lt;&lt; endl;  // questo manda in output 0, 1, 2 e 3\n  }\n  cout &lt;&lt; i &lt;&lt; endl;     // questo invece 487\n}\nreturn 0;\n\n\n0\n1\n2\n3\n487\n\n\nNel caso in cui la variabile non sia dichiarata da qualche parte prima\ndel loop, una persona potrebbe essere tentata di usarla anche dopo il\nloop stesso. Alcuni vecchi compilatori accettano questo comportamento.\nIn quel caso la variabile mantiene l’ultimo valore che aveva alla fine\ndel loop stesso. E’ molto SCONSIGLIATO usare questo modo di programmare\n(viene considerata una bad practice) che puo’ indurre ad errori\ndifficilmente trovabili).\n\nusing namespace std;\n#include &lt;iostream&gt;\nint main ()\n  {\n   for (int i = 0; i &lt; 4; i++)\n   {\n     cout &lt;&lt; i &lt;&lt; endl;\n   }\n   cout &lt;&lt; i &lt;&lt; endl;   // bad practice\n   i += 5;              // bad practice\n   cout &lt;&lt; i &lt;&lt; endl;   // bad practice \n\n   return 0;\n}\n\n\nt.cpp: In function ‘int main()’:\nt.cpp:12: error: name lookup of ‘i’ changed for new ISO ‘for’ scoping\nt.cpp:7: error: using obsolete binding at ‘i’\n\n\nAccesso alle variabili globali, anche se delle variabili locali hanno lo stesso nome\n\nSi puo’ accedere ad una variabile globale anche se all’interno di una\nfunzione si e’ dichiarata un’altra variabile con lo stesso nome.\n\nusing namespace std;\n#include &lt;iostream&gt;\ndouble a = 128;\nint main ()\n  {\n  double a = 256;\n  cout &lt;&lt; \"Local a: \" &lt;&lt; a &lt;&lt; endl;\n  cout &lt;&lt; \"Global a: \" &lt;&lt; ::a &lt;&lt; endl;  // nota l'operatore :: \n  return 0;\n} \n\n\nLocal a: 256\nGlobal a: 128 \n\n\nE’ possibile dichiarare una REFERENZA ad un’altra variabile\n\nE’ possibile dichiarare una REFERENZA ad un’altra variabile. In pratica\nquesto fa si’ che una variabile diventi un’altra variabile, e quindi\nsiano collegate tra loro (si usa per questo il simbolo di refereziazione\n&amp;). Detto in altri termini, si costruisce un altro nome della stessa\nvariabile.\n\nusing namespace std;\n#include &lt;iostream&gt;\nint main ()\n{\n  double a = 3.1415927;\n  double &amp;b = a;                        // b e' un altro nome per a!\n  b = 89;\n  cout &lt;&lt; \"a contiene: \" &lt;&lt; a &lt;&lt; endl;  // mostra 89\n  return 0;\n} \n\n\na contiene: 89 \n\n\nSe sei abituato ai puntatori e vuoi assolutamente sapere cosa succede,\nsemplicemente pensalo in questo modo:\n\ndouble &amp;b  = a =&gt; double *b= &amp;a e tutti i successivi b sono\nrimpiazzati da *b\\\nSe si e’ creata una referenza da una variabile ad un altra, questo non\npuo’ poi essere modificato nel seguito del codice per collegare la\nvariabile ad una nuova variabile. Per esempio non e’ possibile scrivere,\npoche linee dopo, &amp;b=c ed aspettarci che ora b sia c. Non funziona. La\ndichiarazione iniziale definisce una volta per tutte b. La b e a sono\nsposate per sempre e nulla le separera’.\n\nLe referenze possono essere usate per consentire ad una\nfunzione di modificare una variabile chiamante:\n\nusing namespace std;\n#include &lt;iostream&gt;\nvoid change (double &amp;r, double s)\n  {\n  r = 100;\n  s = 200;\n  }\nint main ()\n  {\n  double k, m;\n  k = 3;\n  m = 4;\n  change (k, m);\n  cout &lt;&lt; k &lt;&lt; \", \" &lt;&lt; m &lt;&lt; endl;  // mostra 100, 4\n  return 0;\n}\n\n\n100, 4 \n\n\nChiaramente lo stesso risultato poteva essere ottenuto tramite i\npuntatori in C, in particolare il compilatore C++, se si dovesse\ntradurre questo codice in C, scriverebbe:\n\nusing namespace std;\n#include &lt;iostream&gt;\nvoid change (double *r, double s)\n  {\n  *r = 100;      \n   s = 200;\n  }\nint main ()\n  {\n  double k, m;\n  k = 3;\n  m = 4;\n  change (&amp;k, m);       \n  cout &lt;&lt; k &lt;&lt; \", \" &lt;&lt; m &lt;&lt; endl; // mostra 100, 4\n  return 0;\n} \n\n\n100, 4 \n\n\nUna referenza puo’ essere usata per consentire ad una funzione di\nrestituire una variabile:\n\nusing namespace std;\n#include &lt;iostream&gt;\ndouble &amp;maggiore (double &amp;r, double &amp;s) // nota l'operatore &amp; prima di maggiore\n{\n   if (r &gt; s) return r;\n   else\n   return s;\n}\nint main ()\n{\n   double k = 3;\n   double m = 7;\n   \n   cout &lt;&lt; \"k: \" &lt;&lt; k &lt;&lt; endl;   // mostra 3\n   cout &lt;&lt; \"m: \" &lt;&lt; m &lt;&lt; endl;   // mostra 7\n   cout &lt;&lt; endl;\n   \n   maggiore (k, m) = 10;    // ho assegnato un valore alla funzione\n   \n   cout &lt;&lt; \"k: \" &lt;&lt; k &lt;&lt; endl;   // mostra  3\n   cout &lt;&lt; \"m: \" &lt;&lt; m &lt;&lt; endl;   // mostra 10\n   cout &lt;&lt; endl;\n\n   maggiore (k, m) ++;     // aggiungo uno al valore della funzione \n                           //   (dopo averla chiamata)\n                           \n   cout &lt;&lt; \"k: \" &lt;&lt; k &lt;&lt; endl;  // mostra  3\n   cout &lt;&lt; \"m: \" &lt;&lt; m &lt;&lt; endl;  // mostra 11\n   cout &lt;&lt; endl;\n\n  return 0;\n} \n\n\nk: 3\nm: 7\n\nk: 3\nm: 10\n\nk: 3\nm: 11\n\n\nAncora una volta, se si e’ abituati ai puntatori del C e si domanda come\nquesta notazione funzioni, basta immaginare che il compilatore traduca\nquanto scritto sopra nel seguente codice C standard:\n\nusing namespace std;\n#include &lt;iostream&gt;\ndouble *maggiore (double *r, double *s)\n{\n  if (*r &gt; *s) return r;\n  else\n return s;\n}\nint main ()\n{\n  double k = 3;\n  double m = 7;\n  \n  cout &lt;&lt; \"k: \" &lt;&lt; k &lt;&lt; endl;\n  cout &lt;&lt; \"m: \" &lt;&lt; m &lt;&lt; endl;\n  cout &lt;&lt; endl;\n  \n  (*(maggiore (&amp;k, &amp;m))) = 10;\n  \n  cout &lt;&lt; \"k: \" &lt;&lt; k &lt;&lt; endl;\n  cout &lt;&lt; \"m: \" &lt;&lt; m &lt;&lt; endl;\n  cout &lt;&lt; endl;\n  \n  (*(maggiore (&amp;k, &amp;m))) ++;\n  \n  cout &lt;&lt; \"k: \" &lt;&lt; k &lt;&lt; endl;\n  cout &lt;&lt; \"m: \" &lt;&lt; m &lt;&lt; endl;\n  cout &lt;&lt; endl;\n  return 0;\n}\n\n\nk: 3\nm: 7\n\nk: 3\nm: 10\n\nk: 3\nm: 11\n\n\nPer finire, per le persone che non amano i puntatori ma devono\ninteragire con essi, le referenze possono essere utili\nper in pratica fare un “un-pointer” delle variabili. Attenzione che\nquesto tipo di azione puo’ essere considerata una “bad practice” e puo’\ncreare problemi. Vedasi l’esempio:\n\nhttps://www.embedded.com/electronics-blogs/programming-pointers/4023307/References-vs-Pointers\n\nusing namespace std;\n#include &lt;iostream&gt;\ndouble *silly_function ()  // questa funzione restituisce un puntatore ad un double\n{\n  static double r = 342;\n  return &amp;r;\n}\nint main ()\n{\n  double *a;\n  a = silly_function();\n  double &amp;b = *a;   // ora b e' il double verso cui punta!\n\n  b += 1;           // ottimo!\n  b = b * b;        // non c'e' bisogno di scrivere *a ovunque! \n  b += 4;\n\n  cout &lt;&lt; \"Contenuto di *a, b and r: \" &lt;&lt; b &lt;&lt; endl;\n  return 0;\n}\n\n\ncontenuto di *a, b e r: 117635 \n\n\nE’ possibile dichiarare dei namespace\n\nSi possono dichiarare dei namespace. Le variabili dichiarate entro un\nnamespace possono essere usate tramite l’operatore ::\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nnamespace first\n{\n  int a;\n  int b;\n}\n\nnamespace second\n{\n  double a;\n  double b;\n}\n\nint main ()\n{\n   first::a = 2;\n   first::b = 5;\n   second::a = 6.453;\n   second::b = 4.1e4;\n   cout &lt;&lt; first::a + second::a &lt;&lt; endl;\n   cout &lt;&lt; first::b + second::b &lt;&lt; endl;\n\n   return 0;\n} \n\n\n 8.453\n 41005\n\n\nUna funzione puo’ essere dichiarata inline\n\nSe una funzione contiene semplici linee di codice e non contiene\nfor loop o simili, allora puo’ essere dichiarata\ninline. Questo implica che il codice della funzione\nstessa, al momento della compliazione, verra’ inserito in tutti i luoghi\ndove essa viene usata. In pratica diventa simile ad una macro. Il\nvantaggio principale e’ che il codice diventa piu’ veloce. Come piccolo\ndifetto c’e’ il fatto che l’eseguibile diventera’ un po’ piu’ grande\nperche’ tutte le linee della funzione verranno ripetute ovunque venga\nchiamata.\n\n \nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\ninline double ipotenusa (double a, double b)\n{\n   return sqrt (a * a + b * b);\n}\nint main ()\n{\n   double k = 6, m = 9;\n// le seguenti due linee producono esattamente lo stesso eseguibile:\n \n   cout &lt;&lt; ipotenusa (k, m) &lt;&lt; endl;\n   cout &lt;&lt; sqrt (k * k + m * m) &lt;&lt; endl;\n\n   return 0;\n} \n\n\n10.8167\n10.8167\n\n\nE’ stata aggiunta la struttura exception\n\nOltre alle classiche strutture di controllo del C: for, if, do,\nwhile, switch… nel C++ viene inserita una nuova struttura\nchiamata exception:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nint main ()\n{\n   int a, b;\n   cout &lt;&lt; \"inserisci un numero: \";\n   cin &gt;&gt; a;\n   cout &lt;&lt; endl;\n   try\n   {\n       if (a &gt; 100) throw 100;\n       if (a &lt; 10) throw 10;\n       throw a / 3;\n   }\n   catch (int risultato)\n   {\n       cout &lt;&lt; \"il risultato e' : \" &lt;&lt; risultato &lt;&lt; endl;\n       b = risultato + 1;\n   }\n   cout &lt;&lt; \"b contiene: \" &lt;&lt; b &lt;&lt; endl;\n   cout &lt;&lt; endl;\n   \n   // un altro esempio dell'uso di exception:\n   \n   char zero [] = \"zero\";\n   char pair [] = \"pari\";\n   char notprime [] = \"non primo\";\n   char prime [] = \"primo\";\n   \n   try\n   {\n       if (a == 0) throw zero;\n       if ((a / 2) * 2 == a) throw pair;\n       for (int i = 3; i &lt;= sqrt (a); i++)\n       {\n          if ((a / i) * i == a) throw notprime;\n       }\n       throw prime;\n   }\n   catch (char *conclusion)\n   {\n       cout &lt;&lt; \"il numero che hai inserito e' \"&lt;&lt; conclusion &lt;&lt; endl;\n   }\n   \n   cout &lt;&lt; endl;\n   return 0;\n} \n\n\n Inserisci un numero: 5\n \n il risultato e': 10\n b  contiene: 11\n \n il numero che hai inserito e' primo\n\n\nE’ possibile definire valori di default per gli argomenti delle funzioni\n\nusing namespace std;\n#include &lt;iostream&gt;\ndouble test (double a, double b = 7)  // se non sepcificato, b=7\n{\n  return a - b;\n}\nint main ()\n{\n   cout &lt;&lt; test (14, 5) &lt;&lt; endl;  // mostra a video 14 - 5\n   cout &lt;&lt; test (14) &lt;&lt; endl;     // mostra a video 14 - 7\n}\nreturn 0;\n \n\n\n 9\n 7\n\n\nOverload delle funzioni\n\nUn notevole vantaggio del C e’ la possibilita’ di fare\nl’overload delle funzioni. Questo significa che\nfunzioni differenti possono avere lo stesso nome, basta\nche ci sia qualcosa che consenta al compilatore di distinguerle in modo\nunivoco, per esempio: il numero di parametri, il\ntipo dei parametri,…\n\nusing namespace std;\n#include &lt;iostream&gt;\ndouble test (double a, double b) // questa funzione prende 2 double e li somma\n{\n  return a + b;\n}\nint test (int a, int b)     // questa, invece, prende 2 interi e li sottrae\n{                           // ma ha lo stesso nome, \"test\", di quella che somma\n  return a - b;\n}\nint main ()\n{\n   double   m = 7,   n = 4;\n   int      k = 5,   p = 3;\n   cout &lt;&lt; test(m, n) &lt;&lt; \" , \" &lt;&lt; test(k, p) &lt;&lt; endl;\n   return 0;\n} \n\n\n11, 2 \n\n\nOverload di operatori (+-*/…) per il loro utilizzo con nuovi tipi di dato\n\nL’overload di operatori puo’ essere usato per ridefinire dei simboli di\nbase per lavorare con nuovi tipi di parametri:\n\nusing namespace std;\n#include &lt;iostream&gt;\nstruct vettore   // creo l'oggetto vettore\n{\n   double x;\n   double y;\n};\n \nvettore operator * (double a, vettore b)  // \n{               // fa prodotto PER uno scalare e un vettore 2D\n   vettore r;        \n   r.x = a * b.x;\n   r.y = a * b.y;\n   return r;                            \n}\n\nint main ()\n{\n   vettore k, m;       // Non c'e' bisogno di scrivere \"struct vettore\"\n   k.x = 2;            // per essere in grado di scrivere\n   k.y = -1;           // k = vettore (2, -1)\n                       // vedi il Cap 19.\n   m = 3.1415927 * k;  // Magia!\n   \n   cout &lt;&lt; \"(\" &lt;&lt; m.x &lt;&lt; \", \" &lt;&lt; m.y &lt;&lt; \")\" &lt;&lt; endl;\n   return 0;\n} \n\n\n (6.28319, -3.14159)\n\n\nOltre all’operatore di moltiplicazione (*), in C++ ci sono altri 43\noperatori di base di cui si puo’ fare overload, tra cui ci sono\n+=, ++, l’array [], e cosi’ via…\n\nTramite un overload, l’operatore &lt;&lt; normalmente impiegato per lo\nshifting binario di interi, puo’ portare all’output di uno stream (per\nesempio cout «. E’ possibile fare ulteriori overload\ndell’operatore &lt;&lt;, per l’output di nuovi tipi, come i vettori:\n\nusing namespace std;\n#include &lt;iostream&gt;\nstruct vettore\n{\n  double x;\n  double y;\n};\nostream&amp; operator &lt;&lt; (ostream&amp; o, vettore a)  // tipo in uscita e' un ostream\n{\n   o &lt;&lt; \"(\" &lt;&lt; a.x &lt;&lt; \", \" &lt;&lt; a.y &lt;&lt; \")\";\n   return o;\n}\nint main ()\n{\n  vettore a;\n  a.x = 35;\n  a.y = 23;\n  cout &lt;&lt; a &lt;&lt; endl;  // mostra a video (35,23)\n  return 0;\n} \n\n\n(35,23)\n\n\nTemplate: funzioni indipendenti dal tipo\n\nStanchi di definire la stessa funzione 5 volte? Una definizione per\nparametri di tipo int, una nuova definizione per\nparametri di tipo double, una per i\nfloat… Non ti sarai dimenticato un tipo? E se dovessi\nusare la stessa funzione con un nuovo tipo? Nessun problema il\ncompilatore C++ puo’ generare automaticamente tutte le versioni delle\nfunzioni che siano necessarie! Basta specificare come e’ fatta la\nfunzione dichiarando una funzione template:\n\nusing namespace std;\n#include &lt;iostream&gt;\n\ntemplate &lt;class ttype&gt;   \nttype minimo (ttype a, ttype b)\n{\n   ttype r;\n   r = a;\n   if (b &lt; a) r = b;  // gli operatori \"&lt;\" e \"=\" devono essere \n                      // definiti per tutti tipi per cui sono usati\n\n   return r;\n}   \nint main ()\n{\n   int i1, i2, i3;\n   i1 = 34;\n   i2 = 6;\n   i3 = minimo (i1, i2);\n   cout &lt;&lt; \"Piu' piccolo: \" &lt;&lt; i3 &lt;&lt; endl;\n   \n   double d1, d2, d3;\n   d1 = 7.9;\n   d2 = 32.1;\n   d3 = minimo (d1, d2);\n   cout &lt;&lt; \"Piu' piccolo: \" &lt;&lt; d3 &lt;&lt; endl;\n   \n   cout &lt;&lt; \"Piu' piccolo: \" &lt;&lt; minimo (d3, 3.5) &lt;&lt; endl;\n   \n   return 0;\n} \n\n\nPiu' piccolo: 6\nPiu' piccolo: 7.9\nPiu' piccolo: 3.5\n\n\nLa funzione minimo viene usata tre volte nel codice qui\nsopra, nondimeno il compilatore C++ genera solo 2 versioni di essa:\n\n\n  \n     int     minimo(int a   , int    b)\n  \n  \n     double  minimo(double a, double b)\n  \n\n\nQuesto e’ sufficiente per tutto il programma. Cosa sarebbe successo se\navessi provato a calcolare qualcosa del tipo\nminimo(i1,d1)? (ovvero mettendo un int come primo\ningresso e un double come secondo). Il compilatore avrebbe restituito un\nerrore. Questo perche’, nella forma scelta nell’esempio, nel\ntemplate entrambi i parametri hanno lo stesso tipo. In\ngenereale, fortunatamente, si puo’ usare un numero arbitrario di tipi\nquando si definisce un template che possono essere “tipi” standard\n(char, int, double,…) o definiti dall’utente. Qui\nsotto c’e’ un esempio dove la funzione minimo accetta parametri di\nqualunque tipo (differenti o identici tra loro) e restituisce un valore\ndi somma che ha lo stesso tipo del primo parametro:\n\nusing namespace std;\n#include &lt;iostream&gt;\ntemplate &lt;class type1, class type2&gt;  // tipe1 primo argomento, tipe2 secondo\ntype1 minimo (type1 a, type2 b)\n{\n   type1 r, b_convertito;      // dichiara un paio di oggetti di type1\n   r = a;                      // di base prende a come minimo il primo\n   b_convertito = (type1) b;   // fa un cast del secondo parametro nel tipo del primo\n   if (b_convertito &lt; a) r = b_convertito; // controlla se il secondo e' minore\n   return r;\n}\nint main ()\n{\n   int i;\n   double d;\n   i = 45;\n   d = 7.41;\n   \n   cout &lt;&lt; \"Piu' piccolo: \" &lt;&lt; minimo (i, d) &lt;&lt; endl;     // int    vs double\n   cout &lt;&lt; \"Piu' piccolo: \" &lt;&lt; minimo (d, i) &lt;&lt; endl;     // double vs int\n   cout &lt;&lt; \"Piu' piccolo: \" &lt;&lt; minimo ('A', i) &lt;&lt; endl;   // char   vs int \n\n   return 0;\n}   \n\n\nPiu' piccolo: 7\nPiu' piccolo: 7.41\nPiu' piccolo: -\n\n\n(Si noti che il codice ASCII per il carattere ’-’ e’ 45, mentre il\ncodice di ’A’ e’ 65, quindi nel caso dell’operatore &lt; tra\nchar, converte automaticamente nel corrispondente\ncodice ASCII.\n\nE’ meglio usare NEW e DELETE per alloccare e dealloccare la memoria\n\nI comandi new e delete possono essere\nusati per alloccare e dealloccare la memoria. Sono in qualche modo piu’\npuliti rispetto alle funzioni malloc e\nfree del C standard. Si noti che per gli array si usano\ninvece:\n\n\n  \n    new []\n  \n  \n    delete []\n  \n\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cstring&gt;\nint main ()\n{\ndouble *d;   // d e' una variabile il cui scopo\n             // e' di contenere l'indirizzo di\n             // memoria dove e' posto un double\n\nd = new double;  // new allocca una zona di memoria\n                 // grande abbastanza da contenere un double\n                 // e restituisce il suo indirizzo.\n                 // L'indirizzo e' qunidi messo in d.\n             \n*d= 45.3        // Il numero 45.3 e' messo \n                // nella zona di memoria, il cui\n                // indirizzo e' dato da d.\n\n\ncout &lt;&lt; \"Inserisci un numero: \";\ncin &gt;&gt; *d;\n*d = *d + 5;\ncout &lt;&lt; \"Risultato: \" &lt;&lt; *d &lt;&lt; endl;\n                \n                \ndelete d;  //  delete deallocca la zona \n           //  di memoria il cui indirizzo\n           //  e' dato dal puntatore d\n           //  quell'indirizzo non puo' piu' essere usato\n\n\n           \nd = new double[15] // allocca una zona per un array di 15 double\n                   // Nota che ognuno dei 15 double viene costruito.\n                   // In questo caso non serve, ma e' fondamentale\n                   // quando si usano dei tipi di dato\n                   // che necessitino che il loro constructor sia \n                   // usato per ogni istanza\n                   \nd[0]=4456;\nd[1]=d[0]+567;\n\ncout &lt;&lt; \"Contenuto di d[1]: \" &lt;&lt; d[1] &lt;&lt; endl;\n\ndelete [] d;       // delete [] distrugge la zona di memoria\n                   // Nota che ognuno dei 15 ingressi di tipo\n                   // double verra' distrutto. Anche in questo\n                   // caso, ora non e' importante, ma al momento in\n                   // cui verranno usati i destructor per le istanze\n                   // delle classi (il metodo ~). Se venisse usato\n                   // delete senza mettere le parentesi quadre\n                   // questo provocherebbe la dealloccazione della\n                   // zona di memoria, senza distruggere ognuna delle 15 istanze\n                   // Questo comportamento puo' causare un memory leakage.\n\nint n = 30;\nd = new double[n]; // new puo' essere usato per alloccare un array \n                   // dinamicamente, ad una grandezza n \nfor (int i = 0; i &lt; n; i++)\n{\n  d[i] = i;\n}\n                \ndelete [] d;\n\nchar *s;    \ns = new char[100];\n\nstrcpy (s, \"Ciao!\");\n\ncout &lt;&lt; s &lt;&lt; endl;\n\ndelete [] s;\n            \nreturn 0;\n}           \n\n\nInserisci un numero: 6\nRisultato: 11\nContenuto di d[1]: 5023\nCiao!\n\n\nSi possono mettere delle funzioni (metodi) in uno Struct o una Classe\n\nNel C standard, uno struct contiene solo dati. In C++,\nuno struct puo’ contenere anche delle funzioni. Queste\nfunzioni sono possedute dallo struct e sono pensate per\noperare sui dati dello struct stesso. Queste funzioni\nsono chiamate METODI. Nel seguito viene mostrato il\nmetodo superficie associato allo struct\nvettore:\n\nusing namespace std;\n#include &lt;iostream&gt;\nstruct vettore\n{\n   double x;\n   double y;\n   double superficie () // intesa come rettangolo di cui il vettore e' diagonale\n   {\n      double s;\n      s = x * y;\n      if (s &lt; 0) s = -s;\n      return s;\n   }\n};\nint main ()\n{\n   vettore a;\n   a.x = 3;\n   a.y = 4;\n \n   cout &lt;&lt; \"La superficie di a: \" &lt;&lt; a.superficie() &lt;&lt; endl;\n   return 0;\n} \n\n\nLa superficie di a: 12 \n\n\nNell’esempio qui sopra a e’ un’\nistanza dello struct “vettore”. (Si noti che il comando\n“struct” non era necessario quando si e’ dichiarato il\nvettore a).\n\nProprio come per le funzioni, un metodo puo’ essere un overload di\nqualsiasi operatore del C++, puo’ avere un numero arbitrario di\nparametri (ma uno di questi parametri e’ implicito: l’istanza su cui\nagisce), restituire qualunque tipo di parametri o nessuno (un metodo e’\nuna funzione…).\n\nClassi\n\n\n  \n    Cos’e’ una class (classe)?\n  \n  \n    Una classe e’ una struct che\nmantiene i propri dati nascosti.\n  \n  \n    solo i metodi della classe possono accedere ai dati. Non e’\npossibile accedere ai dati di una classe direttamente, a meno che\nquesti siano stati definiti tramite la direttiva:\npublic.\n  \n\n\nQui sotto c’e’ un esempio della definizione di una\nclasse, che si comporta esattamente come lo struct\nsopra perche’ i dati x e y sono\ndefiniti come public:\n\nusing namespace std;\n#include &lt;iostream&gt;\nclass vettore\n{\n   public:\n   double y;\n   double x;\n  \n   double superficie ()\n   {\n      double s;\n      s = x * y;\n      if (s &lt; 0) s = -s; \n      return s;\n   }\n};         \n\n\nint main ()\n{\n   vettore a;\n   a.x = 3;\n   a.y = 4;\n   cout &lt;&lt; \"La superficie di a: \" &lt;&lt; a.superficie() &lt;&lt; endl;\n   return 0;\n} \n\n\nLa superficie di a: 12 \n\n\nNell’esempio qui sopra, direttamente dal main e’\npossibile modificare i dati dell’istanza del vettore, usando:\n\n\n  \n    a.x=3\n  \n  \n    a.y=4\n  \n\n\nQuesto e’ stato possibile per la direttiva public:\nusata nella definizione della classe. L’uso della public e’\nconsiderata bad practice! si veda il Capitolo 30.\n\nAd un metodo e’ consentito cambiare le variabili dell’istanza su cui\nagisce:\n\nusing namespace std;\n#include &lt;iostream&gt;\nclass vettore\n{\n  public:\n  double x;    // parametri della classe (accessibili dall'esterno per il public)\n  double y;    // parametri della classe (             \"                        )\n\n  vettore costruisci_opposto() // metodo che RESTITUISCE l'opposto dell'istanza\n  {                            // nota che questo metodo ha un \"tipo\"\n     vettore r;                // e' proprio la stessa classe!  \n     r.x = -x;\n     r.y = -y;\n     return r; \n  }\n\n  void trasforma_in_opposto()    // metodo che TRASFORMA l'istanza nel suo opposto\n  {                      // e' un metodo VOID, non restituisce nulla!\n      x = -x;            // trasforma soltanto l'istanza su cui agisce \n      y = -y;\n  }\n  void da_calcolare (double a, double b, double c, double d) \n                        // metodo che MODIFICA l'istanza\n  {                     // (e' void)\n     x = a - c;         // ATTENZIONE non c'e' un return...\n     y = b - d;         // \n  }\n  \n  vettore operator * (double a) // overload del prodotto\n  {                      // occhio che non e' come un metodo normale\n     vettore r;          // in cui gli argomenti vanno messi tra tonde ()\n     r.x = x * a;        // l'istanza della classe va messa prima del *  \n     r.y = y * a;        // il double va messo dopo. NON si usano le parentesi\n     return r;           // crea una NUOVA istanza  \n  }\n};\n\nint main ()\n{\n   vettore a, b;\n   a.x = 3;\n   a.y = 5;\n   b = a.costruisci_opposto();\n   \n   cout &lt;&lt; \"Vector a: \" &lt;&lt; a.x &lt;&lt; \", \" &lt;&lt; a.y &lt;&lt; endl;\n   cout &lt;&lt; \"Vector b: \" &lt;&lt; b.x &lt;&lt; \", \" &lt;&lt; b.y &lt;&lt; endl;\n   \n   b.trasforma_in_opposto();\n   cout &lt;&lt; \"Vector b: \" &lt;&lt; b.x &lt;&lt; \", \" &lt;&lt; b.y &lt;&lt; endl;\n \n   a.da_calcolare (7, 8, 3, 2);\n   cout &lt;&lt; \"Vector a: \" &lt;&lt; a.x &lt;&lt; \", \" &lt;&lt; a.y &lt;&lt; endl;\n   a = b * 2;     // questo e' istruttivo, avendo fatto\n                  //l'OVERLOAD del *, il primo ingresso\n                  //sara' un vettore, il secondo un double\n                  // che era tra parentesi nella definizione del\n                  // metodo. Nessuno degli \"ingressi\" dell'\n                  // operatore, va messo tra parentesi (), si\n                  // continua ad usare il * come al solito\n   \n   cout &lt;&lt; \"Vector a: \" &lt;&lt; a.x &lt;&lt; \", \" &lt;&lt; a.y &lt;&lt; endl;\n   a = b.costruisci_opposto() * 2;\n   \n   cout &lt;&lt; \"Vector a: \" &lt;&lt; a.x &lt;&lt; \", \" &lt;&lt; a.y &lt;&lt; endl;\n   cout &lt;&lt; \"x dell'opposto di a: \" &lt;&lt; a.trasforma_in_opposto().x &lt;&lt; endl;\n   \n   return 0;\n} \n\n\nVector a: 3, 5\nVector b: -3, -5\nVector b: 3, 5\nVector a: 4, 6\nVector a: 6, 10\nVector a: -6, -10\nx dell'opposto di a: 6 \n\n\nConstructor e destructor: inizializzare e distruggere istanze di una classe\n\nEsistono dei metodi speciali ed essenziali che sono i:\n\n\n  \n    constructor (costruttore)\n  \n  \n    destructor (distruttore)\n  \n\n\nQuesti metodi vengono chiamati automaticamente nei seguenti casi:\n\n\n  \n    al momento di creazione di un’istanza della classe (p.es. con un\nnew)\n  \n  \n    al momento di distruzione di un’istanza della classe (con un\ndelete)\n  \n  \n    alla fine del programma\n  \n  \n    …\n  \n\n\nIl costruttore (constructor) (e’ un metodo con lo\nstesso nome della classe):\n\n\n  \n    inizializzera’ le variabili dell’istanza\n  \n  \n    fara’ dei calcoli (definiti nella classe)\n  \n  \n    allocchera’ della memoria\n  \n  \n    mandera’ a video delle scritte\n  \n  \n    …\n  \n\n\nIn generale il costruttore viene scritto per fare tutto quello che e’\nnecessario per la classe. Nel seguito vediamo un esempio della\ndefinizione di una classe con due costruttori di cui viene fatto\nl’overload (sono funzioni… quindi si puo’ fare l’overload dei\ncostruttori):\n\nusing namespace std;\n#include &lt;iostream&gt;\nclass vettore\n{\n   public:\n   double x;\n   double y;\n\n   vettore ()  // questo e' un costruttore, lo si riconosce \n   {          // perche' ha lo stesso NOME della classe\n      x = 0;  // se viene fatta una istanza senza indicare\n      y = 0;  // le componenti, questo le mette a 0 di default\n   }\n\n   vettore (double a, double b) // anche questo e' un costruttore \n   {                           // ed e' un overload, perche' questo\n       x = a;                  // viene chiamato con 2 argomenti  \n       y = b;                  // in particolare 2 double\n   }                           // che diventeranno le componenti \n};\n\nint main ()\n{\n   vettore k;            // il costruttore vettore () viene chiamato\n   cout &lt;&lt; \"vettore k: \" &lt;&lt; k.x &lt;&lt; \", \" &lt;&lt; k.y &lt;&lt; endl &lt;&lt; endl;\n   \n   vettore m (45, 2);    // qui viene chiamato vettore (double, double)\n   cout &lt;&lt; \"vettore m: \" &lt;&lt; m.x &lt;&lt; \", \" &lt;&lt; m.y &lt;&lt; endl &lt;&lt; endl;\n   \n   k = vettore (23, 2); // viene creato un vettore, copiato  in k,\n                        // e poi cancellato \n                        // perche' viene cancellato? perche' finisce l'esecuzione\n   cout &lt;&lt; \"vettore k: \" &lt;&lt; k.x &lt;&lt; \", \" &lt;&lt; k.y &lt;&lt; endl &lt;&lt; endl;\n   \n   return 0;\n}\n\n\nvettore k: 0, 0\n\nvettore m: 45, 2\n\nvettore k: 23, 2 \n\n\nLa buona pratica di scrittura di un codice suggerisce di non fare\nl’overload dei costruttori. Sarebbe meglio dichiarare solo un\ncostruttore e dargli dei valori di default quando possibile.\n\nusing namespace std;\n#include &lt;iostream&gt;\nclass vettore\n{\n   public:\n   double x;\n   double y;\n   \n   vettore (double a = 0, double b = 0)\n   {\n      x = a;\n      y = b;\n   }\n};\n\nint main ()\n{\n   vettore k;\n   cout &lt;&lt; \"vettore k: \" &lt;&lt; k.x &lt;&lt; \", \" &lt;&lt; k.y &lt;&lt; endl &lt;&lt; endl;\n\n   vettore m (45, 2);\n   cout &lt;&lt; \"vettore m: \" &lt;&lt; m.x &lt;&lt; \", \" &lt;&lt; m.y &lt;&lt; endl &lt;&lt; endl;\n   \n   vettore p (3);\n   cout &lt;&lt; \"vettore p: \" &lt;&lt; p.x &lt;&lt; \", \" &lt;&lt; p.y &lt;&lt; endl &lt;&lt; endl;\n   return 0;\n}   \n\n\nvettore k: 0, 0\n\nvettore m: 45, 2\n\nvettore p: 3, 0 \n\n\nIl distruttore e’ spesso non necessario. Puo’ essere usato per fare dei\ncalcoli quando l’istanza viene distrutta o per mandare a video dei testi\nper il debug. Se pero’ le variabili dell’istanza puntano a qualche area\ndi memoria alloccata, allora il ruolo del distruttore e’ essenziale:\ndeve liberare la memoria! Qui vediamio un esempio di un\ntale utilizzo:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cstring&gt;\nclass persona\n{\n   public:\n   char *name;\n   int anni;\n   persona (char *n = \"nessun nome\", int a = 0)  // costruttore\n   {\n      nome = new char [100];  // new e' meglio di malloc!\n      strcpy (name, n);\n      anni = a;\n      cout &lt;&lt; \"Instanza inizializzata, 100 bytes allocati\" &lt;&lt; endl;\n   }\n   ~persona ()  // DISTRUTTORE, c'e' la ~ davanti al nome!\n   {\n       delete [] nome; // invece che un semplice free, uso delete\n                       // si noti che potrebbe funzionare con un\n                       // semplice delete senza  le [], questo \n                       // perche' l'array non contiene C++ sub-oggetti\n                       // che debbano essere cancellati. Pero', visto che\n                       // il comportamento senza le [] non e' definito, e'\n                       // meglio andare sul sicuro e mettere le quadre.\n\n       cout &lt;&lt; \"L'istanza viene rimossa, 100 byte vengono liberati\" &lt;&lt; endl;\n   }\n};        // fine della definizione della classe\n\n\n\nint main ()\n{\n   cout &lt;&lt; \"Ciao!\" &lt;&lt; endl &lt;&lt; endl;\n   persona a;\n   \n   cout &lt;&lt; a.nome &lt;&lt; \", anni \" &lt;&lt; a.anni &lt;&lt; endl &lt;&lt; endl;\n   persona b (\"John\");\n   \n   cout &lt;&lt; b.nome &lt;&lt; \", anni \" &lt;&lt; b.anni &lt;&lt; endl &lt;&lt; endl;\n                       \n   b.anni = 21;\n   cout &lt;&lt; b.nome &lt;&lt; \", anni \" &lt;&lt; b.anni &lt;&lt; endl &lt;&lt; endl;\n   \n   persona c (\"Miki\", 45);\n   \n   cout &lt;&lt; c.nome &lt;&lt; \", anni \" &lt;&lt; c.anni &lt;&lt; endl &lt;&lt; endl;\n   cout &lt;&lt; \"Ciao ciao!\" &lt;&lt; endl &lt;&lt; endl;\n   \n   return 0;\n}\n \n\n\nCiao!\n\nL'istanza viene inizializzata, 100 byte allocati\nnessun nome, anni 0\n\nL'istanza viene inizializzata, 100 byte allocati\nJohn, anni 0\n\nJohn, anni 21\n\nL'istanza viene inizializzata, 100 byte alloccati\nMiki, anni 45\n\nCiao ciao!\n\nL'istanza viene rimossa, 100 byte vengono liberati\nL'istanza viene rimossa, 100 byte vengono liberati\nL'istanza viene rimossa, 100 byte vengono liberati\n\n\nQui invece verra’ mostrato un breve esempio di una definizione di una\nclasse chiamata “array”. C’e’ poi un metodo che e’ un overload\ndell’operatore [] e restituisce come valore una\nreferenza (&amp;) ed e’ usato per generare un errore se si\ntenta di accedere a dati al di fuori dei limiti dell’array.\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cstdlib&gt;\nclass array\n{\n   public:\n   int size;\n   double *data;\n   array (int s)\n   {\n      size = s;\n      data = new double [s];\n   }\n   ~array ()\n   {\n      delete [] data;\n   }\n   \n   double &amp;operator [] (int i) // overload dell'operatore []\n   {                           // restituisce un double \n      if (i &lt; 0 || i &gt;= size)  // ha come parametro di ingresso un intero\n      {\n          cerr &lt;&lt; endl &lt;&lt; \"Fuori dai limiti\" &lt;&lt; endl;\n          exit (EXIT_FAILURE);\n      }\n      else return data [i];\n   }\n};\n\n\nint main ()\n{\n   array t (5);         // OK\n   t[0] = 45;           // Ok\n   t[4] = t[0] + 6;     // Ok \n   \n   cout &lt;&lt; t[4] &lt;&lt; endl;\n   \n   t[10] = 7;           // ERRORE!\n    \n   return 0;\n}\n \n\n\n 51\n \n Fuori dai limiti\n\n\nCOPY constructor e l’overload dell’operatore “=” per copiare istanze\n\nSe si copia un oggetto come un vettore, non c’e’ nessun problema. Per\nesempio, se si ha il vettore k, di coordinate\n(4,7), dopo averlo copiato m=k, il\nvettore m conterra’ anche lui coordinate\n(4,7). I valori di k.x e\nk.y sono stati semplicemente copiati in\nm.x e m.y.\n\nSupponiamo ora che si stia usando un oggetto come la classe\npersona definita precedentemente. Questo tipo di\noggetti contiene un puntatore ad una stringa di\ncaratteri. Se si fa la copia dell’oggetto persona\nscrivendo p=r diventa necessario che qualche funzione\nsi incarichi di produrre una copia corretta da p a\nr. Altrimenti, p.nome puntera’ alla\nstessa stringa di r.nome.\n\nInoltre la precedente stringa puntata da p.nome e’\npersa e diventa un o zombi di memoria. Il risultato sarebbe\ncatastrofico, un disastro di puntatori e dati persi. I metodi che\nrisolvono questo tipo di problemi sono:\n\n\n  \n    COPY constructor\n  \n  \n    un overload dell’operatore =\n  \n\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cstring&gt;\nclass persona\n{\n   public:\n   char *name;\n   int anni;\n   persona (char *n = \"nessun nome\", int a = 0)  // costruttore\n   {\n      name = new char[100];\n      strcpy (name, n);\n      anni = a;\n   }\n   \n   persona (const persona &amp;s)  // l'argomento di constructor e' un oggetto \n   {                           // di tipo \"persona\"\n      name = new char[100];    // allocca della nuova memoria\n      strcpy (name, s.nome); // copia il nome dell'oggetto passato come nuovo nome\n      anni = s.anni;    // mette come eta' quella della \"persona\" in argomento  \n   }\n   \n   persona&amp; operator= (const persona &amp;s) // overload dell' =, restituisce \n   {                                     // un oggetto di tipo persona e prende\n      strcpy (name, s.nome);             // come argomento un oggetto persona\n      anni = s.anni;                     // associa l'eta' dell'argomento\n      return *this;                // restituisce l'istanza appena costruita\n    }\n    \n    ~persona ()  // DISTRUTTORE\n    {\n       delete [] name;            // l'unica quantita' alloccata era per il nome\n    }\n};            \n\n\nvoid modifica_persona (persona&amp; h)  // nota che questa e' una funzione\n                                    // NON e' un metodo!\n{                                  \n   h.anni += 7;               // semplicemente modifica la \"persona\" passata\n}\n\npersona calcola_persona (persona h) \n{                                     \n   h.anni += 7;\n   return h;\n}\n\n \nint main ()\n{\n   persona p;\n   cout &lt;&lt; p.nome &lt;&lt; \", anni \" &lt;&lt; p.anni &lt;&lt; endl &lt;&lt; endl;\n   // output: nessun nome, anni 0\n   \n   persona k (\"John\", 56);\n   cout &lt;&lt; k.nome &lt;&lt; \", anni \" &lt;&lt; k.anni &lt;&lt; endl &lt;&lt; endl;\n   // output: John, anni 56\n   \n   p = k;\n   cout &lt;&lt; p.nome &lt;&lt; \", anni \" &lt;&lt; p.anni &lt;&lt; endl &lt;&lt; endl;\n   // output: John, anni 56\n   \n   p = persona (\"Bob\", 10);\n   cout &lt;&lt; p.nome &lt;&lt; \", anni \" &lt;&lt; p.anni &lt;&lt; endl &lt;&lt; endl;\n   // output: Bob, anni 10 \n   \n   // Ne il copy constructor ne l'overload \n   // dell' = sono necessari per l'operazione che modifica \n   // p dato (che faremo qui sotto) che solo la referenza verso p\n   // e' passata alla funzione modifica_persona   \n   modifica_persona (p);\n   \n   cout &lt;&lt; p.nome &lt;&lt; \", anni \" &lt;&lt; p.anni &lt;&lt; endl &lt;&lt; endl;\n   // output: Bob, anni 17\n   \n   // Il copy constructor e' chiamato per passare una\n   // copia completa di p alla funzione calcola_persona.\n   // La funzione usa quella copia per fare i suoi calcoli\n   // poi una copia di quella copia modificata viene fatta per \n   // restituire i risultati. In fine l'overload dell'=\n   // viene chiamato per incollare la seconda copia dentro k\n   \n   k = calcola_persona (p);\n   cout &lt;&lt; p.nome &lt;&lt; \", anni \" &lt;&lt; p.anni &lt;&lt; endl &lt;&lt; endl;\n   // output: Bob, anni 17\n   \n   cout &lt;&lt; k.nome &lt;&lt; \", anni \" &lt;&lt; k.anni &lt;&lt; endl &lt;&lt; endl;\n   // output: Bob, anni 24\n   \n   return 0;\n}\n\n\nnessun nome, anni 0\n\nJohn, anni 56\n\nJohn, anni 56\n\nBob, anni 10\n\nBob, anni 17\n\nBob, anni 17\n\nBob, anni 24\n\n\nIl copy constructor consente al programma di fare copie delle istanze\nquando ci sono dei calcoli. E’ un metodo chiave. Durante i calcoli, le\nistanze sono create per mantenere i riultati intermedi. Sono modificate,\ncopiate e distrutte senza che il programmatore lo noti. Questo e’ il\nmotivo per cui questi metodi sono utili anche per oggetti semplici (vedi\nCapitolo 14).\n\nIn tutti gli esempi sopra, i metodi sono definiti all’interno delle\ndefinizioni delle classi. Questo implica che sono automaticamente dei\nmetodi inline.\n\nPrototipi: definire i metodi sotto la definizione di una classe\n\nConsideriamo i seguenti casi:\n\n\n  \n    se un metodo non puo’ essere inline (per esempio perche’ ha un loop\nal suo interno)\n  \n  \n    se non si vuole che il metodo diventi inline (per non ingrandire\ntroppo l’eseguibile)\n  \n  \n    se si vuole che la definizione di una classe contenga solo un\n“riassunto” dei metodi in modo che sia leggibile\n  \n  \n    se, semplicemente, si vuole separare l’header file .h dal sorgente\n.cpp\n  \n\n\nallora:\n\n\n  \n    nella classe si inserisce solo il prototipo\n(prototype) del metodo\n  \n  \n    il metodo stesso va definito sotto la definizione\ndella classe stessa o in un file sorgente .cpp separato\n  \n\n\nusing namespace std;\n#include &lt;iostream&gt;\nclass vettore\n{\n   public:\n   double x;\n   double y;\n\n   double superficie(); // il ; e il fatto che non ci siano {} mostra che e' un prototipo\n};                      // &lt;=== fine della definizione della classe \n\n\ndouble vettore::superficie()  // qui sotto definisco esplicitamente il metodo\n{\n   double s = 0;\n   for (double i = 0; i &lt; x; i++)\n   {\n      s = s + y;  // e' una specie di modo per fare il prodotto\n   }\n   return s;\n}\n\n\nint main ()\n{\n   vettore k;\n   k.x = 4;\n   k.y = 5;\n   \n   cout &lt;&lt; \"Superficie: \" &lt;&lt; k.superficie() &lt;&lt; endl;\n   return 0;\n}\n\n\nSuperficie: 20 \n\n\nPer chi e’ alle prime armi\n\nSe volete sviluppare un codice C o C++ serio, avete bisogno di separare\nil file sorgente in:\n\n\n  \n    uno (o piu’) file header .h\n  \n  \n    uno (o piu’) file sorgente .cpp\n  \n\n\nQui c’e’ un breve esempio di come questo viene fatto. Il programma qui\nsopra viene diviso in 3 file:\n\n\n  \n    vettore.h contenente la classe e i prototipi dei\nmetodi\n  \n  \n    vettore.cpp dove vengono definiti i metodi della\nclasse vettore\n  \n  \n    main.cpp dov c’e’ il main\n  \n\n\nil file header vettore.h e’:\n\nclass vettore\n{\n   public:\n   double x; \n   double y;\n\n   double superficie();\n}; \n\n\nIl file sorgente vettore.cpp:\n\nusing namespace std;\n#include \"vettore.h\"\ndouble vettore::superficie()\n{\n   double s = 0;\n   for (double i = 0; i &lt; x; i++)\n   {\n      s = s + y;\n   }\n   return s;\n}\n\n\ned infine un nuovo file sorgente chiamato main.cpp\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include \"vettore.h\"\nint main ()\n{\n   vettore k;\n   k.x = 4;\n   k.y = 5;\n   cout &lt;&lt; \"Superficie: \" &lt;&lt; k.superficie() &lt;&lt; endl;\n   return 0;\n} \n\n\nSe si assume che il file vettore.cpp sia perfetto,\nallora abbiamo bisogno di compliarlo una volta sola in un file\n.o (un “object file”), tramite il comando (per\nesempio):\n\ng++ -c vettore.cpp\n\n\n(che produce un file vettore.o).\n\nOgni volta che il file main.cpp viene modifcato, va\ncompilato in un file eseguibile, per esempio chiamato\ntest20, per fare questo bisogna dire esplicitamente al\ncompilatore che deve “linkare” l’oggetto vettore.o\nall’interno dell’esegubile test20:\n\ng++ main.cpp vettore.o -o test20 \n\n\nL’eseguibile (su macchine tipo Unix) viene fatto “girare” con:\n\n ./test20\n\n\nQuesto procedimento ha un certo numero di vantaggi:\n\n\n  \n    Il codice sorgente vettore.cpp deve essere compilato solo una\nvolta. Questo fa risparmiare molto tempo nei progetti grandi (fare\nil “linking” del file vettore.o nell’eseguibile test20 e’\nmolto veloce).\n  \n  \n    E’ possibile passare i file .h e i .o. In questo modo possono\nusare il tuo programma ma non cambiarlo perche’ non hanno i file\n.cpp (non fidarti molto di questo, aspetta fino a quando avrai una\ncomprensione piena di questi problemi).\n  \n\n\nSi noti che e’ possibile compilare anche il file main.cpp in un file\ndi tipo “object” e poi linkarlo con vettore.o:\n\n g++ -c main.cpp\n \n g++ main.o vettore.o test20\n\n\nMAKEFILE\n\nQui viene fatta una digressione rispetto all’argomento “differenze tra C\ne C++”. Se si vuole apparire come veri programmatori, si dovrebbe\ncondensare i comandi qui sopra in un Makefile e compilare usando il\ncomando make. Il contenuto del file sotto e’ una versione super\nsemplificata di un tale Makefile. Prova a copiarlo in un file chiamato\nproprio Makefile. Attenzione nota che, ed e’ molto importante, lo\nspazio tra i comandi del g++ deve obbligatoriamente\nessere un Tab. Non usare lo spazio, usa invece il carattere di\ntabulazione (tutto a sinistra di una tastiera internazionale sopra il\ncaps lock).\n\ntest20: main.o vettore.o\n        g++ main.o vettore.o -o test20\n        \nmain.o: main.cpp vettore.h\n        g++ -c main.cpp\n        \nvettore.o: vettore.cpp vettore.h\n          g++ -c vettore.cpp\n\n\nPer utilizzare questo Makefile per compilare, e’ sufficiente usare\nquesto comando:\n\nmake test20\n\n\nIl comando make fara’ un “parse” (legge i comandi parola per\nparola) attraverso il Makefile e capira’ quello che deve essere fatto.\nAll’inizio, viene detto che:\n\n\n  \n    test20 dipende da main.o e vettore.o\n  \n  \n    a questo punto lancera’ automaticamente make main.o e\nmake vettore.o\n  \n  \n    poi controllera’ se test20 esiste gia’ e controllera’\nse la data di creazione dei file main.o e\nvettore.o e’ precedente a test20. Nel caso in cui il comando\nmake determini che la versione corrente di test20 e’ aggiornata\nnon fara’ nulla e dira’ che non ha fatto nulla.\n  \n  \n    altrimenti se test20 non esiste, oppure main.o o vettore.o\nsono piu’ recenti di test20 il comando creera’ una versione\naggiornata di test20, eseguendo: g++ main.o vettore.o -o test20\n  \n\n\nLa versione di seguito del Makefile e’ piu’ vicina allo “standard”\nMakefile:\n\nall: test20\n\ntest20: main.o vettore.o\n        g++ main.o vettore.o -o test20\n        \nmain.o: main.cpp vettore.h\n        g++ -c main.cpp\n        \nvettore.o: vettore.cpp vettore.h\n        g++ -c vettore.cpp\n          \nclean:  \n        rm -f *.o test20 *~ #* \n\n\nSi fa partire la compilazione con il comando make.\n\n\n  la prima linea nel Makefile implica che se scrivi solo make, in\nrealta’ intendi: make  test20\n\n\nSe si usa il comando seguente, tutti i file prodotti durante la\ncompilazione e tutti i file di testo di backup verranno cancellati:\n\nmake clean \n\n\nThis: per puntare all’istanza su cui sta agendo un metodo\n\nQuando un metodo e’ applicato ad un’istanza, quel metodo puo’ usare le\nvariabili dell’istanza e modificarle… ma alle volte e’ necessario\nconoscere l’indirizzo di un’istanza. Nessun problema, il comando\nthis serve proprio a questo scopo:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nclass vettore\n{\n   public:\n   double x;\n   double y;\n   \n   vettore (double a = 0, double b = 0)\n   {\n      x = a;\n      y = b;\n   }\n   \n   double modulo()\n   {\n      return sqrt (x * x + y * y);\n   }\n   \n   void definisci_lunghezza (double a = 1)\n   {\n      double lunghezza;\n      \n      lunghezza = this-&gt;modulo(); // fa il il modulo di QUESTA istanza\n      \n      x = x / lunghezza * a;\n      y = y / lunghezza * a;\n   }\n};\n\nint main ()\n{\n   vettore c (3, 5);\n   cout &lt;&lt; \"Il modulo del vettore c: \" &lt;&lt; c.modulo() &lt;&lt; endl;\n   \n   c.definisci_lunghezza(2);       // Transforma c in un vettore di lunghezza 2.\n   cout &lt;&lt; \"Il modulo del vettore c:\" &lt;&lt; c.modulo() &lt;&lt; endl;\n   \n   c.definisci_lunghezza();        // Transforma b in un vettore unitario.\n   cout &lt;&lt; \"Il modulo del vettore c: \" &lt;&lt; c.modulo() &lt;&lt; endl;\n   \n   return 0;\n}\n \n\n\nIl modulo del vettore c: 5.83095\nIl modulo del vettore c: 2\nIl modulo del vettore c: 1 \n\n\nArray di istanze di classi\n\nOvviamente e’ possibile dichiarare degli oggetti che sono array di\nclassi:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nclass vettore\n{\n   public:\n   double x; \n   double y;\n\n   vettore (double a = 0, double b = 0)\n   {\n      x = a;\n      y = b;\n   }\n   \n   double modulo ()\n   {\n      return sqrt (x * x + y * y);\n   }\n};\n\nint main ()\n{\n   vettore s [1000];\n   vettore t[3] = {vettore(4, 5), vettore(5, 5), vettore(2, 4)};\n   \n   s[23] = t[2];\n   cout &lt;&lt; t[0].modulo() &lt;&lt; endl;\n   return 0;\n}\n\n\n6.40312 \n\n\nEsempio di dichiarazione di una classe\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nclass vettore\n{\n  public:\n     double x;\n     double y;\n\n     vettore (double = 0, double = 0);  // questo e' il costruttore\n     vettore operator + (vettore);      // overload del +  \n     vettore operator - (vettore);      // overload del -\n     vettore operator - ();        // overload del - davanti alla classe stessa   \n     vettore operator * (double a);// overload del * prodotto per uno scalare    \n     double modulo();              // metodo per calcolare il modulo della classe\n     void definisci_lunghezza (double = 1); // modifica il modulo della classe   \n};\n\n\nvettore::vettore (double a, double b)    // specifico cosa fa il costruttore\n{\n  x = a;\n  y = b;\n}\n\nvettore vettore::operator + (vettore a)   // specifico l'overload del +\n{\n   return vettore (x + a.x, y + a.y);\n}\n\nvettore vettore::operator - (vettore a)   // specifico l'overload del -\n{\n   return vettore (x - a.x, y - a.y);\n}\n\nvettore vettore::operator - ()   // se tra parentesi non c'e' nulla, allora \n{                                // l'operatore va messo davanti alla istanza\n   return vettore (-x, -y);      // su cui deve agire\n}\n\nvettore vettore::operator * (double a)   // overload del * per fare prodotto per scalare\n{\n   return vettore (x * a, y * a);\n}\n\ndouble vettore::modulo()          // nota che questo metodo ha un tipo e un \n{                                 // HA un valore di return \n   return sqrt (x * x + y * y);        \n}\n\nvoid vettore::definisci_lunghezza (double a) // questo metodo invece e' void, e   \n{                                            // NON ha un valore di return \n   double lunghezza = this-&gt;modulo();\n   x = x / lunghezza * a;  \n   y = y / lunghezza * a;\n}\n\nostream&amp; operator &lt;&lt; (ostream&amp; o, vettore a) // questo NON e' un metodo\n{                                            // infatti non era tra i\n   o &lt;&lt; \"(\" &lt;&lt; a.x &lt;&lt; \", \" &lt;&lt; a.y &lt;&lt; \")\";    // prototipi\n   return o;\n}\n\nint main ()\n{\n   vettore a;         \n   vettore b;\n   vettore c (3, 5);\n   \n   a = c * 3;\n   a = b + c;\n   c = b - c + a + (b - a) * 7;\n\n   c = -c;\n   \n   cout &lt;&lt; \"Il modulo del vettore c: \" &lt;&lt; c.modulo() &lt;&lt; endl;\n   cout &lt;&lt; \"Il contenuto del vettore a: \" &lt;&lt; a &lt;&lt; endl;\n   cout &lt;&lt; \"L'opposto del vettore a: \" &lt;&lt; -a &lt;&lt; endl;\n   \n   c.definisci_lunghezza(2);   // Transforma c in un vettore di modulo 2\n   \n   a = vettore (56, -3);\n   b = vettore (7, c.y);\n   b.definisci_lunghezza();    // Transforma b in un vettore unitario\n   \n   cout &lt;&lt; \"Il contenuto del vettore b: \" &lt;&lt; b &lt;&lt; endl;\n   \n   double k;\n   \n   k = vettore(1, 1).modulo(); // k conterra' 1.4142 (=radice di 2)\n   cout &lt;&lt; \"k contiene: \" &lt;&lt; k &lt;&lt; endl;\n   return 0;\n}\n\n\nIl modulo del vettore c: 40.8167\nIl contenuto del vettore a: (3, 5)\nL' opposto del vettore a: (-3, -5)\nIl contenuto del vettore b: (0.971275, 0.23796)\nk contiene: 1.41421 \n\n\nE’ altresi’ possibile definire una funzione che produca la somma di due\noggetti vettore senza che questo venga menzionato all’interno della\ndefinizione della classe. In questo caso non sara’ un metodo della\nclasse, ma piuttosto una funzione che usa vettori:\n\nvettore operator + (vettore a, vettore b)\n{\nreturn vettore (a.x + b.x, a.y + b.y);\n} \n\n\nNell’esempio delle definizione della classe vettore qui sopra e’\ndefinita la moltiplicazione di un vettore per un double. Supponiamo di\nvolere la moltiplicazione di un double per un vettore. In questo caso\ndobbiamo scrivere una funzione isolata fuori dalla classe:\n\nvettore operator * (double a, vettore b)\n{\nreturn vettore (a * b.x, a * b.y);\n} \n\n\nChiaramente le keyword new e delete\nfunzionano anche per le istanze delle classi. In piu’,\nnew automaticamente chiama il constructor per\ninizializzare gli oggetti, e delete automaticamente\nchiama il destructor prima di dealloccare la memoria delle variabili\ndell’istanza come:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nclass vettore\n{\n   public:\n   double x;\n   double y;\n\n   vettore (double = 0, double = 0);\n   vettore operator + (vettore);\n   vettore operator - (vettore);\n   vettore operator - ();\n   vettore operator * (double);\n   \n   double modulo();\n   void definisci_lunghezza (double = 1);\n};\n\nvettore::vettore (double a, double b)\n{\n   x = a;\n   y = b;\n}\n\nvettore vettore::operator + (vettore a)\n{\n   return vettore (x + a.x, y + a.y);\n}\n\nvettore vettore::operator - (vettore a)\n{\n   return vettore (x - a.x, y - a.y);\n}\n\nvettore vettore::operator - ()\n{\n   return vettore (-x, -y);\n}\n\nvettore vettore::operator * (double a)\n{\n   return vettore (a * x, a * y);\n}\n\ndouble vettore::modulo()\n{\n   return sqrt (x * x + y * y);\n}\n\nvoid vettore::definisci_lunghezza (double a)\n{\n   vettore &amp;il_vettore = *this;\n   double lunghezza = il_vettore.modulo();\n   x = x / lunghezza * a;\n   y = y / lunghezza * a;\n}\n\nostream&amp; operator &lt;&lt; (ostream&amp; o, vettore a)\n{\n   o &lt;&lt; \"(\" &lt;&lt; a.x &lt;&lt; \", \" &lt;&lt; a.y &lt;&lt; \")\";\n   return o;\n}\n\nint main ()\n{\n   vettore c (3, 5);\n   vettore *r;     // r e' un puntatore a vettore.\n   r = new vettore;//  new alloccca la memoria necessaria\n                   // per contenere le variabili di vettore,\n                   // chiama il costruttore che le \n                   // inizializza a 0, 0. Infine \n                   // new restituisce l'indirizzo dell'istanza di vettore \n                   \n   cout &lt;&lt; *r &lt;&lt; endl;                \n                   \n   r-&gt;x = 94;\n   r-&gt;y = 345;\n   cout &lt;&lt; *r &lt;&lt; endl;\n\n   *r = vettore (94, 343);\n   cout &lt;&lt; *r &lt;&lt; endl;\n   \n   *r = *r - c;\n   r-&gt;definisci_lunghezza(3);\n   cout &lt;&lt; *r &lt;&lt; endl;\n   \n   *r = (-c * 3 + -*r * 4) * 5;\n   cout &lt;&lt; *r &lt;&lt; endl;\n   delete r;  // Chiama il distruttore di vettore \n              // poi libera la memoria.\n              \n   r = &amp;c;    // r punta verso il vettore c\n   cout &lt;&lt; *r &lt;&lt; endl;\n   r = new vettore (78, 345);  // Crea un nuovo vettore.\n   cout &lt;&lt; *r &lt;&lt; endl;         // Il costruttore  inizializzera'\n                               // la x e la y di vettore a 78 and 345\n                               \n   cout &lt;&lt; \"componente x di r: \" &lt;&lt; r-&gt;x &lt;&lt; endl;\n   cout &lt;&lt; \"componente y di r: \" &lt;&lt; (*r).x &lt;&lt; endl;\n   \n   delete r;\n   r = new vettore[4];  // crea un array di 4 vettore\n   r[3] = vettore (4, 5);\n   cout &lt;&lt; r[3].modulo() &lt;&lt; endl;\n   delete [] r;         // cancella l'array\n   \n   int n = 5;\n   r = new vettore[n];  // bello!\n   r[1] = vettore (432, 3);\n   cout &lt;&lt; r[1] &lt;&lt; endl;\n   delete [] r;\n   \n   return 0;\n}\n\n\n(0, 0)\n(94, 345)\n(94, 343)\n(0.77992, 2.89685)\n(-60.5984, -132.937)\n(3, 5)\n(78, 345)\ncomponente y di r: 78\ncomponente x di r: 78\n6.40312\n(432, 3) \n\n\nVariabili “static” in una classe\n\nUna o piu’ variabili in una classe possono essere dichiarate\nstatic. In questo caso:\n\n\n  \n    esiste una sola istanza di una variabile static\n  \n  \n    questa variabile e’ condivisa da tutte le istanze\ndella classe\n  \n  \n    questa variabile deve essere inizializzata fuori\ndalla dichiarazione della classe (e puo’ essere modificata)\n  \n\n\nusing namespace std;\n#include &lt;iostream&gt;\nclass vettore\n{\n   public:\n      double x;\n      double y;\n      static int count;   // &lt;= count e' una variabile STATIC\n      \n      vettore (double a = 0, double b = 0)  // COSTRUTTORE\n      {\n         x = a;\n         y = b;\n         count++;  // ogni volta che viene chiamato, si aggiunge 1 a count\n      }\n      \n      ~vettore()    // DISTRUTTORE\n      {\n         count--;  // ogni volta che viene chiamato si toglie 1 a count\n      }\n};\n\nint vettore::count = 0; // Inizializzazione FUORI \n                        // dalla definizione della classe\n\nint main ()\n{\n   cout &lt;&lt; \"Quanti vettore ci sono:\" &lt;&lt; endl;\n   \n   vettore a;    // istanza di vettore, il costruttore aggiunge 1 a count!      \n   cout &lt;&lt; vettore::count &lt;&lt; endl; \n   \n   vettore b;   // altra istanza, count diventa 2!\n   cout &lt;&lt; vettore::count &lt;&lt; endl;\n   \n   vettore *r, *u;  // due puntatori, il costruttore NON e' ancora chiamato\n   r = new vettore; // new chiama il costruttore, count diventa 3\n   cout &lt;&lt; vettore::count &lt;&lt; endl;\n   \n   u = new vettore; // new chiama il costruttore, count diventa 4\n   cout &lt;&lt; a.count &lt;&lt; endl;\n   delete r;       // delete chiama il DISTRUTTORE, count diventa 3\n   cout &lt;&lt; vettore::count &lt;&lt; endl;\n   \n   delete u;       // altro delete, count diventa 2\n   cout &lt;&lt; b.count &lt;&lt; endl;\n\n   return 0;\n} \n\n\nQuanti vettore ci sono:\n1\n2\n3\n4\n3\n2\n\n\nVariabili “const” in una classe\n\nUn tipo diverso di variabile e’ la const. Una variabile\nconst:\n\n\n  \n    viene definita all’interno della classe\n  \n  \n    non puo’ piu’ essere modificata\n  \n\n\nusing namespace std;\n#include &lt;iostream&gt;\nclass vettore\n{\n   public:\n      double x;\n      double y;\n      const static double pi = 3.1415927; // &lt;= pi greco non puo' essere modificato\n      \n      vettore (double a = 0, double b = 0)\n      {\n         x = a;\n         y = b;\n      }\n      \n      double cylinder_volume ()\n      {\n         return x * x / 4 * pi * y;\n      }\n};\n\nint main()\n{\n   cout &lt;&lt; \"Il valore di pi greco: \" &lt;&lt; vettore::pi &lt;&lt; endl &lt;&lt; endl;\n   \n   vettore k (3, 4);  \n   cout &lt;&lt; \"Risultato: \" &lt;&lt; k.cylinder_volume() &lt;&lt; endl;\n   return 0;\n}\n\n\nIl valore di pi greco: 3.14159\n\nRisultato: 28.2743\n\n\nE’ possibile DERIVARE un’altra classe da un’altra\n\nUna classe puo’ essere derivata da un’altra classe. La nuova classe,\neredita (inherits) le variabili e i metodi dalla\nbase class. Si possono aggiungere nuovi metodi e\nvariabili alla classe appena creata:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nclass vettore\n{\n   public:\n      double x;\n      double y;\n\n      vettore (double a = 0, double b = 0)\n      {\n         x = a;\n         y = b;\n      }\n      \n     double modulo()\n     {\n        return sqrt (x*x + y*y);\n     }\n     \n     double superficie()\n     {\n        return x * y;\n    }\n};\n\nclass trivettore: public vettore  // trivettore e' derivato da vettore\n{\n   public:\n   double z;  // variabile in piu' rispetto a x e y di vettore\n   \n   trivettore (double m=0, double n=0, double p=0): vettore (m, n)\n   {\n      z = p; // il constructor di vettore verra'  \n             // chiamato PRIMA del costruttore di trivettore\n             // con parametri m e n\n   }\n   \n   trivettore (vettore a)// questo constructor indica cosa fare nel caso in cui\n   {                     // venga fatto un cast da un vettore a un trivettore \n      x = a.x;\n      y = a.y;\n      z = 0;\n   }\n\n   double modulo ()  // ri-definisce il modulo() per un trivettore\n   {\n      return sqrt (x*x + y*y + z*z);\n   }\n\n   double volume ()\n   { \n       return this-&gt;superficie() * z; // usa il metodo \"superficie\" di questa istanza  \n   }\n};\n\nint main ()\n{\n   vettore a (4, 5);\n   trivettore b (1, 2, 3);\n   cout &lt;&lt; \"a (4, 5)    b (1, 2, 3)  *r = b\" &lt;&lt; endl &lt;&lt; endl;\n   cout &lt;&lt; \"Superficie di a: \" &lt;&lt; a.superficie() &lt;&lt; endl; \n   cout &lt;&lt; \"Volume di b: \" &lt;&lt; b.volume() &lt;&lt; endl;\n   cout &lt;&lt; \"Superficie della base di b: \" &lt;&lt; b.superficie() &lt;&lt; endl;\n   cout &lt;&lt; \"Modulo di a: \" &lt;&lt; a.modulo() &lt;&lt; endl;\n   cout &lt;&lt; \"Modulo di b: \" &lt;&lt; b.modulo() &lt;&lt; endl; \n   cout &lt;&lt; \"Modulo di base di b: \" &lt;&lt; b.vettore::modulo() &lt;&lt; endl;\n   \n   trivettore k;\n   k = a;     // grazie alla definizione di trivettore(vettore)\n              // copia di x e y,      k.z = 0\n   vettore j;\n   j = b;     // copia di x e y.      b.z non fa nulla\n   \n   vettore *r; // puntatore di un vettore\n   r = &amp;b;    // che pero' punta ad un TRIVECTOR\n   cout &lt;&lt; \"Superficie di r: \" &lt;&lt; r-&gt;superficie() &lt;&lt; endl;\n   cout &lt;&lt; \"Modulo di r: \" &lt;&lt; r-&gt;modulo() &lt;&lt; endl;\n\n   return 0;\n}\n\n\na (4, 5)  b (1, 2, 3)  *r = b\n\nSuperficie di a: 20\nVolume di b: 6\nSuperficie della base di b: 2\nModulo di a: 6.40312\nModulo di b: 3.74166\nModulo della base di b: 2.23607\nSuperficie di r: 2\nModulo di r: 2.23607 \n\n\nMetodi virtuali\n\nSe un metodo viene dichiarato virtuale, il programma controllera’ sempre\nil tipo dell’istanza a cui punta e usera’ il metodo appropriato.\n\nNel programma qui sopra, r-&gt;modulo() calcola il modulo\ndel vettore, usando x e y, perche’\nr e’ stato dichiarato come un puntatore ad un vettore.\nIl fatto che r in pratica punti ad un trivettore non\nviene preso in considerazione. Se vuoi che il programma controlli il\ntipo dell’oggetto puntato e scelga il metodo appropriato, allora bisogna\ndichiarare il metodo come virtuale all’interno della\nclasse di base.\n\nSe perlomeno uno dei metodi della classe di base e’ virtuale, allora un\n“header” di 4 byte viene aggiunto ad ogni istanza della classe.\nQuesto consente al programma di determinare a cosa punti un vettore (4\nbyte e’ probabilmente specifico del compilatore usato, su una macchina a\n64 bit forse sono 8 byte).\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nclass vettore\n{\n   public:\n   double x;\n   double y;\n\n   vettore (double a = 0, double b = 0)\n   {\n      x = a;\n      y = b;\n   }\n   virtual double modulo() //   metodo dichiarato come VIRTUALE\n   {\n      return sqrt (x*x + y*y);\n   }\n};\n\nclass trivettore: public vettore\n{\n   public:\n      double z;\n      trivettore (double m = 0, double n = 0, double p = 0)\n      {\n         x = m;  // Solo per fare un esempio pertinente\n         y = n;  // qui NON viene chiamato il costruttore   \n         z = p;  // di vettore e si lascia che il costruttore\n                 // di trivettore faccia tutto il lavoro. \n                 // Il risultato non cambia\n      }            \n      double modulo ()\n      {\n         return sqrt (x*x + y*y + z*z);\n      }\n};\n\nvoid test (vettore &amp;k)\n{\n   cout &lt;&lt; \"Risultato della funzione test:  \" &lt;&lt; k.modulo() &lt;&lt; endl;\n}\n\nint main ()\n{\n   vettore a (4, 5);\n   trivettore b (1, 2, 3);\n   cout &lt;&lt; \"a (4, 5)  b (1, 2, 3)\" &lt;&lt; endl &lt;&lt; endl;\n   vettore *r;\n   r = &amp;a;\n   cout &lt;&lt; \"modulo di vettore a: \" &lt;&lt; r-&gt;modulo() &lt;&lt; endl;\n   r = &amp;b;\n   cout &lt;&lt; \"modulo di trivettore b: \" &lt;&lt; r-&gt;modulo() &lt;&lt; endl;\n   test (a);\n   test (b);\n   \n   vettore &amp;s = b;\n   cout &lt;&lt; \"modulo di trivettore b: \" &lt;&lt; s.modulo() &lt;&lt; endl;\n   return 0;\n} \n\n\na (4, 5) b (1, 2, 3)\n\nmodulo di vettore a: 6.40312\nmodulo di trivettore b: 3.74166\nRisultato della funzione test:\n 6.40312\nRisultato della funzione test:\n 3.74166\nmodulo di trivettore b: 3.74166 \n\n\nDerivare una classe da piu’ di una classe di base\n\nSe vi state domandando se si possa derivare una classe da piu’ di una\nclasse di base, la risposta e’ si’:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nclass vettore\n{\n   public:\n      double x;\n      double y;\n\n      vettore (double a = 0, double b = 0)\n      {\n         x = a;\n         y = b;\n      }\n      \n      double superficie()\n      {\n         return fabs (x * y);\n      }\n};\n\nclass numero\n{\n   public:\n      double z;\n      numero (double a)\n      {\n         z = a;\n      }\n      \n      int is_negative () \n      {\n         if (z &lt; 0) return 1;\n         else\n         return 0;\n      }\n};\n\nclass trivettore: public vettore, public numero\n{\n   public:\n      trivettore(double a=0, double b=0, double c=0): vettore(a,b), numero(c)\n      {\n      }  // Il costruttore di trivettore chiama il\n         // costruttore di vettore, poi il costruttore\n         // di numero e in questo esempio non fa nulla\n         // di piu'                                 \n      double volume()\n      {\n         return fabs (x * y * z); \n      }\n};\n\nint main ()\n{\n   trivettore a(2, 3, -4);\n   cout &lt;&lt; a.volume() &lt;&lt; endl;\n   cout &lt;&lt; a.superficie() &lt;&lt; endl;\n   cout &lt;&lt; a.is_negative() &lt;&lt; endl;\n \nreturn 0;\n}\n\n\n24\n6\n1 \n\n\nDerivazione delle classi e metodi generici\n\nLa derivazione da classi gia’ esistenti consente di costruire classi\npiu’ complesse costruite a partire da una classe di base. Esiste\nun’altra applicazione della derivazione delle classi: consentire al\nprogrammatore di scrivere delle generic functions.\n\nSupponiamo di definire una classe di base senza alcuna variabile. In\npratica, non ha senso usare istanze di quella classe all’interno del\nproprio programma. Supponiamo pero’ di avere costruito una funzione, il\ncui scopo sia quello di ordinare istanze proprio di quella classe.\nQuesta funzione sara’ in grado di ordinare qualunque tutti gli oggetti,\nche siano istanze di classi derivate dalla classe di base iniziale. La\nsola condizione e’ che all’interno dei ognuna delle definizioni di\nclasse derivata, tutti i metodi di cui ha bisogno la funzione di\nordinamento siano definiti correttamente:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nclass octopus                     // costruiamo una classe senza argomenti\n{\n   public:\n\n      virtual double modulo() = 0;// =0 implica che la funzione non e' definita\n                                  // Questo fa si' che istanze di questa\n                                  // classe non possano essere dichiarate \n};\n\ndouble modulo_maggiore (octopus &amp;a, octopus &amp;b, octopus &amp;c)\n{\n   double r = a.modulo();    // questa funzione restituisce come valore il modulo\n   if (b.modulo() &gt; r) r = b.modulo();  // della istanza com modulo\n                                        // maggiore tra le 3\n   if (c.modulo() &gt; r) r = c.modulo();\n   return r;\n}\n\nclass vettore: public octopus   // costruisco una nuova classe\n                                // che eredita da octopus\n{\n   public:\n   double x; \n   double y;\n\n   vettore (double a = 0, double b = 0)\n   {\n      x = a;\n      y = b;\n   }\n   \n   double modulo()           // ha un metodo modulo come la classe di base\n   {\n      return sqrt (x * x + y * y);\n   }\n};\n\nclass numero: public octopus  // costruisco un'altra classe derivata da octopus\n{\n   public:\n      double n;\n      numero (double a = 0)\n      {\n         n = a;\n      }\n      double modulo()        // anche questa ha un metodo chiamato modulo\n      {\n         if (n &gt;= 0) return n;\n         else       return -n;\n      }\n};\n\nint main ()\n{\n   vettore k (1,2), m (6,7), n (100, 0);\n   numero p (5),  q (-3), r (-150);\n   cout &lt;&lt; modulo_maggiore (k, m, n) &lt;&lt; endl; // accetta tutte le classi\n   cout &lt;&lt; modulo_maggiore (p, q, r) &lt;&lt; endl; // che sono derivate da octopus\n   cout &lt;&lt; modulo_maggiore (p, q, n) &lt;&lt; endl; // quindi anche vettore e numero\n   \n   return 0;\n}\n\n\n100\n150\n100\n\n\nUna persona potrebbe pensare: ”ok, l’idea di derivare classi dalla\nclasse octopus e’ buona perche’, in quel modo posso\napplicare loro istanze dei metodi della mia classe e funzioni che erano\nstate progettate in modo generico per la classe\noctopus. Cosa potrebbe succedere se ci fosse un’altra\nclasse di base, chiamata cuttlefish, che ha dei metodi\ne delle funzioni molto interessanti? E’ forse necessario scegliere tra\noctopus e cuttlefish quando si vuole\nderivare una classe?” No chiaramente no!. Una classe derivata puo’\nessere derivata sia da octopus che da\ncuttlefish.\n\nQuesto e’ POLIMORFISMO\nLa classe derivata, semplicemente, deve definire sia metodi necessari\nper octopus che per cuttlefish:\n\nclass octopus\n{\n   virtual double modulo() = 0;\n};\n\nclass cuttlefish\n{\n   virtual int test() = 0;\n};\n\nclass vettore: public octopus, public cuttlefish\n{\n   double x;\n   double y;\n   double modulo ()\n   {\n      return sqrt (x * x + y * y); \n   }\n   \n   int test ()\n   {\n      if (x &gt; y) return 1;\n      else       return 0;\n   }\n}\n\n\nEncapsulation: public, protected e private\n\n\n  \n    La direttiva public, significa che, ovunque nel\nprogramma, si puo’ accedere ed usare le variabili e i metodi scritti\ndi seguito alla direttiva stessa.\n  \n  \n    La direttiva protected, significa che le variabili\ne i metodi scritti sotto ad essa sono accedibili ed usabili solo\ntramite metodi della classe stessa E metodi di\nclassi derivate da essa.\n  \n  \n    La direttiva private e’ ancora piu’ restrittiva, e’\npossibile accedere alle variabili ed ai metodi della classe stessa\n(non da quelle derivate o dall’esterno).\n  \n\n\nIl fatto che le variabili o i metodi siano dichiarati\nprivate or protected significa che\nnulla esterno alla classe puo’ accedere a loro o usarli. Questo tipo di\ncaratteristica si chiama ENCAPSULATION (se si vuole\ndare ad una funzione il diritto di accesso a quei metodi o a quelle\nvariabili, allora e’ necessario includere il prototype\ndella funzione all’interno della definizione di classe, con davanti la\nkeyword: friend.\n\nE’ considerata una buona pratica di programmazione il fatto di fare\n“encapsulation” per tutte le variabili di una classe. Questo\ncomportamento puo’ sembrare strano se si e’ abituati agli\nstruct, in C. In effetti uno struct ha\nsenso solo se e’ possibile accedere a tutti i dati al suo interno. In\nC++, invece, si deve creare un metodo apposito per accedere ai dati\nall’interno di una classe. L’esempio seguente usa l’esempio di base del\ncapitolo [ch:metodiClassi], ma dichiara i dati della classe come\nprotected:\n\nusing namespace std;\n#include &lt;iostream&gt;\nclass vettore\n{\n   protected:\n     double x;\n     double y;\n\n   public:\n      void definisci_x (int n)\n      {\n         x = n;\n      }\n      \n      void definisci_y (int n)\n      {\n         y = n;\n      }\n      \n      double superficie ()\n      {\n         double s;\n         s = x * y;\n         if (s &lt; 0) s = -s;\n         return s;\n      }\n};\n\nint main ()\n{\n   vettore a;\n   a.definisci_x (3);\n   a.definisci_y (4);\n   cout &lt;&lt; \"La superficie di a: \" &lt;&lt; a.superficie() &lt;&lt; endl;\n   \n   return 0;\n}\n\n\nLa superficie di a: 12 \n\n\nL’esempio di cui sopra, e’ un po’ strano dato che i parametri x e y\ndella classe possono essere inizializzati, ma non letti! Qualunque\ntentativo, all’interno del main() di leggere a.x o\na.y portera’ ad un errore di compilazione. Nell’esempio\nseguente, invece si potra’ anche leggere sia x che y:\n\nusing namespace std;\n#include &lt;iostream&gt;\nclass vettore\n{\n   protected:\n      double x;\n      double y;\n      \n   public:\n      void definisci_x (int n)\n      {\n         x = n;\n      }\n      \n      void definisci_y (int n)\n      {\n         y = n;\n      }\n      \n      double ottieni_x ()\n      {\n         return x;\n      }\n      \n      double ottieni_y ()\n      {\n         return y;\n      }\n      \n      double superficie ()\n      {\n         double s;\n         s = x * y;\n         if (s &lt; 0) s = -s;\n         return s;\n      }\n};\n\nint main ()\n{\n   vettore a;\n   a.definisci_x(3);\n   a.definisci_y(4);\n\n   cout &lt;&lt; \"La superficie di a: \" &lt;&lt; a.superficie() &lt;&lt; endl;\n   cout &lt;&lt; \"La larghezza di a:  \" &lt;&lt; a.ottieni_x() &lt;&lt; endl;\n   cout &lt;&lt; \"L'altezza di a: \" &lt;&lt; a.ottieni_y() &lt;&lt; endl;\n\n   return 0; \n}   \n\n\nLa superficie di a: 12\nLa larghezza di a: 3\nL'altezza di a: 4 \n\n\nIn C++ una persona non dovrebbe poter accedere ai dati di una classe\ndirettamente. Si dovrebbero dichiarare dei metodi appositi. Perche’\nviene richiesto questo comportamento? Ci sono molte ragioni. Una di\nqueste e’ che in questo modo si consente di cambiare il modo in cui i\ndati sono rappresentati all’interno della classe. Un’altra ragione e’\nche quasto consente ai dati all’interno della classe di essere\n“cross-dependent”. Supponiamo che x e y debbano sempre avere lo\nstesso segno, altrimenti questo causi dei problemi… Se fosse\nconsentito accedere ai dati della classe direttamente, sarebbe possibile\ne semplice imporre per esempio che x sia positivo e negativo.\nNell’esempio qui sotto questo e’ controllato strettamente.\n\nusing namespace std;\n#include &lt;iostream&gt;\nint sign (double n)\n{\n   if (n &gt;= 0) return 1;\n   return -1;\n}\nclass vettore\n{\n   protected:\n      double x;\n      double y;\n\n   public:\n      void definisci_x (int n)\n      {\n         x = n;\n         if (sign (x) != sign(y)) y = -y;\n      }\n      \n      void definisci_y (int n)\n      {\n         y = n;\n         if (sign (y) != sign(x)) x = -x;\n      }\n      \n      double ottieni_x ()\n      {\n         return x;\n      }\n      \n      double ottieni_y ()\n      {\n         return y;\n      }\n      \n      double superficie ()\n      {\n         double s;\n         s = x * y;\n         if (s &lt; 0) s = -s;\n         return s;\n      }\n};\n\nint main ()\n{\n   vettore a;\n   a.definisci_x(3);\n   a.definisci_y(4);\n\n   cout &lt;&lt; \"La superficie di a: \" &lt;&lt; a.superficie() &lt;&lt; endl;\n   cout &lt;&lt; \"La larghezza di a: \" &lt;&lt; a.ottieni_x() &lt;&lt; endl;\n   cout &lt;&lt; \"L'altezza di a: \" &lt;&lt; a.ottieni_y() &lt;&lt; endl;\n\n   return 0;\n} \n\n\nLa superficie di a: 12\nLa larghezza di a: 3\nL'altezza di a: 4\n\n\nBrevi cenni all’ Input e output di file\n\nParliamo ora di input/output. Questo e’ un argomento molto vasto per\nquanto riguarda il C++. Nel seguito c’e’ un programma che scrive un\nfile:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;fstream&gt;\nint main ()\n{\n   fstream f;\n   f.open(\"test.txt\", ios::out);\n   f &lt;&lt; \"Questo testo e' inviato in output ad un file.\" &lt;&lt; endl;\n   double a = 345;\n   f &lt;&lt; \"Il numero a: \" &lt;&lt; a &lt;&lt; endl;\n   f.close();\n    \n   return 0;\n} \n\n\nIl contenuto del file test.txt:\nQuesto testo e' inviato in output ad un file.\nIl numero a: 345\n\n\nQui invece c’e’ il programma che legge da file:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;fstream&gt;\nint main ()\n{\n   fstream f;\n   char c;\n   \n   cout &lt;&lt; \"Cosa c'e' nel file test.txt\" &lt;&lt; endl;\n   cout &lt;&lt; endl;\n   \n   f.open(\"test.txt\", ios::in);\n   while (! f.eof() )\n   {\n      f.get(c);\n      cout &lt;&lt; c;\n   }\n\n   f.close();\n   return 0; \n}   \n\n\nQuesto testo e' inviato in output ad un file.\nIl numero a: 345\n\n\nArray di character possono essere usati come file\n\nIn generale e’ possibile fare le stesse operazioni sugli array di\ncharacter che sui file. Questo risulta molto utile per convertire dati o\nper gestire array di memoria.\n\nQui c’e’ un programma che scrive su un array di character:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;strstream&gt;\n#include &lt;cstring&gt;\n#include &lt;cmath&gt;\nint main ()\n{\n   char a[1024];\n   ostrstream b(a, 1024);\n   b.seekp(0);                       // Inizia dal primo char.\n   b &lt;&lt; \"2 + 2 = \" &lt;&lt; 2 + 2 &lt;&lt; ends; // OCCHIO usa il comando \"ends\", non \"endl\" \n                                     // \"ends\" e' semplicemente il\n                                     // carattere null o '\\0'\n\n   cout &lt;&lt; a &lt;&lt; endl;\n   double v = 2;\n   strcpy (a, \"A sinus: \");\n   b.seekp(strlen (a));\n   b &lt;&lt; \"sin (\" &lt;&lt; v &lt;&lt; \") = \" &lt;&lt; sin(v) &lt;&lt; ends;\n   cout &lt;&lt; a &lt;&lt; endl;\n   return 0;\n} \n\n\n2 + 2 = 4\nA sinus: sin (2) = 0.909297 \n\n\nUn programma che legge da una stringa di caratteri:\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include &lt;strstream&gt;\n#include &lt;cstring&gt;\nint main ()\n{\n   char a[1024];\n   istrstream b(a, 1024);\n   strcpy (a, \"45.656\");\n   double k, p;\n   b.seekg(0);  // Inizia dal primo carattere.\n   b &gt;&gt; k;\n   k = k + 1;\n   cout &lt;&lt; k &lt;&lt; endl;\n   strcpy (a, \"444.23 56.89\");\n   b.seekg(0);\n   b &gt;&gt; k &gt;&gt; p;\n   cout &lt;&lt; k &lt;&lt; \", \" &lt;&lt; p + 1 &lt;&lt; endl;\n   return 0;\n} \n\n\n46.656\n444.23  57.89\n\n\nUn esempio di output formattato\n\nQuesto programma produce un output formattato in due modi. Si noti che i\nMODIFICATORI width() e setw() hanno\neffetto SOLO sul prossimio output dello stream. Elementi successivi non\nverranno influenzati dai MODIFICATORI.\n\nusing namespace std;\n#include &lt;iostream&gt;\n#include&lt;iomanip&gt;\n\nint main ()\n{\n   int i;\n   cout &lt;&lt; \"Una lista di numeri:\" &lt;&lt; endl;\n   for (i = 1; i &lt;= 1024; i *= 2)\n   {\n      cout.width (7);\n      cout &lt;&lt; i &lt;&lt; endl; \n   }\n   \n   cout &lt;&lt; \"Una tabella di numeri:\" &lt;&lt; endl;\n   for (i = 0; i &lt;= 4; i++)\n   {\n      cout &lt;&lt; setw(3) &lt;&lt; i &lt;&lt; setw(5) &lt;&lt; i * i * i &lt;&lt; endl;\n   }\n\n   return 0;\n}\n\n\nUna lista di numeri:\n1\n2\n4\n8\n16\n32\n64\n128\n256\n512\n1024\nUna tabella di numeri:\n0 0\n1 1\n2 8\n3 27\n4 64 \n\n\nA questo punto avete una conoscenza di base del C++. Da un buon libro\npotrete imparare molte altre cose. Il file management system e’ molto\npotente, e ha a disposizione molte altre possibilita’ rispetto a quelle\nillustrate in questa guida. C’e’ molto altro da dire riguardo alle\nclassi, classi template, clssi\nvirtual, … Per poter lavorare efficacemente con il C++ avrete\nbisogno di un buon libro di riferimento, proprio come succede con il C.\nAvrete inoltre bisogno di sapere come il C++ viene usato nel vostro\nparticolare dominio di lavoro. Gli standard, l’approccio globale, i\ntrucchi, i tipici problemi che si incontrano e le loro soluzioni… La\nmigliore referenza sono ovviamente i libri scritti da Bjarne Stroutrup\n(non ricordo quale io abbia letto). Il seguente libro contiene\npraticamente ogni dettaglio del C e C++, ed e’ costruito in modo molto\nsimile a questo testo e contiene un CD:\n\nJamsa's C/C++ Programmer's Bible\n&amp;copyright; 1998 Jamsa Press\nLas Vegas, United States\n\nFrench edition:\nC/C++ La Bible du programmeur\nKris Jamsa, Ph.D - Lars Klander \nFrance : Editions Eyrolles\nwww.eyrolles.com\nCanada : Les Editions Reynald Goulet inc.\nwww.goulet.ca\nISBN 2-212-09058-7\n\n\nQuesto e’ ormai obsoleto ed e’ ora:\n\nIt has been obsoleted and is now:\nJamsa's C/C++/C# Programmer's Bible\nOnword Press \n\n\nAltre referenze:\n\naccu:www.accu.org/bookreviews/public/reviews/0hr/index.htm\n\nCoderSource.net: www.codersource.net/\n\nC++ Guide:\ngoogle-styleguide.googlecode.com/svn/trunk/cppguide.xml\n\nC++ Reference:\nfresh2refresh.com/c/c-language-history\n\nA similar tutorial for Ada is available at\nwww.adahome.com/Ammo/cpp2ada.html\n\nA Haskell tutorial by a C programmer:\nlearnyouahaskell.com\n\nDesidero ringraziare Didier Bizzarri, Toni Ronkko,\nFrédéric Cloth, Jack Lam, Morten Brix\nPedersen, Elmer Fittery, Ana Yuseepi, William L. Dye, Bahjat F. Qaqish,\nMuthukumar Veluswamy, Marco Cimarosti, Jarrod Miller, Nikolaos Pothitos,\nRalph Wu, Dave Abercrombie, Alex Pennington, Scott Marsden, Robert\nKrten, Dave Panter, Cihat Imamoglu, Bohdan Zograf, David L. Markowitz,\nMarko Pozner, Filip Zaludek, Kevin Wheeler e Patrick Einheber per la\nloro ispirazione, suggerimenti, aiuti, dati, controllo sui bug,\nreferenze, miglioramento della versione inglese e traduzione.\n\nEric Brasseur - 23 Febbraio 1998 fino al 25 Dicembre 2016"
					}
					
				
			
		
			
				
					,
					
					"categorie": {
						"id": "categorie",
						"title": "Trucchi per Pages",
						"categories": "italiano",
						"url": " /categorie",
						"content": "Questo post e’ per ricordare alcune funzionalita’ di Jekyll.\n\nSono quasi tutti esempi presi da Notetheme di Thi\n\naggiungo qualche linea di testo. Provo latex $R^n$\n\n\n\tkeyboard_arrow_right\n\t\n\n\n$[A]=\\begin{bmatrix}1 &amp; 2 \\\\ 2 &amp; 3.999 \\end{bmatrix},$\n\n\n\n\n\n\n  \n    item 1\n    item 2\n    item 3\n    item 4\n    item 5\n    item 6\n  \n\n\nSito dove con buone informazioni riguardo al frontmatter dei post:\nhttps://chriskyfung.github.io/amp-affiliately-jekyll-theme/front-matter-guide/`:"
					}
					
				
			
		
	};
</script>

		</div>
	</div>
</main>

	<script src="/assets/js/jquery-1.11.0.min.js"></script>
<script type="text/javascript">
  jQuery(document).ready(function($){
    // browser window scroll (in pixels) after which the "back to top" link is shown
    var offset = 300,
      //browser window scroll (in pixels) after which the "back to top" link opacity is reduced
      offset_opacity = 1200,
      //duration of the top scrolling animation (in ms)
      scroll_top_duration = 700,
      //grab the "back to top" link
      $back_to_top = $('.cd-top');

    //hide or show the "back to top" link
    $(window).scroll(function(){
      ( $(this).scrollTop() > offset ) ? $back_to_top.addClass('cd-is-visible') : $back_to_top.removeClass('cd-is-visible cd-fade-out');
      // if( $(this).scrollTop() > offset_opacity ) { 
      //  $back_to_top.addClass('cd-fade-out');
      // }
    });

    //smooth scroll to top
    $back_to_top.on('click', function(event){
      event.preventDefault();
      $('body,html').animate({
        scrollTop: 0 ,
        }, scroll_top_duration
      );
    });

  });
</script>
<style type="text/css">
.cd-top {
  display: inline-block;
  height: 50px;
  width: 50px;
  position: fixed;
  bottom: 2%;
  right: 2%;
  border-radius: 40px;
  box-shadow: 0 0 10px rgba(0, 0, 0, 0.05);
  /* image replacement properties */
  overflow: hidden;
  text-indent: 100%;
  white-space: nowrap;
  background: #bbb url(/images/cd-top-arrow.svg) no-repeat center 50%;
  visibility: hidden;
  opacity: 0;
  -webkit-transition: opacity .3s 0s, visibility 0s .3s;
  -moz-transition: opacity .3s 0s, visibility 0s .3s;
  transition: opacity .3s 0s, visibility 0s .3s;
}
.cd-top.cd-is-visible, .cd-top.cd-fade-out, .no-touch .cd-top:hover {
  -webkit-transition: opacity .3s 0s, visibility 0s 0s;
  -moz-transition: opacity .3s 0s, visibility 0s 0s;
  transition: opacity .3s 0s, visibility 0s 0s;
}
.cd-top.cd-is-visible {
  /* the button becomes visible */
  visibility: visible;
  opacity: 1;
}
.cd-top.cd-fade-out {
  /* if the user keeps scrolling down, the button is out of focus and becomes less visible */
  opacity: .5;
}
.no-touch .cd-top:hover {
  background-color: #e86256;
  opacity: 1;
}
</style>

<a href="#0" class="cd-top">Top</a>
	<footer class="page-footer light-blue accent-4">  
  <div class="footer-copyright">
    <div class="container text-white">
     <a href="">4Phycs</a> &#xA9; 2021 Inherited from <a href="https://shawnteoh.github.io/matjek/">MatJeck</a>.
    </div>
  </div>
</footer>

<script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/js/materialize.min.js"></script>




  
    <script src="/assets/js/lunr.min.js"></script>
  

  
    <script src="/assets/js/search.js"></script>
  



<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})
  (window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>

<script src="/assets/js/main.js"></script>

        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158698892-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-158698892-1');
</script>

</body>
</html>
